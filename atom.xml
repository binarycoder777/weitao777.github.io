<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-03-21T08:19:53.324Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MySQL两阶段提交</title>
    <link href="http://example.com/2022/03/21/MySQL%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/"/>
    <id>http://example.com/2022/03/21/MySQL%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/</id>
    <published>2022-03-21T08:12:00.000Z</published>
    <updated>2022-03-21T08:19:53.324Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL中经常说的WAL技术，WAL的全称是Write Ahead Logging，它的关键点就是先写日志，再写磁盘。即当有一条记录需要更新时，InnoDB引擎就会先把记录写到redo log里，并更新内存，这个时候更新就完成了。因为如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。</p><p>在执行一条update语句时候，通过连接器、分析器、优化器之后，调用操作引擎，将新行写入内存，写入redo log，状态为prepare-&gt;写binlog-&gt;redo log状态修改为commit。写入redo的过程分为了prepare和commit称为二阶段提交。</p><ul><li><p>采用二阶段提交的原因：</p></li><li><p>先写redolog再写binlog：如果在一条语句redolog之后崩溃了，binlog则没有记录这条语句。系统在crash recovery时重新执行了一遍binlog便会少了这一次的修改。恢复的数据库少了这条更新。</p></li><li><p>先写binlog再写redolog：如果在一条语句binlog之后崩溃了，redolog则没有记录这条语句（数据库物理层面并没有执行这条语句）。系统在crash recovery时重新执行了一遍binlog便会多了这一次的修改。恢复的数据库便多了这条更新。</p></li></ul><h2 id="Crash-recovery"><a href="#Crash-recovery" class="headerlink" title="Crash recovery"></a>Crash recovery</h2><p>在做Crash recovery时，分为以下3种情况：</p><ul><li><p>binlog有记录，redolog状态commit：正常完成的事务，不需要恢复；</p></li><li><p>binlog有记录，redolog状态prepare：在binlog写完提交事务之前的crash，恢复操作：提交事务。（因为之前没有提交）</p></li><li><p>binlog无记录，redolog状态prepare：在binlog写完之前的crash，恢复操作：回滚事务（因为crash时并没有成功写入数据库）</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;MySQL中经常说的WAL技术，WAL的全称是Write Ahead Logging，它的关键点就是先写日志，再写磁盘。即当有一条记录需要更新时，InnoDB引擎就会先把记录写到redo log里，并更新内存，这个时候更新就完成了。因为如果每一次的更新操作都需要写进磁盘，然</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="两阶段提交" scheme="http://example.com/tags/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/"/>
    
    <category term="Binlog" scheme="http://example.com/tags/Binlog/"/>
    
  </entry>
  
  <entry>
    <title>如何判断一个数据库是否出现了问题？</title>
    <link href="http://example.com/2022/03/21/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E5%87%BA%E7%8E%B0%E4%BA%86%E9%97%AE%E9%A2%98%EF%BC%9F/"/>
    <id>http://example.com/2022/03/21/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E5%87%BA%E7%8E%B0%E4%BA%86%E9%97%AE%E9%A2%98%EF%BC%9F/</id>
    <published>2022-03-21T07:30:00.000Z</published>
    <updated>2022-03-21T07:50:00.480Z</updated>
    
    <content type="html"><![CDATA[<p>在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。</p><p>主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出问题了，由 HA 系统发起的。</p><p>而怎么判断主库出现了问题则是一个重点。</p><h2 id="select-1判断"><a href="#select-1判断" class="headerlink" title="select 1判断"></a>select 1判断</h2><p>select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。</p><p>我们设置 innodb_thread_concurrency 参数为3控制InnoDB 的并发线程上限。也就是说，一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。</p><p>此时执行三个select sleep(100) from t，然后执行 select 1会返回成功，但执行select * from t会阻塞。这select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。</p><p>在 InnoDB 中，innodb_thread_concurrency 这个参数的默认值是 0，表示不限制并发线程数量。但是，不限制并发线程数肯定是不行的。因为，一个机器的 CPU 核数有限，线程全冲进来，上下文切换的成本就会太高。</p><p>所以，通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值。这时，你一定会有疑问，并发线程上限数设置为 128 够干啥，线上的并发连接数动不动就上千了。</p><p>并发连接和并发查询，并不是同一个概念。你在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。</p><p>并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。这也是为什么我们需要设置innodb_thread_concurrency 参数的原因。</p><h2 id="查表判断"><a href="#查表判断" class="headerlink" title="查表判断"></a>查表判断</h2><p>为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行。</p><p>使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。</p><p>但是，我们马上还会碰到下一个问题，即：空间满了以后，这种方法又会变得不好使。</p><p>我们知道，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。</p><h2 id="更新判断"><a href="#更新判断" class="headerlink" title="更新判断"></a>更新判断</h2><p>既然要更新，就要放个有意义的字段，常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。</p><p>节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。</p><p>但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。</p><p>但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。所以，现在看来 mysql.health_check 这个表就不能只有一行数据了。</p><p>为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。</p><p>由于 MySQL 规定了主库和备库的 server_id 必须不同（否则创建主备关系的时候就会报错），这样就可以保证主、备库各自的检测命令不会发生冲突。</p><p>更新判断是一个相对比较常用的方案了，不过依然存在一些问题。其中，“判定慢”一直是让 DBA 头疼的问题。</p><p>其实，这里涉及到的是服务器 IO 资源分配的问题。</p><p>首先，所有的检测逻辑都需要一个超时时间 N。执行一条 update 语句，超过 N 秒后还不返回，就认为系统不可用。</p><p>你可以设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。</p><p>但是你要知道，IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在</p><p>拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。</p><p>检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。</p><p>也就是说，这时候在业务系统上正常的 SQL 语句已经执行得很慢了，但是 DBA 上去一看，HA 系统还在正常工作，并且认为主库现在处于可用状态。</p><p>之所以会出现这个现象，根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。</p><p>因为，外部检测都需要定时轮询，所以系统可能已经出问题了，但是却需要等到下一个检测发起执行语句的时候，我们才有可能发现问题。而且，如果你的运气不够好的话，可能第一次轮询还不能发现，这就会导致切换慢的问题。</p><h2 id="内部统计"><a href="#内部统计" class="headerlink" title="内部统计"></a>内部统计</h2><p>针对磁盘利用率这个问题，如果 MySQL 可以告诉我们，内部每一次 IO 请求的时间，那我们判断数据库是否出问题的方法就可靠得多了。</p><p>其实，MySQL 5.6 版本以后提供的 performance_schema 库，就在file_summary_by_event_name 表里统计了每次 IO 请求的时间。</p><p>因为我们每一次操作数据库，performance_schema 都需要额外地统计这些信息，所以我们打开这个统计功能是有性能损耗的。</p><p>假设，现在你已经开启了 redo log 和 binlog 这两个统计信息，那要怎么把这个信息用在实例状态诊断上呢？</p><p>很简单，你可以通过 MAX_TIMER 的值来判断数据库是否出问题了。比如，你可以设定阈值，单次 IO 请求时间超过 200 毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。</p><pre><code>mysql&gt; select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_n</code></pre><p>发现异常后，取到你需要的信息，再通过下面这条语句：</p><pre><code>mysql&gt; truncate table performance_schema.file_summary_by_event_name;</code></pre><p>把之前的统计信息清空。这样如果后面的监控中，再次出现这个异常，就可以加入监控累积值了。</p><pre><code>转载：https://www.jianshu.com/p/a95064c25e45</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。&lt;/p&gt;
&lt;p&gt;主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出问题了，由 HA 系统发起</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    <category term="主从复制" scheme="http://example.com/categories/MySQL/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="主从复制" scheme="http://example.com/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
    <category term="故障" scheme="http://example.com/tags/%E6%95%85%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>Java中的Optional类</title>
    <link href="http://example.com/2022/03/20/Java%E4%B8%AD%E7%9A%84Optional%E7%B1%BB/"/>
    <id>http://example.com/2022/03/20/Java%E4%B8%AD%E7%9A%84Optional%E7%B1%BB/</id>
    <published>2022-03-20T01:17:00.000Z</published>
    <updated>2022-03-20T01:25:45.463Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。</p></li><li><p>Optional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。</p></li><li><p>Optional 类的引入很好的解决空指针异常。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Optional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optio</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Optional" scheme="http://example.com/tags/Optional/"/>
    
    <category term="空指针" scheme="http://example.com/tags/%E7%A9%BA%E6%8C%87%E9%92%88/"/>
    
  </entry>
  
  <entry>
    <title>G1中的String去重操作</title>
    <link href="http://example.com/2022/03/19/G1%E4%B8%AD%E7%9A%84String%E5%8E%BB%E9%87%8D%E6%93%8D%E4%BD%9C/"/>
    <id>http://example.com/2022/03/19/G1%E4%B8%AD%E7%9A%84String%E5%8E%BB%E9%87%8D%E6%93%8D%E4%BD%9C/</id>
    <published>2022-03-19T12:04:00.000Z</published>
    <updated>2022-03-19T12:12:59.659Z</updated>
    
    <content type="html"><![CDATA[<p>堆中存活数据String占了很大一部分，而里面很多可能都是重复的字符串对象。在G1垃圾回收器中，会实现自动持续对重复的string对象进行去重，避免内存浪费。</p><p>实现：</p><ul><li>当垃圾回收器工作时，会访问堆上存活的对象。对每一个对象的访问都会检查是否是候选的要去重的string对象</li><li>如果是，把这个对象的一个引用插入到队列中等待后续处理。一个去重的线程在后台运行，处理这个队列。处理一个元素意味着从队列删除这个元素，然后尝试去重它引用的string对象。</li><li>使用一个hashtable来记录所有被string对象使用的不重复的char数组，当去重时，会查这个hashtable，来看是否存在一个一样的char数组。</li><li>如果存在，string对象会被调整引用那个对象，释放对原数组的引用，原数组被垃圾回收。如果查找失败，则放入hashtable，就可以用于共享。</li></ul><p>开启去重，默认未开启<br>usestringDeduplication(bool)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;堆中存活数据String占了很大一部分，而里面很多可能都是重复的字符串对象。在G1垃圾回收器中，会实现自动持续对重复的string对象进行去重，避免内存浪费。&lt;/p&gt;
&lt;p&gt;实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当垃圾回收器工作时，会访问堆上存活的对象。对每一个对象的访问都会检</summary>
      
    
    
    
    <category term="String" scheme="http://example.com/categories/String/"/>
    
    
    <category term="String" scheme="http://example.com/tags/String/"/>
    
    <category term="G1" scheme="http://example.com/tags/G1/"/>
    
  </entry>
  
  <entry>
    <title>关于String的intern方法</title>
    <link href="http://example.com/2022/03/19/%E5%85%B3%E4%BA%8EString%E7%9A%84intern%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2022/03/19/%E5%85%B3%E4%BA%8EString%E7%9A%84intern%E6%96%B9%E6%B3%95/</id>
    <published>2022-03-19T11:44:00.000Z</published>
    <updated>2022-03-19T12:04:44.977Z</updated>
    
    <content type="html"><![CDATA[<p>首先需要说明的是</p><ul><li>常量与常量拼接结果是放在常量池（编译期优化）</li><li>常量池不会存放相同字符串（hashtable）</li><li>只要其中一个是变量，拼接的时候，结果就是在堆（使用了stringbuiler）</li><li>拼接结果调用intern，则主动将常量池还没有的字符串对象放入，并返回对象地址。</li></ul><p>intern是一个native方法，调用的是底层c的方法。</p><ul><li>jdk1.6，会将这个对象尝试放入串池，如果串池有，则直接返回串池中该对象的地址。如果没有，则将该对象复杂一份，放入串池，并返回串池对象的地址</li><li>jdk1.7起，变动在于，当串池没有该对象，会将对象的引用复制一份放入串池，返回串池的引用地址</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;首先需要说明的是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;常量与常量拼接结果是放在常量池（编译期优化）&lt;/li&gt;
&lt;li&gt;常量池不会存放相同字符串（hashtable）&lt;/li&gt;
&lt;li&gt;只要其中一个是变量，拼接的时候，结果就是在堆（使用了stringbuiler）&lt;/li&gt;
&lt;li&gt;拼</summary>
      
    
    
    
    <category term="String" scheme="http://example.com/categories/String/"/>
    
    
    <category term="String" scheme="http://example.com/tags/String/"/>
    
    <category term="intern" scheme="http://example.com/tags/intern/"/>
    
  </entry>
  
  <entry>
    <title>为什么JDK9时String从char换为了byte？</title>
    <link href="http://example.com/2022/03/19/%E4%B8%BA%E4%BB%80%E4%B9%88JDK9%E6%97%B6String%E4%BB%8Echar%E6%8D%A2%E4%B8%BA%E4%BA%86byte%EF%BC%9F/"/>
    <id>http://example.com/2022/03/19/%E4%B8%BA%E4%BB%80%E4%B9%88JDK9%E6%97%B6String%E4%BB%8Echar%E6%8D%A2%E4%B8%BA%E4%BA%86byte%EF%BC%9F/</id>
    <published>2022-03-19T11:32:00.000Z</published>
    <updated>2022-03-19T11:44:40.964Z</updated>
    
    <content type="html"><![CDATA[<p>jdk1.8及以前String的底层是用char数组构成，但在1.9变为了byte数组，为什么呢？</p><p>首先我们知道char字符占两个字节（16位），其次字符串是堆使用的重要部分，而且大多数字符串对象只包含拉丁字符（这些字符只需一个字节的存储空间），因此对于这些字符串对象的内部char数组可能会有半数以上的空间未使用，造成空间浪费。</p><p>因此将char转化为byte来应对这种情况。新的String类将根据字符串的内存存储编码为ISO或UTF的字符。</p><ul><li>注意：同String一样的Stringbuffer和Stringbuilder也同样做了修改</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;jdk1.8及以前String的底层是用char数组构成，但在1.9变为了byte数组，为什么呢？&lt;/p&gt;
&lt;p&gt;首先我们知道char字符占两个字节（16位），其次字符串是堆使用的重要部分，而且大多数字符串对象只包含拉丁字符（这些字符只需一个字节的存储空间），因此对于这些字</summary>
      
    
    
    
    <category term="String" scheme="http://example.com/categories/String/"/>
    
    <category term="字符串" scheme="http://example.com/categories/String/%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    
    
    <category term="String" scheme="http://example.com/tags/String/"/>
    
    <category term="新特性" scheme="http://example.com/tags/%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot中JIT的分类</title>
    <link href="http://example.com/2022/03/19/HotSpot%E4%B8%ADJIT%E7%9A%84%E5%88%86%E7%B1%BB/"/>
    <id>http://example.com/2022/03/19/HotSpot%E4%B8%ADJIT%E7%9A%84%E5%88%86%E7%B1%BB/</id>
    <published>2022-03-19T11:11:00.000Z</published>
    <updated>2022-03-19T11:23:39.386Z</updated>
    
    <content type="html"><![CDATA[<p>JIT的编译器分了两种：C1和C2，在HotSpot下对应Client和Server两类。（-client和-servcer指定）</p><h2 id="C1和C2不同的优化策略"><a href="#C1和C2不同的优化策略" class="headerlink" title="C1和C2不同的优化策略"></a>C1和C2不同的优化策略</h2><p>C1：方法内联、去虚拟化、冗余消除</p><ul><li><p>方法内联：将引用的函数代码编译到引用点，尖山栈帧的生成，减少参数传递和跳转</p></li><li><p>去虚拟化：对唯一实现进行内联</p></li><li><p>冗余消除： 在运行期间把一些不会执行的代码折叠掉</p></li></ul><p>C2：逃逸分析</p><ul><li><p>标量替换：用标量值代替聚合对象的属性值</p></li><li><p>栈上分配：用于对未逃逸的对象分配对象在栈上，而不是堆</p></li><li><p>同步消除： 清楚同步操作，通常是指synchronized</p></li></ul><p>总结：</p><ul><li>JIT编译出来的机器码比解释器执行效率高，但启动速度要慢一点</li><li>C2比C1启动慢，但稳定下来后，C2速度远快于C1</li></ul><p>补充：AOT编译器（静态提前编译器），它可以将java类文件直接转化为机器码。</p><ul><li>好处：java虚拟机加载已经预编译好的二进制库，可以直接执行，不必等待及时编译器的预热</li><li>缺点：破坏了java一次编译到处运行。降低了java链接过程的动态性。还需要继续优化。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;JIT的编译器分了两种：C1和C2，在HotSpot下对应Client和Server两类。（-client和-servcer指定）&lt;/p&gt;
&lt;h2 id=&quot;C1和C2不同的优化策略&quot;&gt;&lt;a href=&quot;#C1和C2不同的优化策略&quot; class=&quot;headerlink&quot; ti</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="JIT" scheme="http://example.com/tags/JIT/"/>
    
    <category term="C1" scheme="http://example.com/tags/C1/"/>
    
    <category term="C2" scheme="http://example.com/tags/C2/"/>
    
  </entry>
  
  <entry>
    <title>热点探测技术</title>
    <link href="http://example.com/2022/03/19/%E7%83%AD%E7%82%B9%E6%8E%A2%E6%B5%8B%E6%8A%80%E6%9C%AF/"/>
    <id>http://example.com/2022/03/19/%E7%83%AD%E7%82%B9%E6%8E%A2%E6%B5%8B%E6%8A%80%E6%9C%AF/</id>
    <published>2022-03-19T10:59:00.000Z</published>
    <updated>2022-03-19T11:11:09.698Z</updated>
    
    <content type="html"><![CDATA[<p>一个方法被调用多次，或者是一个方法内部多虚循环执行都可以被称作热点代码，因此都可以通过JIT编译器编译为本地机器指令。其过程发生在方法的执行过程中，因此被称为栈上替换，或简称OSR。其主要实现通过热点探测功能<br>。HostSpot采用的热点探测方法是基于计数器的热点探测。</p><ul><li>计数器的热点探测：HotSpot会为每一个方法建立2个不同类型的计数器，分别为方法调用计数器和回边计数器。</li><li>方法调用计数器统计方法调用次数，默认在Client下是1500，Server下是10000，超过则会触发即时编译。（-XX：complieThreshold）。如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即一段时间内方法的调用次数。当超过一定时间调用次数不足让他提交给即使编译器编译，那么这个方法调用的计数器就减少一般（热点衰减：其发生在垃圾回收时顺便进行的）</li></ul><ul><li>回边计数器统计循环体执行循环次数</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;一个方法被调用多次，或者是一个方法内部多虚循环执行都可以被称作热点代码，因此都可以通过JIT编译器编译为本地机器指令。其过程发生在方法的执行过程中，因此被称为栈上替换，或简称OSR。其主要实现通过热点探测功能&lt;br&gt;。HostSpot采用的热点探测方法是基于计数器的热点探测</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="热点探测" scheme="http://example.com/tags/%E7%83%AD%E7%82%B9%E6%8E%A2%E6%B5%8B/"/>
    
    <category term="即时编译" scheme="http://example.com/tags/%E5%8D%B3%E6%97%B6%E7%BC%96%E8%AF%91/"/>
    
    <category term="方法计数器" scheme="http://example.com/tags/%E6%96%B9%E6%B3%95%E8%AE%A1%E6%95%B0%E5%99%A8/"/>
    
    <category term="回边计数器" scheme="http://example.com/tags/%E5%9B%9E%E8%BE%B9%E8%AE%A1%E6%95%B0%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Hot Spot JVM执行方式</title>
    <link href="http://example.com/2022/03/19/Hot-Spot-JVM%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8F/"/>
    <id>http://example.com/2022/03/19/Hot-Spot-JVM%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8F/</id>
    <published>2022-03-19T10:52:00.000Z</published>
    <updated>2022-03-19T10:57:38.235Z</updated>
    
    <content type="html"><![CDATA[<p>当虚拟机启动的时候，解释器可以先发挥作用，而不必等待及时编译器全部编译完在执行，可以节约不必要的编译时间，而在随着程序运行时间的推移。及时编译器会逐步发挥作用，根据热点探测技术，将有价值的字节码编译成本地的机器指令，换取更高效率的程序运行。</p><ul><li>机器在热机状态的负载要大于冷机状态。如果以热机状态进行流量切割，可能会使得处于冷机状态的服务器因无法承载流量而假死</li></ul><p> <img src="/images/pasted-165.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;当虚拟机启动的时候，解释器可以先发挥作用，而不必等待及时编译器全部编译完在执行，可以节约不必要的编译时间，而在随着程序运行时间的推移。及时编译器会逐步发挥作用，根据热点探测技术，将有价值的字节码编译成本地的机器指令，换取更高效率的程序运行。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;机器在</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="JVM" scheme="http://example.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>解释器的分类</title>
    <link href="http://example.com/2022/03/19/%E8%A7%A3%E9%87%8A%E5%99%A8%E7%9A%84%E5%88%86%E7%B1%BB/"/>
    <id>http://example.com/2022/03/19/%E8%A7%A3%E9%87%8A%E5%99%A8%E7%9A%84%E5%88%86%E7%B1%BB/</id>
    <published>2022-03-19T10:38:00.000Z</published>
    <updated>2022-03-19T10:42:48.741Z</updated>
    
    <content type="html"><![CDATA[<p>在java的发展历史上，一共有两套解释执行器，即古老的字节码解释器和现在普遍使用的模板解释器。</p><ul><li><p>字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率低下</p></li><li><p>模板解释器将每一条字节码和一个模板函数相关联，模板函数中直接产生字节码执行时的机器码，从而提升解释器的性能</p></li></ul><p>在Hotspot JVM中，解释器主要由Interpreter模块和Code模块构成</p><ul><li><p>Interpreter：实现了解释器的核心功能</p></li><li><p>Code模块： 用于管理HostSpot JVM在运行时生成的本地机器指令</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在java的发展历史上，一共有两套解释执行器，即古老的字节码解释器和现在普遍使用的模板解释器。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率低下&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;模板解释器将每一条字节码和一个模板函数相关联，模板</summary>
      
    
    
    
    <category term="解释器" scheme="http://example.com/categories/%E8%A7%A3%E9%87%8A%E5%99%A8/"/>
    
    <category term="JVM" scheme="http://example.com/categories/%E8%A7%A3%E9%87%8A%E5%99%A8/JVM/"/>
    
    
    <category term="解释器分类" scheme="http://example.com/tags/%E8%A7%A3%E9%87%8A%E5%99%A8%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>直接内存Direct Memory</title>
    <link href="http://example.com/2022/03/19/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98Direct-Memory/"/>
    <id>http://example.com/2022/03/19/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98Direct-Memory/</id>
    <published>2022-03-19T10:23:00.000Z</published>
    <updated>2022-03-19T10:28:48.265Z</updated>
    
    <content type="html"><![CDATA[<p>直接内存Direct Memory不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域。直接内存时Java堆外的，直接向系统申请的内存区间。</p><p>直接内存的访问速度优于java堆。读写性能更高</p><p> <img src="/images/pasted-164.png" alt="upload successful"></p><p> 存在的问题：不受指定堆大学的限定，而是受系统内存的限制。而且不受jvm内存管理回收，因此回收成本较高。</p><p> MaxDirectMemorySize可以知道其大小，默认与xmx参数值一样</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;直接内存Direct Memory不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域。直接内存时Java堆外的，直接向系统申请的内存区间。&lt;/p&gt;
&lt;p&gt;直接内存的访问速度优于java堆。读写性能更高&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pas</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="直接内存" scheme="http://example.com/tags/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>缓存和数据库的数据一致性问题</title>
    <link href="http://example.com/2022/03/19/%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2022/03/19/%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</id>
    <published>2022-03-19T01:21:00.000Z</published>
    <updated>2022-03-19T01:49:36.849Z</updated>
    
    <content type="html"><![CDATA[<p>缓存和数据库的数据一致性问题是一个老生常谈的问题了。在这里我记录几种方案及其可能出现的问题。</p><ol><li><p>先更新缓存，再更新数据库：此时线程A去先去更新缓存，然后更新数据库，但数据库更新时出现回滚，更新失败，数据库和缓存数据不一致。</p></li><li><p>先更新数据库，在更新缓存：线程A去更新数据库-&gt;线程B也去更新数据库-&gt;A更新数据库完毕-&gt;A去更新缓存-&gt;B更新数据库完毕-&gt;B更新缓存完毕-&gt;A更新缓存完毕，此时导致数据不一致</p></li><li><p>先删除缓存，在更新数据库：线程A删除缓存-&gt;线程B查询会去更新缓存-&gt;线程A更新数据库，数据不一致。（延迟双删，即在更新数据库后，延迟在去删除缓存，保证在此期间，其他线程读，导致数据不一致。注意：延迟双删不能绝对解决一致性问题，在更新完毕，延时删除之间，来了读线程，但因为网络等原因，更新缓存操作被延迟到了，延迟删除之后，也会导致数据不一致）</p></li><li><p>先更新数据库，在删除缓存：线程A更新数据库-&gt;线程A删除缓存-&gt;线程B查询-&gt;线程C更新数据库-&gt;线程C删除缓存-&gt;线程B更新缓存。数据不一致。</p></li><li><p>请求串行化：将访问操作串行化，先删缓存，将更新数据库的操作放进有序队列中从缓存查不到的查询操作，都进入有序队列。需要解决的问题：读请求积压，大量超时，导致数据库的压力：限流、熔断。如何避免大量请求积压：将队列水平拆分，提高并行度。保证相同请求路由正确。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;缓存和数据库的数据一致性问题是一个老生常谈的问题了。在这里我记录几种方案及其可能出现的问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;先更新缓存，再更新数据库：此时线程A去先去更新缓存，然后更新数据库，但数据库更新时出现回滚，更新失败，数据库和缓存数据不一致。&lt;/p&gt;
&lt;/li&gt;
</summary>
      
    
    
    
    <category term="Redis" scheme="http://example.com/categories/Redis/"/>
    
    
    <category term="Redis" scheme="http://example.com/tags/Redis/"/>
    
    <category term="数据一致性" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>对ThreadLocal的理解</title>
    <link href="http://example.com/2022/03/18/%E5%AF%B9ThreadLocal%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://example.com/2022/03/18/%E5%AF%B9ThreadLocal%E7%9A%84%E7%90%86%E8%A7%A3/</id>
    <published>2022-03-18T14:22:00.000Z</published>
    <updated>2022-03-18T15:40:02.496Z</updated>
    
    <content type="html"><![CDATA[<h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p>ThreadLocal是Java语言提供用于支持线程局部变量的标准实现类。</p><p>在我们编写的代码层面来讲，我们所编写的代码实际上是在管理系统中各个对象的相关状态。如果不能够对各个对象状态的访问进行合理的管理，对象的状态将被破坏，进而导致系统的不正常运行。特别是多线程环境下，多个线程可能同时对系统中的单一或多个对象状态进行访问，如果不能保证在此期间的线程安全，整个系统将会走向崩溃的方向。</p><p>当然，很容易想到的就是你可以使用synchronization的方式上锁来解决多线程下的线程安全问题，但是这种方式无疑是一个重量级的方式，上了synchronization锁，性能消耗很大。</p><p>那怎么解决呢？synchronization方式是避免了同一时刻多个线程对共享对象的访问，将之变为同步访问。而此时，其实也可以通过ThreadLocal避免对象共享，来达到线程安全。共享对象在个线程内都有一个副本，线程对副本进行操作，结束后再修改共享变量，达到线程安全。</p><p>因此从上面来看，其实synchronization和ThreadLocal在保证线程安全方式上，前者像是从纵向上的一种方式，而后者则是横向上的一种方式。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>虽然是通过ThreadLocal来设定于各个线程的数据资源，但ThreadLocal自身不会保存这些特定的资源数据的。因为数据资源位于对应的线程，由线程管理，而每个线程有一个ThreadLocal.ThreadLocalMap类型的名为ThreadLocal的实例变量，它就是保持那些通过ThreadL哦按差设置给这个资源的地方。当通过ThreadLocal的set方法设置数据的时候，Threadloacl会获取当前这个线程的引用，然后通过该引用获取当前线程的threadLocals，然后将当前线程当做key，将要设置的数据设置到当前线程<br> <img src="/images/pasted-163.png" alt="upload successful"><br>事实上，ThreadLocal就好像是一个窗口，通过这个窗口，我们可以将特定于线程的线程的数据资源绑定到当前线程，也可以通过这个窗口获取绑定的资源。在整个线程的生命周期，我们都可以通过ThreadLoacl这个窗口与当前线程打交道。</p><ul><li>类比城市的各个公交线，就好似系统中的个个线程，在各个公交线上，会有对应的公交车（ThreadLocal），用于运送特定线路的乘客（数据资源），乘客可以下车或上车（数据的装载和清除），在整条路线上都有各个乘车点（处理数据），最终达到终点（线程消亡）。</li></ul><h2 id="ThreadLocal的理解"><a href="#ThreadLocal的理解" class="headerlink" title="ThreadLocal的理解"></a>ThreadLocal的理解</h2><ul><li><p>管理应用程序实现中的线程安全。对于某些有状态的或者非状态的线程安全对象，可以在多线程为某个线程分配对应副本，而不是让多个线程共享该类型的某个对象，从而避免了需要多线程对这些对象进行访问的危险工作。（比如使用JDBC进行数据库访问的过程中，connection对象就属于那种有状态并且非线程安全的类，我们通过ThreadLocal为每个线程分配一个特有的connection保证数据访问安全）</p></li><li><p>我们也可以通过ThreadLocal来跟踪保存在线程内的日志序列，在程序执行的任何必要点将系统跟踪信息追加到ThreadLocal，然后在合适的时点取出分析。</p></li><li><p>我们还可以通过ThreadLocal来保存某个全局变量，在合适的时点取出做某些逻辑。采用ThreadLocal在当前执行的线程类执行数据流转，可以表面耦合性很强的参数传递。（这种处理方式有一种让数据随波逐流的意思，一旦处理不当，甚至会令系统出现差异） </p></li><li><p>某些情况下的性能优化（即以空间换取时间的方式）</p></li><li><p>per-thread Singleton，当某项资源的初始化代价很大，并且在执行中会多次创建，可以存入threadloca避免多次创建。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;理解&quot;&gt;&lt;a href=&quot;#理解&quot; class=&quot;headerlink&quot; title=&quot;理解&quot;&gt;&lt;/a&gt;理解&lt;/h2&gt;&lt;p&gt;ThreadLocal是Java语言提供用于支持线程局部变量的标准实现类。&lt;/p&gt;
&lt;p&gt;在我们编写的代码层面来讲，我们所编写的代码实际上是</summary>
      
    
    
    
    <category term="多线程" scheme="http://example.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
    <category term="ThreadLocal" scheme="http://example.com/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/ThreadLocal/"/>
    
    
    <category term="ThreadLocal" scheme="http://example.com/tags/ThreadLocal/"/>
    
    <category term="多线程" scheme="http://example.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>JVM针对不同年龄段的 对象的分配策略</title>
    <link href="http://example.com/2022/03/15/JVM%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E5%B9%B4%E9%BE%84%E6%AE%B5%E7%9A%84-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/"/>
    <id>http://example.com/2022/03/15/JVM%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E5%B9%B4%E9%BE%84%E6%AE%B5%E7%9A%84-%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/</id>
    <published>2022-03-15T03:25:00.000Z</published>
    <updated>2022-03-15T03:35:09.059Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>优先分配到eden区</p></li><li><p>对于大对象会直接分配到老年代（eden区young gc后还是无法分配足够内存给大对象，大对象会直接跃升到老年代或者在young gc后，幸存者区放不下跃升到幸存者区的大对象，也会直接跃升到老年代，如果老年代也不够分配，则进行major gc，如果仍然不够，则oom）</p></li><li><p>长期存活的对象分配到老年代（根据分代年龄晋升，默认15，每经历一次yonug gc存活下来，分代年龄+1）</p></li><li><p>动态对象年龄判断：如果幸存者区中相同年龄的所有对象大小的总和大于幸存者区空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无需达到分代年龄要求</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;优先分配到eden区&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;对于大对象会直接分配到老年代（eden区young gc后还是无法分配足够内存给大对象，大对象会直接跃升到老年代或者在young gc后，幸存者区放不下跃升到幸存者区的大对象，也会直接跃升到老年代，如</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="JVM" scheme="http://example.com/tags/JVM/"/>
    
    <category term="堆" scheme="http://example.com/tags/%E5%A0%86/"/>
    
    <category term="对象内存分配" scheme="http://example.com/tags/%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch分片原理</title>
    <link href="http://example.com/2022/03/14/Elasticsearch%E5%88%86%E7%89%87%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2022/03/14/Elasticsearch%E5%88%86%E7%89%87%E5%8E%9F%E7%90%86/</id>
    <published>2022-03-14T07:09:00.000Z</published>
    <updated>2022-03-14T08:17:41.076Z</updated>
    
    <content type="html"><![CDATA[<h2 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h2><p>分片是 Elasticsearch 最小的工作单元。一个分片是一个Lucene索引。</p><p>而索引采用的是一种称为倒排索引的结构，它适用于快速的全文搜索。</p><p>见其名，知其意，有倒排索引，肯定会对应有正向索引。正向索引（forward index），反向索引（inverted index）更熟悉的名字是倒排索引。</p><p>所谓的正向索引，就是搜索引擎会将待搜索的文件都对应一个文件 ID，搜索时将这个ID 和搜索关键字进行对应，形成 K-V 对，然后对关键字进行统计计数。</p><p>但是互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。</p><p>一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。</p><p>例如，假设我们有两个文档，每个文档的 content 域包含如下内容：</p><p> The quick brown fox jumped over the lazy dog</p><p> Quick brown foxes leap over lazy dogs in summer</p><p>为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的词（我们称它为词条或 tokens ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。</p><p> <img src="/images/pasted-160.png" alt="upload successful"></p><p> 现在，如果我们想搜索 quick brown ，我们只需要查找包含每个词条的文档：</p><p> <img src="/images/pasted-161.png" alt="upload successful"></p><p>两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单相似性算法，那么我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。</p><p>但是，我们目前的倒排索引有一些问题：</p><p> Quick 和 quick 以独立的词条出现，然而用户可能认为它们是相同的词。</p><p> fox 和 foxes 非常相似, 就像 dog 和 dogs ；他们有相同的词根。</p><p> jumped 和 leap, 尽管没有相同的词根，但他们的意思很相近。他们是同义词。</p><p>使用前面的索引搜索 +Quick +fox 不会得到任何匹配文档。（记住，+ 前缀表明这个词必须存在。）只有同时出现 Quick 和 fox 的文档才满足这个查询条件，但是第一个文档包含quick fox ，第二个文档包含 Quick foxes 。</p><p>我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。</p><p>例如：</p><p> Quick 可以小写化为 quick 。 </p><p> foxes 可以 词干提取 –变为词根的格式– 为 fox 。类似的， dogs 可以为提取为 dog 。 </p><p> jumped 和 leap 是同义词，可以索引为相同的单词 jump 。</p><p> <img src="/images/pasted-162.png" alt="upload successful"></p><p> 这还远远不够。我们搜索 +Quick +fox 仍然 会失败，因为在我们的索引中，已经没有 Quick 了。但是，如果我们对搜索的字符串使用与 content 域相同的标准化规则，会变成查询<br>+quick +fox，这样两个文档都会匹配！分词和标准化的过程称为分析.</p><p>这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。</p><h2 id="文档搜索"><a href="#文档搜索" class="headerlink" title="文档搜索"></a>文档搜索</h2><p>早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检到。</p><p>倒排索引被写入磁盘后是 不可改变 的:它永远不会修改。</p><p>不变性有重要的价值：</p><ul><li><p>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。</p></li><li><p>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</p></li><li><p>其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</p></li><li><p>写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。</p></li></ul><p>当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档 可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。</p><h2 id="动态更新索引"><a href="#动态更新索引" class="headerlink" title="动态更新索引"></a>动态更新索引</h2><p>如何在保留不变性的前提下实现倒排索引的更新？</p><ul><li>答案是: 用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到，从最早的开始查询完后再对结果进行合并。</li></ul><p>Elasticsearch 基于 Lucene, 这个 java 库引入了按段搜索的概念。 每一段本身都是一个倒排索引， 但索引在 Lucene 中除表示所有段的集合外，还增加了提交点的概念 — 一个列出了所有已知段的文件。</p><p>按段搜索会以如下流程执行：</p><ol><li><p>新文档被收集到内存索引缓存</p></li><li><p>不时地, 缓存被提交</p><p> (1) 一个新的段—一个追加的倒排索引—被写入磁盘。</p><p> (2) 一个新的包含新段名字的 提交点 被写入磁盘</p><p> (3) 磁盘进行 同步 — 所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件</p></li><li><p>新的段被开启，让它包含的文档可见以被搜索</p></li><li><p>内存缓存被清空，等待接收新的文档</p></li></ol><p>当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。 这种方式可以用相对较低的成本将新文档添加到索引。</p><p>段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。 取而代之的是，每个提交点会包含一个 .del 文件，文件中会列出这些被删除文档的段信息。</p><p>当一个文档被 “删除” 时，它实际上只是在 .del 文件中被 标记 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个<br>旧版本文档在结果集返回前就已经被移除。</p><h2 id="近实时搜索"><a href="#近实时搜索" class="headerlink" title="近实时搜索"></a>近实时搜索</h2><p>随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。磁盘在这里成为了瓶颈。提（Commiting）一个新的段到磁盘需要一个 fsync 来确保段被物理性地写入磁盘，这样在断<br>电的时候就不会丢失数据。 但是 fsync 操作代价很大; 如果每次索引一个文档都去执行一次的话会造成很大的性能问题。</p><p>我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着 fsync 要从整个过程中被移除。在 Elasticsearch 和磁盘之间是文件系统缓存。 像之前描述的一样， 在内存索引缓冲区中的文档会被写入到一个新的段中。 但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。</p><p>Lucene 允许新段被写入和打开—使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。</p><p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是 近 实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。</p><p>这些行为可能会对新用户造成困惑: 他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用 refresh API 执行一次手动刷新: /users/_refresh</p><ul><li>尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候， 手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。 相反，你的应用需要意识到 Elasticsearch 的近实时的性质，并接受它的不足。</li></ul><p>并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件，你可能想优化索引速度而不是近实时搜索， 可以通过设置 refresh_interval ， 降低每个索<br>引的刷新频率</p><p>refresh_interval 可以在既存索引上进行动态更新。 在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来</p><h2 id="持久变更"><a href="#持久变更" class="headerlink" title="持久变更"></a>持久变更</h2><p>如果没有用 fsync 把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证 Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。在 动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一<br>个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。</p><p>即使通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办？我们也不希望丢失掉这些数据。Elasticsearch 增加了一个 translog ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录</p><ol><li><p>一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog</p></li><li><p>刷新（refresh）使分片每秒被刷新（refresh）一次：</p><ol><li>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行 fsync 操作。</li><li>这个段被打开，使其可被搜索</li><li>内存缓冲区被清空</li></ol></li><li><p>这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志</p></li><li><p>每隔一段时间—例如 translog 变得越来越大—索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行</p><ol><li><p>所有在内存缓冲区的文档都被写入一个新的段。</p></li><li><p>缓冲区被清空。</p></li><li><p>一个提交点被写入硬盘。</p></li><li><p>文件系统缓存通过 fsync 被刷新（flush）。</p></li><li><p>老的 translog 被删除。</p></li></ol></li></ol><p>translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。</p><p>translog 也被用来提供实时 CRUD 。当你试着通过 ID 查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。</p><p>执行一个提交并且截断 translog 的行为在 Elasticsearch 被称作一次 flush分片每 30 分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新</p><p>你很少需要自己手动执行 flush 操作；通常情况下，自动刷新就足够了。这就是说，在重启节点或关闭索引之前执行 flush 有益于你的索引。当 Elasticsearch 尝试恢复或重新打<br>开一个索引， 它需要重放 translog 中所有的操作，所以如果日志越短，恢复越快。</p><p>translog 的目的是保证操作不会丢失，在文件被 fsync 到磁盘前，被写入的文件在重启之后就会丢失。默认 translog 是每 5 秒被 fsync 刷新到硬盘， 或者在每次写请求完成之<br>后执行(e.g. index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。最终， 基本上，这意味着在整个请求被 fsync 到主分片和复制分片的 translog 之前，你的客户端不会得到一个 200 OK 响应。</p><p>在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小（特别是 bulk 导入，它在一次请求中平摊了大量文档的开销）。<br>但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每 5 秒执行一次 fsync 。如果你决定使用异步 translog 的话，你需要 保证 在发生 crash 时，丢失掉 sync_interval 时间段的数据也无所谓。请在决定前知晓这个特性。如果你不确定这个行为的后果，最好是使用默认的参数（ “index.translog.durability”: “request” ）来避免数据丢失。</p><h2 id="段合并"><a href="#段合并" class="headerlink" title="段合并"></a>段合并</h2><p>由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段<br>数目太多会带来较大的麻烦。 每一个段都会消耗文件句柄、内存和 cpu 运行周期。更重要<br>的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。<br>Elasticsearch 通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大<br>的段再被合并到更大的段。<br>段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的<br>旧版本）不会被拷贝到新的大段中。<br>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。</p><ol><li><p>当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</p></li><li><p>合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p></li><li><p>一旦合并结束，老的段被删除<br> 新的段被刷新（flush）到了磁盘。 ** 写入一个包含新段且排除旧的和较小的段<br>的新提交点。<br> 新的段被打开用来搜索。<br> 老的段被删除。</p></li></ol><p>  合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。Elasticsearch<br>在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;倒排索引&quot;&gt;&lt;a href=&quot;#倒排索引&quot; class=&quot;headerlink&quot; title=&quot;倒排索引&quot;&gt;&lt;/a&gt;倒排索引&lt;/h2&gt;&lt;p&gt;分片是 Elasticsearch 最小的工作单元。一个分片是一个Lucene索引。&lt;/p&gt;
&lt;p&gt;而索引采用的是一种称为倒</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="分片" scheme="http://example.com/tags/%E5%88%86%E7%89%87/"/>
    
    <category term="Elasticsearch" scheme="http://example.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch分片控制</title>
    <link href="http://example.com/2022/03/14/Elasticsearch%E5%88%86%E7%89%87%E6%8E%A7%E5%88%B6/"/>
    <id>http://example.com/2022/03/14/Elasticsearch%E5%88%86%E7%89%87%E6%8E%A7%E5%88%B6/</id>
    <published>2022-03-14T06:55:00.000Z</published>
    <updated>2022-03-14T07:09:39.594Z</updated>
    
    <content type="html"><![CDATA[<p>每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。</p><p>写流程：</p><p>新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片</p><p> <img src="/images/pasted-159.png" alt="upload successful"></p><p> 新建，索引和删除文档所需要的步骤顺序：</p><ol><li><p>客户端向 Node 1 发送新建、索引或者删除请求。</p></li><li><p>节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。</p></li><li><p>Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。</p></li></ol><p>在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。有一些可选的请求参数允许您影响这个过程，可能以数据安全为代价提升性能。</p><p>读流程：我们可以从主分片或者从其它任意副本分片检索文档。</p><p>从主分片或者副本分片检索文档的步骤顺序：</p><ol><li><p>客户端向 Node 1 发送获取请求。</p></li><li><p>节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。</p></li><li><p>Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。</p></li></ol><p>更新流程：</p><ol><li><p>客户端向 Node 1 发送更新请求。</p></li><li><p>它将请求转发到主分片所在的 Node 3 。</p></li><li><p>Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。</p></li><li><p>如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。</p></li></ol><p>注意：当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用改，导致得到损坏的文档。</p><p>多文档操作流程：mget 和 bulk API 的模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成每个分片的多文档请求，并且将这些请求并行转发到每个参与节点。协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。</p><p>用单个 mget 请求取回多个文档所需的步骤顺序:</p><ol><li><p>客户端向 Node 1 发送 mget 请求。</p></li><li><p>Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端</p></li></ol><p>bulk API 按如下步骤顺序执行：</p><ol><li><p>客户端向 Node 1 发送 bulk 请求。</p></li><li><p>Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。</p></li><li><p>主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。&lt;/p&gt;
&lt;p&gt;写流程：&lt;/p&gt;
&lt;p&gt;新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="分片" scheme="http://example.com/tags/%E5%88%86%E7%89%87/"/>
    
    <category term="Elasticsearch" scheme="http://example.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch路由计算</title>
    <link href="http://example.com/2022/03/14/Elasticsearch%E8%B7%AF%E7%94%B1%E8%AE%A1%E7%AE%97/"/>
    <id>http://example.com/2022/03/14/Elasticsearch%E8%B7%AF%E7%94%B1%E8%AE%A1%E7%AE%97/</id>
    <published>2022-03-14T06:53:00.000Z</published>
    <updated>2022-03-14T06:55:12.233Z</updated>
    
    <content type="html"><![CDATA[<p>当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道<br>从何处寻找了。实际上，这个过程是根据下面这个公式决定的：</p><p> <img src="/images/pasted-158.png" alt="upload successful"></p><p> routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。</p><p>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道&lt;br&gt;从何处寻找</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="routing" scheme="http://example.com/tags/routing/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch的基本概念</title>
    <link href="http://example.com/2022/03/14/Elasticsearch%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <id>http://example.com/2022/03/14/Elasticsearch%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</id>
    <published>2022-03-14T06:09:00.000Z</published>
    <updated>2022-03-14T06:23:48.299Z</updated>
    
    <content type="html"><![CDATA[<p>Elasticsearch 索引的精髓：一切设计都是为了提高搜索的性能。</p><p>Elasticsearch的索引就是一个拥有相似特征的文档的集合。一个索引由一个名字来标识（必须全是小写字母）。<br>当我们要对这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。</p><p>在一个索引中，你可以定义一种或多种类型。这个类型是索引的一个逻辑分区/分类。但在7.x已经默认不再支持自定义索引类型。</p><p>文档（Document）：一个文档是一个可被索引的基础信息单元，也就是一条数据。</p><p>字段（Field）：相当于数据表的字段，对文档数据根据不同属性进行的分类标识。</p><p>映射（Mapping）：mapping 是处理数据的方式和规则方面做一些限制，如：某个字段的数据类型、默认值、<br>分析器、是否被索引等等。这些都是映射里面可以设置的，其它就是处理 ES 里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。</p><p>分片（Shards）：一个索引可以存储超出单个节点硬件限制的大量数据。比如，一个具有 10 亿文档数据的索引占据 1TB 的磁盘空间，而任一节点都可能没有这样大的磁盘空间。或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch 提供了将索引划分成多份的能力，每一份就称之为分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分<br>片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。</p><p>分片很重要，主要有两方面的原因：</p><p>1）允许你水平分割 / 扩展你的内容容量。</p><p>2）允许你在分片之上进行分布式的、并行的操作，进而提高性能/吞吐量。</p><p>至于一个分片怎样分布，它的文档怎样聚合和搜索请求，是完全由 Elasticsearch 管理的，对于作为用户的你来说，这些都是透明的，无需过分关心。</p><p>被混淆的概念是，一个 Lucene 索引 我们在 Elasticsearch 称作 分片 。 一个Elasticsearch 索引 是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片(Lucene 索引)，然后合并每个分片的结果到一个全局的结果集。（即Elasticsearch 索引 是分片的集合，Lucene 索引在Elasticsearch 称作 分片）</p><p>副本（Replicas）：在一个网络 / 云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch 允许你创建分片的一份或多份拷贝，这些拷贝叫做复<br>制分片(副本)。</p><p>复制分片之所以重要，有两个主要原因：</p><p> 在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。</p><p> 扩展你的搜索量/吞吐量，因为搜索可以在所有的副本上并行运行。</p><p>总之，每个索引可以被分成多个分片。一个索引也可以被复制 0 次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可<br>以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。默认情况下，Elasticsearch 中的每个索引被分片 1 个主分片和 1 个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有 1 个主分片和另外 1 个复制分片（1 个完全拷贝），这样的话每个索引总共就有 2 个分片，我们需要根据索引需要确定分片个数。</p><p>分配（Allocation）：将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分<br>片复制数据的过程。这个过程是由 master 节点完成的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Elasticsearch 索引的精髓：一切设计都是为了提高搜索的性能。&lt;/p&gt;
&lt;p&gt;Elasticsearch的索引就是一个拥有相似特征的文档的集合。一个索引由一个名字来标识（必须全是小写字母）。&lt;br&gt;当我们要对这个索引中的文档进行索引、搜索、更新和删除的时候，都要使</summary>
      
    
    
    
    <category term="Elasticsearch" scheme="http://example.com/categories/Elasticsearch/"/>
    
    
    <category term="基础概念" scheme="http://example.com/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"/>
    
    <category term="Elasticsearch" scheme="http://example.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>时间轮算法</title>
    <link href="http://example.com/2022/03/13/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2022/03/13/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95/</id>
    <published>2022-03-13T05:08:00.000Z</published>
    <updated>2022-03-13T05:18:08.769Z</updated>
    
    <content type="html"><![CDATA[<p>时间轮就是和手表时钟很相似的存在。时间轮用环形数组实现，数组的每个元素可以称为槽，和 HashMap一样称呼。</p><p>槽的内部用双向链表存着待执行的任务，添加和删除的链表操作时间复杂度都是 O(1)，槽位本身也指代时间精度，比如一秒扫一个槽，那么这个时间轮的最高精度就是 1 秒。</p><p>也就是说延迟 1.2 秒的任务和 1.5 秒的任务会被加入到同一个槽中，然后在 1 秒的时候遍历这个槽中的链表执行任务。</p><p> <img src="/images/pasted-157.png" alt="upload successful"></p><p>从图中可以看到此时指针指向的是第一个槽，一共有八个槽0~7，假设槽的时间单位为 1 秒，现在要加入一个延时 5 秒的任务，计算方式就是 5 % 8 + 1 = 6，即放在槽位为 6，下标为 5 的那个槽中。</p><p>更具体的就是拼到槽的双向链表的尾部。然后每秒指针顺时针移动一格，这样就扫到了下一格，遍历这格中的双向链表执行任务。然后再循环继续。</p><p>可以看到插入任务从计算槽位到插入链表，时间复杂度都是O(1)。那假设现在要加入一个50秒后执行的任务怎么办？这槽好像不够啊？难道要加槽嘛？和HashMap一样扩容？</p><p>不是的，常见有两种方式，一种是通过增加轮次的概念。50 % 8 + 1 = 3，即应该放在槽位是 3，下标是2 的位置。然后 (50 - 1) / 8 = 6，即轮数记为 6。也就是说当循环 6 轮之后扫到下标的 2 的这个槽位会触发这个任务。Netty中HashedWheelTimer 使用的就是这种方式。</p><p>还有一种是通过多层次的时间轮，这个和我们的手表就更像了，像我们秒针走一圈，分针走一格，分针走一圈，时针走一格。</p><p>多层次时间轮就是这样实现的。假设上图就是第一层，那么第一层走了一圈，第二层就走一格，可以得知第二层的一格就是8秒，假设第二层也是 8 个槽，那么第二层走一圈，第三层走一格，可以得知第三层一格就是 64 秒。那么一格三层，每层8个槽，一共 24 个槽时间轮就可以处理最多延迟 512 秒的任<br>务。</p><p>而多层次时间轮还会有降级的操作，假设一个任务延迟 500 秒执行，那么刚开始加进来肯定是放在第三层的，当时间过了 436 秒后，此时还需要 64 秒就会触发任务的执行，而此时相对而言它就是个延迟 64秒后的任务，因此它会被降低放在第二层中，第一层还放不下它。再过个 56 秒，相对而言它就是个延迟 8 秒后执行的任务，因此它会再被降级放在第一层中，等待执行。</p><p>降级是为了保证时间精度一致性Kafka内部用的就是多层次的时间轮算法。</p><p>Kafka 就利用了空间换时间的思想，通过 DelayQueue，来保存每个槽，通过每个槽的过期时间排序。这样拥有最早需要执行任务的槽会有优先获取。如果时候未到，那么 delayQueue.poll 就会阻塞着，这样就不会有空推进的情况发送。</p><p>总的来说Kafka用了多层次时间轮来实现，并且是按需创建时间轮，采用任务的绝对时间来判断延期，并且对于每个槽(槽内存放的也是任务的双向链表)都会维护一个过期时间，利用 DelayQueue 来对每个槽的过期<br>时间排序，来进行时间的推进，防止空推进的存在。</p><p>每次推进都会更新 currentTime 为当前时间戳，当然做了点微调使得 currentTime 是 tickMs 的整数<br>倍。并且每次推进都会把能降级的任务重新插入降级。</p><p>可以看到这里的 DelayQueue 的元素是每个槽，而不是任务，因此数量就少很多了，这应该是权衡了对于槽操作的延时队列的时间复杂度与空推进的影响。</p><p>总结：</p><p>Timer、DelayQueue 和 ScheduledThreadPool，它们都是基于优先队列实现的，O(logn)<br>的时间复杂度在任务数多的情况下频繁的入队出队对性能来说有损耗。因此适合于任务数不多的情况。</p><p>Timer 是单线程的会有阻塞的风险，并且对异常没有做处理，一个任务出错 Timer 就挂了。而<br>ScheduledThreadPool 相比于 Timer 首先可以多线程来执行任务，并且线程池对异常做了处理，使得任务之间不会有影响。</p><p>并且 Timer和ScheduledThreadPool 可以周期性执行任务。 而 DelayQueue 就是个具有优先级的阻塞队列。</p><p>对比而言时间轮更适合任务数很大的延时场景，它的任务插入和删除时间复杂度都为O(1)。对于延迟超过时间轮所能表示的范围有两种处理方式，一是通过增加一个字段-轮数，Netty 就是这样实现的。二是多层次时间轮，Kakfa 是这样实现的。</p><p>相比而言 Netty 的实现会有空推进的问题，而 Kafka 采用 DelayQueue 以槽为单位，利用空间换时间的思想解决了空推进的问题。</p><p>可以看出延迟任务的实现都不是很精确的，并且或多或少都会有阻塞的情况，即使你异步执行，线程不够的情况下还是会阻塞。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;时间轮就是和手表时钟很相似的存在。时间轮用环形数组实现，数组的每个元素可以称为槽，和 HashMap一样称呼。&lt;/p&gt;
&lt;p&gt;槽的内部用双向链表存着待执行的任务，添加和删除的链表操作时间复杂度都是 O(1)，槽位本身也指代时间精度，比如一秒扫一个槽，那么这个时间轮的最高精度</summary>
      
    
    
    
    <category term="算法" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="Kafka" scheme="http://example.com/categories/%E7%AE%97%E6%B3%95/Kafka/"/>
    
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="时间轮" scheme="http://example.com/tags/%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>延迟队列 DelayQueue</title>
    <link href="http://example.com/2022/03/13/%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97-DelayQueue/"/>
    <id>http://example.com/2022/03/13/%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97-DelayQueue/</id>
    <published>2022-03-13T05:05:00.000Z</published>
    <updated>2022-03-13T05:07:25.947Z</updated>
    
    <content type="html"><![CDATA[<p>Java 中还有个延迟队列 DelayQueue，加入延迟队列的元素都必须实现 Delayed 接口。延迟队列内部是利用 PriorityQueue 实现的，所以还是利用优先队列！Delayed 接口继承了Comparable 因此优先队<br>列是通过 delay 来排序的。</p><p>延迟队列是利用优先队列实现的，元素通过实现 Delayed 接口来返回延迟的时间。不过延迟队列就是个容<br>器，需要其他线程来获取和执行任务。</p><p>对于 Timer 、ScheduledThreadPool 和 DelayQueue，总结的说下它们都是通过优先队列来获取最早需要执行的任务，因此插入和删除任务的时间复杂度都为O(logn)，并且 Timer 、<br>ScheduledThreadPool 的周期性任务是通过重置任务的下一次执行时间来完成的。</p><p>问题就出在时间复杂度上，插入删除时间复杂度是O(logn)，那么假设频繁插入删除次数为 m，总的时<br>间复杂度就是O(mlogn)，这种时间复杂度满足不了 Kafka 这类中间件对性能的要求，而时间轮算法的插入删除时间复杂度是O(1)。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Java 中还有个延迟队列 DelayQueue，加入延迟队列的元素都必须实现 Delayed 接口。延迟队列内部是利用 PriorityQueue 实现的，所以还是利用优先队列！Delayed 接口继承了Comparable 因此优先队&lt;br&gt;列是通过 delay 来排序</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="DelayQueue" scheme="http://example.com/tags/DelayQueue/"/>
    
    <category term="队列" scheme="http://example.com/tags/%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
</feed>
