<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-07-09T12:13:44.655Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hashCode 的计算逻辑中，为什么是 31 作为乘数？</title>
    <link href="http://example.com/2022/07/09/hashCode-%E7%9A%84%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E4%B8%AD%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-31-%E4%BD%9C%E4%B8%BA%E4%B9%98%E6%95%B0%EF%BC%9F/"/>
    <id>http://example.com/2022/07/09/hashCode-%E7%9A%84%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E4%B8%AD%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-31-%E4%BD%9C%E4%B8%BA%E4%B9%98%E6%95%B0%EF%BC%9F/</id>
    <published>2022-07-09T12:01:00.000Z</published>
    <updated>2022-07-09T12:13:44.655Z</updated>
    
    <content type="html"><![CDATA[<p> <img src="/images/pasted-241.png" alt="upload successful"><br> 在获取 hashCode 的源码中可以看到，有一个固定值 31，在 for 循环每次执行时<br>进行乘积计算，循环后的公式如下； s[0]*31^(n-1) + s[1]*31^(n-2) + … +<br>s[n-1]<br>那么这里为什么选择 31 作为乘积值呢？</p><ol><li>31 是一个奇质数，如果选择偶数会导致乘积运算时数据溢出。</li><li>另外在二进制中，2 个 5 次方是 32，那么也就是 31 * i == (i &lt;&lt; 5) - i。这主要是说乘积运算可以使用位移提升性能，同时目前的 JVM 虚拟机也会自动支持此类的优化。</li><li>经过大量测试，相对于其他数，31得到的hash碰撞结果最小</li></ol><p>当然一个好的哈希函数除了要尽量减少碰撞外，关于散列表也就是 hash，<br>还有一个非常重要的点，那就是要尽可能的让数据散列分布。只有这样才能减少<br>hash 碰撞次数。</p><h3 id="扰动函数"><a href="#扰动函数" class="headerlink" title="扰动函数"></a>扰动函数</h3><p>在 HashMap 存放元素时候有这样一段代码来处理哈希值，这是 java 8 的散列值<br>扰动函数，用于优化散列效果；</p><p> <img src="/images/pasted-242.png" alt="upload successful"></p><p> 理论上来说字符串的 hashCode是一个 int 类型值，那可以直接作为数组下标了，<br>且不会出现碰撞。但是这个 hashCode 的取值范围是[-2147483648, 2147483647]，<br>有将近 40 亿的长度，谁也不能把数组初始化的这么大，内存也是放不下的。</p><p>我们默认初始化的 Map 大小是 16 个长度 DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4，<br>所以获取的 Hash 值并不能直接作为下标使用，需要与数组长度进行取模运算得<br>到一个下标值，也就是我们上面做的散列列子。</p><p>那么，hashMap 源码这里不只是直接获取哈希值，还进行了一次扰动计算，(h =<br>key.hashCode()) ^ (h &gt;&gt;&gt; 16)。把哈希值右移 16 位，也就正好是自己长度的一<br>半，之后与原哈希值做异或运算，这样就混合了原哈希值中的高位和低位，增大<br>了随机性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;img src=&quot;/images/pasted-241.png&quot; alt=&quot;upload successful&quot;&gt;&lt;br&gt; 在获取 hashCode 的源码中可以看到，有一个固定值 31，在 for 循环每次执行时&lt;br&gt;进行乘积计算，循环后的公式如下； s[0]*31</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="HashMap" scheme="http://example.com/tags/HashMap/"/>
    
  </entry>
  
  <entry>
    <title>Thread.start（）启动原理</title>
    <link href="http://example.com/2022/07/09/Thread-start%EF%BC%88%EF%BC%89%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2022/07/09/Thread-start%EF%BC%88%EF%BC%89%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86/</id>
    <published>2022-07-09T09:00:00.000Z</published>
    <updated>2022-07-09T10:52:32.322Z</updated>
    
    <content type="html"><![CDATA[<p>java中启动一个线程很简单</p><p>new Thread(()-&gt;{</p><p>// TODD</p><p>}).start();</p><p>但是这个线程是如何启动起来的呢？主要会经过下面这个流程</p><p> <img src="/images/pasted-237.png" alt="upload successful"></p><ol><li>线程的启动涉及到本地方法JNI的调用</li><li>具体的线程是映射到操作系统层面由操作系统处理</li><li>线程的启动涉及到线程的生命周期状态以及唤醒操作，所有有回调操作run()</li></ol><p>具体的UML图如下<br> <img src="/images/pasted-238.png" alt="upload successful"></p><h3 id="Java-层面-Thread-启动"><a href="#Java-层面-Thread-启动" class="headerlink" title="Java 层面 Thread 启动"></a>Java 层面 Thread 启动</h3><p>new Thread(() -&gt; {</p><p>// todo</p><p>}).start();</p><p>// JDK 源码</p><p>public synchronized void start() {</p><p>if (threadStatus != 0)</p><p>throw new IllegalThreadStateException();</p><p>group.add(this);</p><p>boolean started = false;</p><p>try {</p><p>start0();</p><p>started = true;</p><p>} finally {</p><p>try {</p><p>if (!started) {</p><p>group.threadStartFailed(this);</p><p>} } catch (Throwable ignore) {}</p><p>} }</p><p> 线程启动方法 start()，在它的方法英文注释中已经把核心内容描述出来。<br>Causes this thread to begin execution; the Java Virtual<br>Machine calls the run method of this thread. 这段话的意思<br>是：由 JVM 调用此线程的 run 方法，使线程开始执行。其实这就是一个 JVM 的<br>回调过程，下文源码分析中会讲到</p><p> 另外 start() 是一个 synchronized 方法，但为了避免多次调用，在方法中<br>会由线程状态判断。threadStatus != 0。 </p><p> group.add(this)，是把当前线程加入到线程组，ThreadGroup。 </p><p> start0()，是一个本地方法，通过 JNI 方式调用执行。这一步的操作才是启动<br>线程的核心步骤。</p><p> <img src="/images/pasted-239.png" alt="upload successful"></p><p> start0()，是一个本地方法，用于启动线程。</p><p> registerNatives()，这个方法是用于注册线程执行过程中需要的一些本地方<br>法，比如：start0、isAlive、yield、sleep、interrupt0 等。</p><p>后面线程的启动过程涉及到了 JVM 的参与，整个源码分析可以结合着代码调用 UML 时序图进行观看，基本核心过程包括：<br>Java 创建线程和启动、调用本地方法 start0()、JVM 中<br>JVM_StartThread 的创建和启动、设置线程状态等待被唤醒、根据不同<br>的 OS 启动线程并唤醒、最后回调 run() 方法启动 Java 线程</p><p>待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;java中启动一个线程很简单&lt;/p&gt;
&lt;p&gt;new Thread(()-&amp;gt;{&lt;/p&gt;
&lt;p&gt;// TODD&lt;/p&gt;
&lt;p&gt;}).start();&lt;/p&gt;
&lt;p&gt;但是这个线程是如何启动起来的呢？主要会经过下面这个流程&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="线程" scheme="http://example.com/tags/%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>打破双亲委派机制的一些场景</title>
    <link href="http://example.com/2022/07/05/%E6%89%93%E7%A0%B4%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF/"/>
    <id>http://example.com/2022/07/05/%E6%89%93%E7%A0%B4%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF/</id>
    <published>2022-07-05T11:42:00.000Z</published>
    <updated>2022-07-05T12:29:39.462Z</updated>
    
    <content type="html"><![CDATA[<p>前言：在说打破双亲委派机制的一些场景前，先聊一聊为什么需要双亲委派机制。</p><p>在双亲委派机制中，父子类通过组合的方式聚合在一起。由应用类加载器开始到系统类加器。主要是这几步：</p><ol><li>在自身的loadclass方法中先检查类是否已经被加载过</li><li>若没有加载则调用父类加载器的loadclass方法加载，若父类为空则默认用启动类加载器作为父加载器加载。</li><li>如果父类加载器失败，抛出异常classnotfoundexception后，调用自身的findclass方法进行加载类</li></ol><p>这样做的好处是一方面可以避免类的重复加载，当父类加载器已经加载过这个类时，子类不会再去加载。另一方面，通过这样的方式可以保证安全性。因为引导类加载在加载的时候只会加载JAVA_HOME的jar包，这个类及时被同名的类破坏也不会有影响，除非你本地jdk的jar被改写。即可以有效的防止核心java api被篡改。</p><p>而既然知道了双亲委派机制的实现，那么想要破坏双亲委派机制就简单了。只需要自定义一个类加载器，重写其中的loadclass方法，使其不进行双亲委派机制。而如果我们要自定义一个类加载器而又不想破坏双亲委派机制，只需集成classloader然后重写findclass方法。</p><p>而在某些场景下，我们却需要去打破双亲委派机制，比如我下面将要提到的几种</p><h3 id="JNDI、JDBC等"><a href="#JNDI、JDBC等" class="headerlink" title="JNDI、JDBC等"></a>JNDI、JDBC等</h3><p>在我们通过API调用一些java的基类时，存在一种SPI机制。比如JDBC。在类加载时，会先加载驱动DriverManger类，该类由类加载器加载。因为java.sql.DriverManger类位于rt.jar下面，会被根类加载器加载。而在其加载时，会执行静态方法，静态方法会尝试加载classpath下的所有实现driver接口的类。但这些实现类基本由各大数据库厂商实现，如果根据双亲委派机制来执行时行不通的。因为第三方的类不能被根加载器加载。因此，在jdbc中引入了线程上下文加载器的方式破坏双亲委派机制。</p><h3 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h3><p>在tomcat中为了应用程序访问不同存储库中的类和资源，达到应用类之间隔离的目的，打破了双亲委派机制。即为给个容器单独提供一个WebAppClassLoader加载器（优先加载web应用自身的类，即优先由WebAppClassLoader加载，加载不到在由CommonClassLoader加载，这和双亲委派刚好相反）。</p><p>Tomcat整体类加载器结构如下：<br> <img src="/images/pasted-235.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前言：在说打破双亲委派机制的一些场景前，先聊一聊为什么需要双亲委派机制。&lt;/p&gt;
&lt;p&gt;在双亲委派机制中，父子类通过组合的方式聚合在一起。由应用类加载器开始到系统类加器。主要是这几步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在自身的loadclass方法中先检查类是否已经被加载过&lt;/l</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="类加载机制" scheme="http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
    
    <category term="双亲委派机制" scheme="http://example.com/tags/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>Spring编程式事务</title>
    <link href="http://example.com/2022/06/17/Spring%E7%BC%96%E7%A8%8B%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2022/06/17/Spring%E7%BC%96%E7%A8%8B%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2022-06-17T08:55:00.000Z</published>
    <updated>2022-06-17T12:43:17.962Z</updated>
    
    <content type="html"><![CDATA[<p>描述：今天在做项目实现活动领取功能模块时，考虑到在系统中，用户的领取次数表和领取活动表的后续开销问题，在设计时通过自研的分库分表db-router-Spring-boot-starter组件对该功能涉及的两张表进行了分库操作。即让不同uid的用户产生的领取活动信息和活动次数信息打到不同的数据库上，减轻数据库的压力。但在后续开发时，发现涉及到两张表的修改，而这里又用到了分库操作，对数据源进行了切换。导致常用的@trancation注解在这里并不适用。为此，去温习了一下编程式事务，用于解决此处的问题。在这里记录一下。</p><p>编程式事务主要有2种用法</p><ul><li>方式1：通过PlatformTransactionManager控制事务</li><li>方式2：通过TransactionTemplate控制事务</li></ul><h3 id="方式1：PlatformTransactionManager"><a href="#方式1：PlatformTransactionManager" class="headerlink" title="方式1：PlatformTransactionManager"></a>方式1：PlatformTransactionManager</h3><ol><li>定义事务管理器PlatformTransactionManager<br>（事务管理器相当于一个管理员，这个管理员就是用来帮你控制事务的，比如开启事务，提交事务，回滚事务等等。spring中使用PlatformTransactionManager这个接口来表示事务管理器，PlatformTransactionManager多个实现类，用来应对不同的环境<br>）</li></ol><ul><li><p>JpaTransactionManager：如果你用jpa来操作db，那么需要用这个管理器来帮你控制事务。</p></li><li><p>DataSourceTransactionManager：如果你用是指定数据源的方式，比如操作数据库用的是：JdbcTemplate、mybatis、ibatis，那么需要用这个管理器来帮你控制事务。</p></li><li><p>HibernateTransactionManager：如果你用hibernate来操作db，那么需要用这个管理器来帮你控制事务。</p></li><li><p>JtaTransactionManager：如果你用的是java中的jta来操作db，这种通常是分布式事务，此时需要用这种管理器来控制事务。<br><img src="/images/pasted-234.png" alt="upload successful"></p></li></ul><ol start="2"><li><p>定义事务属性TransactionDefinition：定义事务属性，比如事务隔离级别、事务超时时间、事务传播方式、是否是只读事务等等。spring中使用TransactionDefinition接口来表示事务的定义信息，有个子类比较常用：DefaultTransactionDefinition。</p></li><li><p>开启事务：调用事务管理器的getTransaction方法，即可以开启一个事务，这个方法会返回一个TransactionStatus表示事务状态的一个对象，通过TransactionStatus提供的一些方法可以用来控制事务的一些状态，比如事务最终是需要回滚还是需要提交。（执行了getTransaction后，spring内部会执行一些操作。将数据源datasource和connection映射起来放在了ThreadLocal中。通过resources这个ThreadLocal获取datasource其对应的connection对象）</p></li><li><p>执行业务操作：用同一个dataSource，而事务管理器开启事务的时候，会创建一个连接，将datasource和connection映射之后丢在了ThreadLocal中，而JdbcTemplate内部执行db操作的时候，也需要获取连接，JdbcTemplate会以自己内部的datasource去上面的threadlocal中找有没有关联的连接，如果有直接拿来用，若没找到将重新创建一个连接，而此时是可以找到的，那么JdbcTemplate就参与到spring的事务中了。</p></li><li><p>提交或回滚</p></li></ol><p>分析：</p><p>TransactionTemplate，主要有2个方法：</p><p>executeWithoutResult：无返回值场景</p><p>executeWithoutResult(Consumer<TransactionStatus> action)：没有返回值的，需传递一个Consumer对象，在accept方法中做业务操作</p><p>execute：有返回值场景</p><p><T> T execute(TransactionCallback<T> action)：有返回值的，需要传递一个TransactionCallback对象，在doInTransaction方法中做业务操作</p><p>  通过上面2个方法，事务管理器会自动提交事务或者回滚事务。</p><p>什么时候事务会回滚，有2种方式</p><p>方式1</p><p>在execute或者executeWithoutResult内部执行transactionStatus.setRollbackOnly();将事务状态标注为回滚状态，spring会自动让事务回滚</p><p>方式2</p><p>execute方法或者executeWithoutResult方法内部抛出任意异常即可回滚。</p><p>总结：平时我们用的最多的是声明式事务，声明式事务的底层还是使用上面这种方式来控制事务的，只不过对其进行了封装，让我们用起来更容易些。了解不同的方法有助于我们在不同的场景的应用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;描述：今天在做项目实现活动领取功能模块时，考虑到在系统中，用户的领取次数表和领取活动表的后续开销问题，在设计时通过自研的分库分表db-router-Spring-boot-starter组件对该功能涉及的两张表进行了分库操作。即让不同uid的用户产生的领取活动信息和活动次数</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
    <category term="Spring" scheme="http://example.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>误删数据库后除了跑路，还能怎么办？</title>
    <link href="http://example.com/2022/06/15/%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/"/>
    <id>http://example.com/2022/06/15/%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/</id>
    <published>2022-06-15T14:23:00.000Z</published>
    <updated>2022-06-15T15:43:59.602Z</updated>
    
    <content type="html"><![CDATA[<p>传统的高可用架构是不能预防误删除数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。</p><p>为了找到解决误删数据库的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：</p><ol><li>使用delete语句误删数据行</li><li>使用drop table或者truncate table语句误删数据库</li><li>使用drop database语句误删数据库</li><li>使用rm命令误删整个MySQL实例</li></ol><h3 id="误删行"><a href="#误删行" class="headerlink" title="误删行"></a>误删行</h3><p>方案：使用delete语句误删了数据行，可以用Flashback工具通过闪回把数据恢复回来。</p><p>原理：修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row和binlog_row_image=FULL。</p><p>具体：</p><ol><li>对于insert语句，对应的binlog event类型是Write_rows event，把它改成Delete_rows event即可。</li><li>同理，对于delete语句，也是将Delete_rows event改为Write_rows event。</li><li>而如果是Update_rows的话,binlog里面记录了数据行修改前和修改后的值,对调这两行的位置即可。</li></ol><p>而对于误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。</p><p>当然恢复过程并不建议在主库上进行，而是恢复出一个备份，或者找一个从库作为临时库，在临时库上执行恢复操作，确认过数据无误后，在恢复回主库。（原因：一个在执行线上逻辑的主库，数据状态往往是有关联的。可能由于发现数据问题的实际晚了一点，就导致已经在之前误删的基础上，业务代码逻辑又继续修改了其他数据，如果这时进行数据恢复，未经确认，会导致出现对数据的二次破坏）</p><pre><code>    注意：不止要了解误删数据的事后处理方法，更重要的是做到事前预防。    建议：    1. 把sql_safe_updates参数设置成on，在delete或者update语句中写where，或者where条件不包含索引字段，这条语句就会报错。    2. 代码上线前，必须经过SQL审计</code></pre><h3 id="误删库-表"><a href="#误删库-表" class="headerlink" title="误删库/表"></a>误删库/表</h3><p>这种情况下，想要恢复数据就需要使用全量备份了，加增量日志的方式。这个方案要求线上定期的全量备份，并且实时备份binlog（因为对于drop/turncate table/database binlog记录的是statement格式，没法通过flasback进行恢复）</p><p>恢复数据的流程：</p><ol><li>取最近一次全量备份（假设是一天一备，上次备份是当天0点）</li><li>用备份恢复出一个临时库</li><li>从日志备份里面，取出凌晨0点之后的日志</li><li>把这些日志，除了误删除数据的语句外，全部应用到临时库</li></ol><p>说明：为了加速数据恢复，可以在mysqlbinlog加上-database，用来指定误删除表所在的库，但是这样还是不够快（1.误删表，不能指定解析一个表的日志；2.用mysqlbinlog解析出日志应用，应用日志的过程就只能是单线程）</p><p>误删库或表后，恢复数据的思路主要就是通过备份，再加上应用binlog的方式。最好把数据恢复功能做成自动化工具。</p><h3 id="延迟复制备库"><a href="#延迟复制备库" class="headerlink" title="延迟复制备库"></a>延迟复制备库</h3><p>延迟复制备库是一种特殊的备库，通过CHANGE MASTER TO_DELAY = N命令，可以指定这个备库持续保持主库有N秒的延迟。</p><h3 id="预防误删库表的方法"><a href="#预防误删库表的方法" class="headerlink" title="预防误删库表的方法"></a>预防误删库表的方法</h3><ul><li>账号分离，权限控制</li><li>制定操作规范</li><li>定期给开发进行培训</li><li>搭建延迟备库</li><li>做好sql审计</li><li>做好备份</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;传统的高可用架构是不能预防误删除数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。&lt;/p&gt;
&lt;p&gt;为了找到解决误删数据库的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：&lt;/p&gt;</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>关于ZAB协议</title>
    <link href="http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EZAB%E5%8D%8F%E8%AE%AE/"/>
    <id>http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EZAB%E5%8D%8F%E8%AE%AE/</id>
    <published>2022-05-25T14:02:00.000Z</published>
    <updated>2022-05-25T14:19:02.540Z</updated>
    
    <content type="html"><![CDATA[<p>Zab 借鉴了 Paxos 算法，是特别为 Zookeeper 设计的支持崩溃恢复的原子广播协议。基于该协议，Zookeeper 设计为只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader 客户端将数据同步到其他 Follower 节点。Zookeeper 只有一个 Leader 可以发起提案</p><p>Zab协议包括两种基本的模式：消息广播、崩溃恢复。</p><h3 id="消息广播"><a href="#消息广播" class="headerlink" title="消息广播"></a>消息广播</h3><p>ZAB协议针对事务请求的处理过程类似于一个两阶段提交过程</p><p>（1）广播事务阶段</p><p>（2）广播提交操作<br>这两阶段提交模型如下，有可能因为Leader宕机带来数据不一致，比如</p><p>（1） Leader 发 起 一 个 事 务Proposal1 后 就 宕 机 ， Follower 都 没有Proposal1 </p><p>（2）Leader收到半数ACK宕 机，没来得及向Follower发送Commit<br>怎么解决呢？ZAB引入了崩溃恢复模式。</p><p> <img src="/images/pasted-231.png" alt="upload successful"></p><p>（1）客户端发起一个写操作请求。 </p><p>（2）Leader服务器将客户端的请求转化为事务Proposal 提案，同时为每个Proposal 分配一个全局的ID，即zxid。 </p><p>（3）Leader服务器为每个Follower服务器分配一个单独的队列，然后将需要广播的 Proposal依次放到队列中去，并且根据FIFO策略进行消息发送。 </p><p>（4）Follower接收到Proposal后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向Leader反馈一个Ack响应消息。 </p><p>（5）Leader接收到超过半数以上Follower的Ack响应消息后，即认为消息发送成功，可以发送commit消息。 </p><p>（6）Leader向所有Follower广播commit消息，同时自身也会完成事务提交。Follower 接收到commit消息后，会将上一条事务提交。 </p><p>（7）Zookeeper采用Zab协议的核心，就是只要有一台服务器提交了Proposal，就要确保所有的服务器最终都能正确提交Proposal。</p><h3 id="崩溃恢复——异常假设"><a href="#崩溃恢复——异常假设" class="headerlink" title="崩溃恢复——异常假设"></a>崩溃恢复——异常假设</h3><p> 一旦Leader服务器出现崩溃或者由于网络原因导致Leader服务器失去了与过半 Follower的联系，那么就会进入崩溃恢复模式。</p><p> <img src="/images/pasted-232.png" alt="upload successful"></p><p> 假设两种服务器异常情况</p><ol><li>假设一个事务在Leader提出之后，Leader挂了</li><li>一个事务在Leader上提交了，并且过半的Follower都响应ACK了，但是Leader在Commit消息发出之前挂了。</li></ol><p> Zab协议崩溃恢复要满足以下两个要求</p><p> 1、 确保已经被Leader提交的提案Proposal，必须最终被所有的Follower服务器提交。 （已经产生的提案，Follower必须执行） </p><p> 2、 确保丢弃已经被Leader提出的，但是没有被提交的Proposal。（丢弃胎死腹中的提案）</p><p> 崩溃恢复主要包括两部分：Leader选举和数据恢复。</p><h3 id="崩溃恢复—Leader选举"><a href="#崩溃恢复—Leader选举" class="headerlink" title="崩溃恢复—Leader选举"></a>崩溃恢复—Leader选举</h3><p> <img src="/images/pasted-233.png" alt="upload successful"></p><p>Leader选举：根据上述要求，Zab协议需要保证选举出来的Leader需要满足以下条件：</p><p>（1）新选举出来的Leader不能包含未提交的Proposal。即新Leader必须都是已经提交了Proposal的Follower服务器节点。</p><p>（2）新选举的Leader节点中含有最大的zxid。这样做的好处是可以避免Leader服务器检查Proposal的提交和丢弃工作。</p><h3 id="崩溃恢复——数据恢复"><a href="#崩溃恢复——数据恢复" class="headerlink" title="崩溃恢复——数据恢复"></a>崩溃恢复——数据恢复</h3><p>Zab如何数据同步： </p><p>（1）完成Leader选举后，在正式开始工作之前（接收事务请求，然后提出新的Proposal），Leader服务器会首先确认事务日志中的所有的Proposal 是否已经被集群中过半的服务器Commit。</p><p>（2）Leader服务器需要确保所有的Follower服务器能够接收到每一条事务的Proposal，并且能将所有已经提交的事务Proposal应用到内存数据中。等到Follower将所有尚未同步的事务Proposal都从Leader服务器上同步过，并且应用到内存数据中以后，<br>Leader才会把该Follower加入到真正可用的Follower列表中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Zab 借鉴了 Paxos 算法，是特别为 Zookeeper 设计的支持崩溃恢复的原子广播协议。基于该协议，Zookeeper 设计为只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader 客户端将数据同步到其他 Follower 节点。Zookeepe</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="ZAB协议" scheme="http://example.com/tags/ZAB%E5%8D%8F%E8%AE%AE/"/>
    
    <category term="数据一致性" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>关于Paxos算法</title>
    <link href="http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EPaxos%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EPaxos%E7%AE%97%E6%B3%95/</id>
    <published>2022-05-25T13:38:00.000Z</published>
    <updated>2022-05-25T13:59:20.676Z</updated>
    
    <content type="html"><![CDATA[<p>Paxos算法是一种基于消息传递且具有高度容错特性的一致性算法。其通常用于快速正确的在一个分布式系统中对某个数据值达成一致，并且保证无论发送任何异常都不会破坏整个系统的一致性。</p><p> <img src="/images/pasted-226.png" alt="upload successful"></p><p> 在一个Paxos系统中，首先将所有节点划分为Proposer（提议者）、Acceptor（接受者）和Learner（学习者）</p><pre><code>     注意：每个节点可以身兼数职    </code></pre><p>一个完整的Paxos算法流程分为三个阶段</p><ol><li><p>Prepare准备阶段</p><ol><li>Proposer向多个Acceptor发出Propose请求Promise（承诺）</li><li>Acceptor针对收到的Propose请求进行Promise（承诺）</li></ol></li><li><p>Accept接受阶段</p><ol><li>Proposer收到多数Acceptor承诺的Promise后，向Acceptor发出Propose请求</li><li>Acceptor针对收到的Propose请求进行Accept处理</li></ol></li><li><p>Learn学习阶段</p><ol><li>Proposer将形成的决议发送给所有Learners</li></ol></li></ol><p> <img src="/images/pasted-227.png" alt="upload successful"></p><p> 1、 Prepare: Proposer生成全局唯一且递增的Proposal ID，向所有Acceptor发送Propose请求，这里无需携带提案内容，只携带Proposal ID即可。</p><p> 2、 Promise: Acceptor收到Propose请求后，做出“两个承诺，一个应答”。<br>    - 不再接受Proposal ID小于等于（注意：这里是&lt;= ）当前请求的Propose请求。<br>    - 不再接受Proposal ID小于（注意：这里是&lt; ）当前请求的Accept请求。<br>    - 不违背以前做出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。</p><p>3、 Propose: Proposer收到多数Acceptor的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptor发送Propose请求。</p><p>4、 Accept: Acceptor收到Propose请求后，在不违背自己之前做出的承诺下，接受并持久化当前Proposal ID和提案Value。</p><p>5、 Learn: Proposer收到多数Acceptor的Accept后，决议形成，将形成的决议发送给所有Learner。</p><p>下面举例以说明：</p><ol><li>情况1：</li></ol><p> <img src="/images/pasted-228.png" alt="upload successful"></p><ul><li>有A1, A2, A3, A4, A5 5位议员，就税率问题进行决议。</li><li>A1发起1号Proposal的Propose，等待Promise承诺； </li><li>A2-A5回应Promise； </li><li>A1在收到两份回复时就会发起税率10%的Proposal； </li><li>A2-A5回应Accept； </li><li>通过Proposal，税率10%。</li></ul><ol start="2"><li>情况2：</li></ol><p> <img src="/images/pasted-229.png" alt="upload successful"><br>     - 现在我们假设在A1提出提案的同时, A5决定将税率定为20%<br>     - A2承诺A1，A4承诺A5，A3行为成为关键<br>     - 情况1：A3先收到A1消息，承诺A1。<br>     - A1发起Proposal（1，10%），A2，A3接受。<br>     - 之后A3又收到A5消息，回复A1：（1，10%），并承诺A5<br>     - A5发起Proposal（2，20%），A3，A4接受。之后A1，A5同时广播决议。</p><pre><code>    由此可见Paxos 算法缺陷：在网络复杂的情况下，一个应用 Paxos 算法的分布式系统，可能很久无法收敛，甚至陷入活锁的情况。</code></pre><ol start="3"><li>情况3：</li></ol><p> <img src="/images/pasted-230.png" alt="upload successful"></p><pre><code> - 现在我们假设在A1提出提案的同时, A5决定将税率定为20% - A1，A5同时发起Propose（序号分别为1，2） - A2承诺A1，A4承诺A5，A3行为成为关键 - 情况2：A3先收到A1消息，承诺A1。之后立刻收到A5消息，承诺A5。 - A1发起Proposal（1，10%），无足够响应，A1重新Propose （序号3），A3再次承诺A1。 - A5发起Proposal（2，20%），无足够相应。A5重新Propose （序号4），A3再次承诺A5。</code></pre><p> 造成这种情况的原因是系统中有一个以上的 Proposer，多个 Proposers 相互争夺 Acceptor，造成迟迟无法达成一致的情况。针对这种情况，一种改进的 Paxos 算法被提出：从系统中选出一个节点作为 Leader，只有 Leader 能够发起提案。这样，一次 Paxos 流程中只有一个Proposer，不会出现活锁的情况，此时只会出现例子中第一种情况。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Paxos算法是一种基于消息传递且具有高度容错特性的一致性算法。其通常用于快速正确的在一个分布式系统中对某个数据值达成一致，并且保证无论发送任何异常都不会破坏整个系统的一致性。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-226.png&quot; alt=&quot;u</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="Paxos" scheme="http://example.com/tags/Paxos/"/>
    
    <category term="一致性算法" scheme="http://example.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper选举机制</title>
    <link href="http://example.com/2022/05/25/Zookeeper%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2022/05/25/Zookeeper%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/</id>
    <published>2022-05-25T12:24:00.000Z</published>
    <updated>2022-05-25T12:40:27.471Z</updated>
    
    <content type="html"><![CDATA[<p>在了解Zookeeper的选举机制之前，首先需要了解</p><ul><li>SID(服务器ID，用于唯一标识一台Zookeeper集群中的机器，每台机器不能重复，和myid一致)</li><li>ZXID（事务ID。用来标识一次服务器状态的变更。在某一时刻，集群中的每台机器的ZXID值不一定完全一致，这和Zookeeper服务器对于客户端“更新请求”的处理逻辑有关）</li><li>Epoch(每个Leader任期的代号。没有Leader时同一轮投票过程中的逻辑时钟是相同的。每投完一次票，这个数据会增加)</li></ul><p>了解上述三个参数之后，后续Zookeeper的选举机制便和其有关。关于其选举机制可以分为两种情况。</p><p>第一种情况是第一次启动集群时，Leader的选举是根据其myid的大小进行选举的。</p><pre><code>    例如：目前有一个五台Zookeeper的集群。当启动id为1的Zookeeper时，它投自己一票。此时不满足Leader成立的条件。票数半数以上。因此进入looking状态。然后id为2的服务器启动，id1和id2的服务器都投自己一票，然后交换选票信息。此时服务器1发现服务器2的id比自己大，因此服务器1转投服务器2一票。服务器1只有0票，而服务器2有2票。但此时还是不满足半数以上，因此两者都进入looking状态。然后服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING；服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为 1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING；服务器5启动，同4一样当小弟。    </code></pre><p>而第二种情况是非第一次启动，而是在集群运行中，Leader宕机了，需要重新选举Leader。</p><pre><code>    例如：假设ZooKeeper由5台服务器组成，SID分别为1、2、3、4、5，ZXID分别为8、8、8、7、7，并且此时SID为3的服务器是Leader。某一时刻，3和5服务器出现故障，因此开始进行Leader选举。</code></pre><p> <img src="/images/pasted-225.png" alt="upload successful"></p><p> 选举Leader规则： ①EPOCH大的直接胜出 ②EPOCH相同，事务id大的胜出 ③事务id相同，服务器id大的胜出</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在了解Zookeeper的选举机制之前，首先需要了解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SID(服务器ID，用于唯一标识一台Zookeeper集群中的机器，每台机器不能重复，和myid一致)&lt;/li&gt;
&lt;li&gt;ZXID（事务ID。用来标识一次服务器状态的变更。在某一时刻，集群中的每</summary>
      
    
    
    
    <category term="Zookeeper" scheme="http://example.com/categories/Zookeeper/"/>
    
    
    <category term="Zookeeper" scheme="http://example.com/tags/Zookeeper/"/>
    
    <category term="选举机制" scheme="http://example.com/tags/%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>为什么要使用泛型程序设计？</title>
    <link href="http://example.com/2022/05/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%EF%BC%9F/"/>
    <id>http://example.com/2022/05/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%EF%BC%9F/</id>
    <published>2022-05-15T13:49:00.000Z</published>
    <updated>2022-05-18T11:13:31.973Z</updated>
    
    <content type="html"><![CDATA[<p>最近一直忙于编译原理的学习，难得空闲下来，重新巩固了一下泛型的知识。在此小记一下。</p><p>泛型程序设计意味着编写的代码可以被很多不同类型的对象重用</p><h2 id="泛型类"><a href="#泛型类" class="headerlink" title="泛型类"></a>泛型类</h2><p>在java中增加泛型类前，泛型程序设计时通过继承等方式实现的。例如：ArrayList维护一个Object数组的引用。 这种方式存在着两个问题：</p><ol><li>当获取一个值时，必须进行强制类型转换。</li><li>没有进行任何检测，可以向其中添加任何类的对象。</li></ol><p>因此，对于调用，编译和运行都不会出错。但在某些情况下进行了错误的强制类型转换使用。就会报错。</p><p>对此，泛型提供了更好的解决方案：类型参数。这不仅使得代码更具可读性，也使得代码更加安全。因为编译器可以根据这个信息推断出get时的类型，不需要进行强制类型转换。在编译期间检查出类型错误，而不是在运行时才检测出。</p><p>一个泛型类就是具有一个或多个类型变量的类。（使用大写形式，且比较短。在java中，E表示集合类型，K和V则是键值对，T表示任意类型）</p><h2 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h2><p>泛型方法的类型变量放在修饰符后，返回值前面。泛型方法可以定义在普通类中，也可以定义在泛型类中。</p><p>当调用一个泛型方法时，在方法名前的尖括号中放入具体的类型。当然在大多数情况下，编译器可以推导出类型，意味着我们可以省去。（在某些情况下，编译器无法推导出，此时需要指明）</p><h2 id="类型变量的限定"><a href="#类型变量的限定" class="headerlink" title="类型变量的限定"></a>类型变量的限定</h2><p>有时候类或方法需要对类型变量加以约束，&lt; T extends Object &gt; T</p><p>当做出这样的限定后，泛型的变量类型便被约束了。当然一个类型变量或通配符可以有多个限定，只需要用&amp;隔开即可。&lt; T extends Object1 &amp; Object2 &gt; T<br>值得注意的是，在java中可以根据需要拥有多个接口超类型，但限定中至多有一个类。如果用一个类作为限定，它必须位于限定列表的第一个</p><p>extends决定了泛型变量的上限。</p><h2 id="泛型代码和虚拟机"><a href="#泛型代码和虚拟机" class="headerlink" title="泛型代码和虚拟机"></a>泛型代码和虚拟机</h2><p>虚拟机没有泛型类对象，所有对象都是属于普通对象。</p><ul><li><p>类型擦除：无论何时定义一个泛型类型，都自动提供了一个相应的原始类型。原始类型的名字就是删去类型参数后的泛型类型名。擦除类型变量，并替换为限定类型类型。（无限定的变量用Object）</p></li><li><p>翻译泛型表达式：当程序调用泛型方法时，如果擦除返回类型，编译器会插入强制类型转换。</p></li><li><p>翻译泛型方法：类型擦除也会出现在泛型方法中，只留下限定类型。但这可能会导致类型擦除和多态发生冲突。</p></li></ul><h2 id="约束与局限性"><a href="#约束与局限性" class="headerlink" title="约束与局限性"></a>约束与局限性</h2><ul><li><p>不能用基本数据类型实例化类型参数，即不能有&lt; double &gt;，但可以有&lt; Double &gt;,原因是类型擦除。</p></li><li><p>运行时类型查询只适用于原始类型，而不适用于泛型类型。当试图查询一个对象是否属于某个泛型类型时，倘若使用instanceof会得到一个编译器错误。同样的道理，getClass方法总是返回原始类型。</p></li><li><p>不能创建参数化类型的数组，例如：Pair&lt; String &gt;[] table = new Pair&lt; String &gt; [10];类型擦除之后，table类型时Pair[],，可以把它转化为Object[],数组会记住其元素类型，如果试图存其他类型，则会报错。不过对于泛型，这种机制会使之无效。不过仍会导致一个类型错误。因此，不能创建参数化类型的数组。当然可以声明通配类型的数组，然后进行类型转换。</p></li><li><p>不能构造泛型数组，因为数组本身也有类型，用来监控存在虚拟机中的数组。</p></li><li><p>泛型类的静态上下文中类型变量无效：不能在静态域或方法中使用类型变量。</p></li><li><p>不能抛出或捕获泛型类的实例：可以消除对受查异常的检查</p></li><li><p>注意擦除后的冲突：要想支持擦除的转换，就需要强制限制一个类或类型变量不能同时成为两个接口类型的子类，而这两个接口时同一接口的不同参数。</p></li></ul><h2 id="泛型类型的继承规则"><a href="#泛型类型的继承规则" class="headerlink" title="泛型类型的继承规则"></a>泛型类型的继承规则</h2><ul><li>无论S和T有什么关系，通常calssName &lt; S &gt; 和 calssName &lt; T &gt; 没有任何关系</li></ul><p>待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近一直忙于编译原理的学习，难得空闲下来，重新巩固了一下泛型的知识。在此小记一下。&lt;/p&gt;
&lt;p&gt;泛型程序设计意味着编写的代码可以被很多不同类型的对象重用&lt;/p&gt;
&lt;h2 id=&quot;泛型类&quot;&gt;&lt;a href=&quot;#泛型类&quot; class=&quot;headerlink&quot; title=&quot;泛</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="泛型" scheme="http://example.com/tags/%E6%B3%9B%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>关于lambda表达式</title>
    <link href="http://example.com/2022/05/02/%E5%85%B3%E4%BA%8Elambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://example.com/2022/05/02/%E5%85%B3%E4%BA%8Elambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/</id>
    <published>2022-05-02T14:46:00.000Z</published>
    <updated>2022-05-02T15:19:37.907Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h3><p>lambda表达式是一个可传递的代码块，可以在以后执行一次或多次。</p><p>表达形式：(参数)-&gt;{表达式}</p><ul><li><p>如果可以推导出lambda表达式的参数类型，则可以忽略</p></li><li><p>如果只有一个参数，且参数类型可以推断，则（）可以省略</p></li><li><p>无需指定其返回类型，lambda表达式的返回类型可以根据上下文推断得出</p><pre><code>  注意：如果一个lambda表达式在某些分支返回值，而在另一些分支不返还，这是错误的</code></pre></li></ul><h3 id="函数式接口"><a href="#函数式接口" class="headerlink" title="函数式接口"></a>函数式接口</h3><p>对于只有一个抽象方法的接口，需要这种接口的对象时，就可以通过提供一个lambda表达式。这种接口称为函数式接口。</p><p>java.util.function包中定义了不少非常通用的函数式接口。例如其中一个接口BiFunction&lt;T,U,R&gt;描述了参数类型为T和U且返回类型为R的函数。（比如可以把比较的lambda表达式保存在这个类型的变量中。当然，没多少人喜欢在sort的时候接收一个BiFunction。）</p><h3 id="方法引用"><a href="#方法引用" class="headerlink" title="方法引用"></a>方法引用</h3><p>对象或类型::方法名</p><ul><li>object::instanceMethod</li><li>Class::staticMethod</li><li>Class::instanceMethod</li></ul><p>前两种方法引用等价于提供方法参数的lambda表达式，而对于第三种，第一个参数会成为方法的目标</p><p>例子：Arrays.sort(strings,String::compareToIgnoreCase)不考虑字母的大小写进行排序</p><h3 id="构造器引用"><a href="#构造器引用" class="headerlink" title="构造器引用"></a>构造器引用</h3><p>构造器引用同方法引用类似，不过方法名为new。如：String:new</p><h3 id="变量的作用域"><a href="#变量的作用域" class="headerlink" title="变量的作用域"></a>变量的作用域</h3><p>lambda表达式的三个部分：</p><ol><li>代码块</li><li>参数</li><li>自由变量的值（非参数，且不在代码块中定义的变量）<pre><code> 注意：即对于自由变量，lambda表达式需要数据结构对其进行存储，而为了明确其捕获到的自由变量的值，lambda表达式中只能引用值不会改变的变量（常量） 补充：关于代码块和自由变量值有一个术语：闭包</code></pre>在lambda表达式中使用this关键字，值创建这个lambda表达式的方法的this参数<h3 id="处理lambda表达式"><a href="#处理lambda表达式" class="headerlink" title="处理lambda表达式"></a>处理lambda表达式</h3>使用lambda表达式的重点是延迟执行。而希望一个代码延迟执行的原因有很多：</li><li>在一个单独的线程中运行的代码</li><li>多次运行代码</li><li>在算法的适当位置运行代码（如排序比较）</li><li>发生某种事件时执行代码（如点击一个按钮之类）<br>…</li></ol><h3 id="常用函数式接口"><a href="#常用函数式接口" class="headerlink" title="常用函数式接口"></a>常用函数式接口</h3><p> <img src="/images/pasted-223.png" alt="upload successful"></p><h3 id="基本类型函数式接口"><a href="#基本类型函数式接口" class="headerlink" title="基本类型函数式接口"></a>基本类型函数式接口</h3><p><img src="/images/pasted-224.png" alt="upload successful"><br>可以使用这些来减少装箱拆箱</p><pre><code>    补充：如果自己设计接口，其中只有一个抽象方法，可以使用@Functionallnterface注解来标记这个接口（好处：一方面无意增加了另一个抽象方法编译器会提示报错，另一方面javadoc页会指出这是一个函数式接口）</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;简单介绍&quot;&gt;&lt;a href=&quot;#简单介绍&quot; class=&quot;headerlink&quot; title=&quot;简单介绍&quot;&gt;&lt;/a&gt;简单介绍&lt;/h3&gt;&lt;p&gt;lambda表达式是一个可传递的代码块，可以在以后执行一次或多次。&lt;/p&gt;
&lt;p&gt;表达形式：(参数)-&amp;gt;{表达式}&lt;/</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="lambda表达式" scheme="http://example.com/tags/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>SLF4J那些事</title>
    <link href="http://example.com/2022/04/29/SLF4J%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <id>http://example.com/2022/04/29/SLF4J%E9%82%A3%E4%BA%9B%E4%BA%8B/</id>
    <published>2022-04-29T07:21:00.000Z</published>
    <updated>2022-04-29T08:49:21.775Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Java中的日志框架"><a href="#Java中的日志框架" class="headerlink" title="Java中的日志框架"></a>Java中的日志框架</h3><p> <img src="/images/pasted-216.png" alt="upload successful"></p><h3 id="门面日志框架"><a href="#门面日志框架" class="headerlink" title="门面日志框架"></a>门面日志框架</h3><p> <img src="/images/pasted-217.png" alt="upload successful"><br>不同的日志框架，有着不同的api和配置文件，为了统一应用中不同的日志框架所带来的统一管理问题，引入了门面日志框架，向上提供了统一的接口管理，向下对接不同的日志框架实现。<br> <img src="/images/pasted-218.png" alt="upload successful"></p><h3 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a>具体流程</h3><p> <img src="/images/pasted-219.png" alt="upload successful"></p><h3 id="关于SL4J的适配"><a href="#关于SL4J的适配" class="headerlink" title="关于SL4J的适配"></a>关于SL4J的适配</h3><p> <img src="/images/pasted-220.png" alt="upload successful"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>引入jar包slf4-api.jar</li><li>引入适配层jar包（如果需要的话）</li><li>引入底层日志框架的jar包</li><li>确认是否版本安全<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><img src="/images/pasted-221.png" alt="upload successful"></li></ol><p> <img src="/images/pasted-222.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Java中的日志框架&quot;&gt;&lt;a href=&quot;#Java中的日志框架&quot; class=&quot;headerlink&quot; title=&quot;Java中的日志框架&quot;&gt;&lt;/a&gt;Java中的日志框架&lt;/h3&gt;&lt;p&gt; &lt;img src=&quot;/images/pasted-216.png&quot; alt</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="日志" scheme="http://example.com/tags/%E6%97%A5%E5%BF%97/"/>
    
    <category term="SL4J" scheme="http://example.com/tags/SL4J/"/>
    
  </entry>
  
  <entry>
    <title>Java SPI机制</title>
    <link href="http://example.com/2022/04/29/Java-SPI%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2022/04/29/Java-SPI%E6%9C%BA%E5%88%B6/</id>
    <published>2022-04-29T01:06:00.000Z</published>
    <updated>2022-04-29T01:35:01.943Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>SPI（Serivce Provider Interface）：它是从java6开始引入的，一种基于classloader来发现并加载服务的机制。</p><p>一个标准的SPI有三个组件构成：<br>    - Service：是一个公开的接口或抽象类，定义了一个抽象的功能模块<br>    - Service Provider：service的一个实现类<br>    - ServiceLoader：核心组件，负责在运行时发现并加载service provider</p><h2 id="SPI运行流程"><a href="#SPI运行流程" class="headerlink" title="SPI运行流程"></a>SPI运行流程</h2><p> <img src="/images/pasted-211.png" alt="upload successful"></p><p> Application无需关注service的具体实现，只需面向接口编程</p><h2 id="Java-SPI在JDBC中的应用"><a href="#Java-SPI在JDBC中的应用" class="headerlink" title="Java SPI在JDBC中的应用"></a>Java SPI在JDBC中的应用</h2><p> <img src="/images/pasted-212.png" alt="upload successful"></p><ul><li>在Java SPI前，我们需要编码去注册驱动Class.forName(“com.mysql.jdbc.Driver”)</li><li>在引入Java SPI后，我们只需要日引入对应的依赖jar包即可</li></ul><h3 id="Java-SPI的三大规范要素"><a href="#Java-SPI的三大规范要素" class="headerlink" title="Java SPI的三大规范要素"></a>Java SPI的三大规范要素</h3><p> <img src="/images/pasted-214.png" alt="upload successful"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>作用：提供了一种组件发现和注册的方式，可以用于实现各种插件，或者灵活替换所使用的组件</li><li>优点：面向接口编程，优雅的实现模块之间的解耦</li><li>设计思想：面向接口+配置文件+反射技术</li><li>应用场景：JDBC、SLF4J等</li></ul><h3 id="补充：Java-SPI和SPringBoot自动装配"><a href="#补充：Java-SPI和SPringBoot自动装配" class="headerlink" title="补充：Java SPI和SPringBoot自动装配"></a>补充：Java SPI和SPringBoot自动装配</h3><p> <img src="/images/pasted-215.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;p&gt;SPI（Serivce Provider Interface）：它是从java6开始引入的，一种基于classloader来</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="SPI" scheme="http://example.com/tags/SPI/"/>
    
  </entry>
  
  <entry>
    <title>MySQL行转列，列转行</title>
    <link href="http://example.com/2022/04/26/MySQL%E8%A1%8C%E8%BD%AC%E5%88%97%EF%BC%8C%E5%88%97%E8%BD%AC%E8%A1%8C/"/>
    <id>http://example.com/2022/04/26/MySQL%E8%A1%8C%E8%BD%AC%E5%88%97%EF%BC%8C%E5%88%97%E8%BD%AC%E8%A1%8C/</id>
    <published>2022-04-26T12:09:00.000Z</published>
    <updated>2022-04-26T12:41:41.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h2><ul><li><p>建表</p><pre><code>CREATE TABLE tb_score(    id INT(11) NOT NULL auto_increment,    userid VARCHAR(20) NOT NULL COMMENT &#39;用户id&#39;,    subject VARCHAR(20) COMMENT &#39;科目&#39;,    score DOUBLE COMMENT &#39;成绩&#39;,    PRIMARY KEY(id))ENGINE = INNODB DEFAULT CHARSET = utf8;</code></pre></li><li><p>插入数据</p><pre><code>INSERT INTO tb_score(userid,subject,score) VALUES (&#39;001&#39;,&#39;语文&#39;,90);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;001&#39;,&#39;数学&#39;,92);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;001&#39;,&#39;英语&#39;,80);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;002&#39;,&#39;语文&#39;,88);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;002&#39;,&#39;数学&#39;,90);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;002&#39;,&#39;英语&#39;,75.5);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;语文&#39;,70);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;数学&#39;,85);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;英语&#39;,90);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;政治&#39;,82);</code></pre></li></ul><p> 查询数据表中的内容（即转换前的结果）</p><pre><code>    select * from tb_score;</code></pre><p> <img src="/images/pasted-206.png" alt="upload successful"></p><ol><li>使用case…when….then 进行行转列<pre><code> SELECT userid,SUM(CASE `subject` WHEN &#39;语文&#39; THEN score ELSE 0 END) AS &#39;语文&#39;,SUM(CASE `subject` WHEN &#39;数学&#39; THEN score ELSE 0 END) AS &#39;数学&#39;,SUM(CASE `subject` WHEN &#39;英语&#39; THEN score ELSE 0 END) AS &#39;英语&#39;,SUM(CASE `subject` WHEN &#39;政治&#39; THEN score ELSE 0 END) AS &#39;政治&#39;FROM tb_scoreGROUP BY userid</code></pre></li></ol><p> <img src="/images/pasted-207.png" alt="upload successful"></p><ol start="2"><li>使用IF() 进行行转列：<pre><code>SELECT userid,SUM(IF(`subject`=&#39;语文&#39;,score,0)) AS &#39;语文&#39;,SUM(IF(`subject`=&#39;数学&#39;,score,0)) AS &#39;数学&#39;,SUM(IF(`subject`=&#39;英语&#39;,score,0)) AS &#39;英语&#39;,SUM(IF(`subject`=&#39;政治&#39;,score,0)) AS &#39;政治&#39;FROM tb_scoreGROUP BY userid</code></pre></li></ol><p> <img src="/images/pasted-208.png" alt="upload successful"></p><blockquote><p>注意点：</p></blockquote><blockquote><blockquote><p>（1）SUM() 是为了能够使用GROUP BY根据userid进行分组，因为每一个userid对应的subject=”语文”的记录只有一条，所以SUM() 的值就等于对应那一条记录的score的值。假如userid =’001’ and subject=’语文’ 的记录有两条，则此时SUM() 的值将会是这两条记录的和，同理，使用Max()的值将会是这两条记录里面值最大的一个。但是正常情况下，一个user对应一个subject只有一个分数，因此可以使用SUM()、MAX()、MIN()、AVG()等聚合函数都可以达到行转列的效果。</p></blockquote></blockquote><blockquote><blockquote><p>（2）IF(<code>subject</code>=’语文’,score,0) 作为条件，即对所有subject=’语文’的记录的score字段进行SUM()、MAX()、MIN()、AVG()操作，如果score没有值则默认为0。</p></blockquote></blockquote><ol start="3"><li>计算行列和<pre><code> SELECT IFNULL(userid,&#39;TOTAL&#39;) AS userid, SUM(IF(`subject`=&#39;语文&#39;,score,0)) AS 语文, SUM(IF(`subject`=&#39;数学&#39;,score,0)) AS 数学, SUM(IF(`subject`=&#39;英语&#39;,score,0)) AS 英语, SUM(IF(`subject`=&#39;政治&#39;,score,0)) AS 政治, SUM(score) AS TOTAL  FROM tb_score GROUP BY userid WITH ROLLUP;</code></pre></li></ol><p> <img src="/images/pasted-209.png" alt="upload successful"></p><ol start="4"><li><p>合并字段显示：利用group_concat()</p><pre><code>  SELECT userid,GROUP_CONCAT(`subject`,&quot;:&quot;,score)AS 成绩 FROM tb_score  GROUP BY userid</code></pre></li></ol><p> <img src="/images/pasted-210.png" alt="upload successful"></p><h3 id="列转行"><a href="#列转行" class="headerlink" title="列转行"></a>列转行</h3><p>将每个userid对应的多个科目的成绩查出来，通过UNION ALL将结果集加起来</p><pre><code>附：UNION与UNION ALL的区别（摘）：1.对重复结果的处理：UNION会去掉重复记录，UNION ALL不会；2.对排序的处理：UNION会排序，UNION ALL只是简单地将两个结果集合并；3.效率方面的区别：因为UNION 会做去重和排序处理，因此效率比UNION ALL慢很多；</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;行转列&quot;&gt;&lt;a href=&quot;#行转列&quot; class=&quot;headerlink&quot; title=&quot;行转列&quot;&gt;&lt;/a&gt;行转列&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;建表&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE tb_score(
    id INT(11) N</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="查询" scheme="http://example.com/tags/%E6%9F%A5%E8%AF%A2/"/>
    
    <category term="行列转换" scheme="http://example.com/tags/%E8%A1%8C%E5%88%97%E8%BD%AC%E6%8D%A2/"/>
    
  </entry>
  
  <entry>
    <title>记一次安装Zookeeper启动失败的坑</title>
    <link href="http://example.com/2022/04/21/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%AE%89%E8%A3%85Zookeeper%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%9D%91/"/>
    <id>http://example.com/2022/04/21/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%AE%89%E8%A3%85Zookeeper%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%9D%91/</id>
    <published>2022-04-21T13:36:00.000Z</published>
    <updated>2022-04-21T13:43:12.434Z</updated>
    
    <content type="html"><![CDATA[<p>今天在阿里云上安装ZooKeeper，然后启动时一直报: Starting zookeeper … FAILED TO START。折腾了一会，经查阅资料发现，原来和版本有莫大关系…</p><h3 id="1-下载的版本问题（-gt-3-5-5）"><a href="#1-下载的版本问题（-gt-3-5-5）" class="headerlink" title="1. 下载的版本问题（&gt;= 3.5.5）"></a>1. 下载的版本问题（&gt;= 3.5.5）</h3><p>实际上只要 &gt;= 3.5.5 版本都会出现这种问题。</p><p>问题原因：下载了错误的版本文件，Zookeeper 从3.5.5后开始拆分为两个版本，而且他们的结构还很类似。</p><ul><li>标准版本（Apache ZooKeeper x.y.z ），下载的文件名为：apache-zookeeper-x.y.z-bin.tar.gz</li><li>另一个是源码版本（Apache ZooKeeper x.y.z Source Release），下载的文件名为：apache-zookeeper-x.y.z.tar.gz</li></ul><p> <img src="/images/pasted-204.png" alt="upload successful"></p><p> <img src="/images/pasted-205.png" alt="upload successful"><br> 所以下载 Zookeeper 的时候要注意，应该下载第一个(本人头铁，下载了第二个)。</p><h3 id="2-端口冲突问题（-gt-3-5-0）"><a href="#2-端口冲突问题（-gt-3-5-0）" class="headerlink" title="2. 端口冲突问题（&gt;=3.5.0）"></a>2. 端口冲突问题（&gt;=3.5.0）</h3><p> 在3.5.5版本及以上，Zookeeper 提供了一个内嵌的Jetty容器来运行 AdminServer，默认占用的是 8080端口，AdminServer 主要是来查看 Zookeeper 的一些状态，如果机器上有其他程序（比如：Tomcat）占用了 8080 端口，也会导致 Starting zookeeper … FAILED TO START 的问题。</p><p>可以通过以下几种方式去解决：</p><ul><li><p>禁用 AdminServer 服务</p><pre><code>  admin.enableServer=false</code></pre></li><li><p>修改器端口号：</p><pre><code>  admin.serverPort=9000</code></pre></li></ul><p>转载自：<a href="https://blog.csdn.net/peng2hui1314/article/details/107255142">https://blog.csdn.net/peng2hui1314/article/details/107255142</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天在阿里云上安装ZooKeeper，然后启动时一直报: Starting zookeeper … FAILED TO START。折腾了一会，经查阅资料发现，原来和版本有莫大关系…&lt;/p&gt;
&lt;h3 id=&quot;1-下载的版本问题（-gt-3-5-5）&quot;&gt;&lt;a href=&quot;#1</summary>
      
    
    
    
    <category term="Zookeeper" scheme="http://example.com/categories/Zookeeper/"/>
    
    
    <category term="Zookeeper" scheme="http://example.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>重排序</title>
    <link href="http://example.com/2022/04/17/%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    <id>http://example.com/2022/04/17/%E9%87%8D%E6%8E%92%E5%BA%8F/</id>
    <published>2022-04-17T02:01:00.000Z</published>
    <updated>2022-04-17T02:13:06.463Z</updated>
    
    <content type="html"><![CDATA[<p>重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。</p><h3 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h3><p>如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间 就存在数据依赖性。数据依赖分为下列3种类型</p><p> <img src="/images/pasted-203.png" alt="upload successful"></p><p> 上面3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。 而编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。 这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作， 不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。</p><h3 id="as-if-serial语义"><a href="#as-if-serial语义" class="headerlink" title="as-if-serial语义"></a>as-if-serial语义</h3><p> as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程） 程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p><p> 为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因 为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被 编译器和处理器重排序。</p><p> as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器 共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as- if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p><h3 id="程序顺序规则"><a href="#程序顺序规则" class="headerlink" title="程序顺序规则"></a>程序顺序规则</h3><p> 1）A happens-before B。 </p><p> 2）B happens-before C。 </p><p> 3）A happens-before C。</p><p> 这里的第3个happens-before关系，是根据happens-before的传递性推导出来的。 这里A happens-before B，但实际执行时B却可以排在A之前执行（看上面的重排序后的执 行顺序）。如果A happens-before B，JMM并不要求A一定要在B之前执行。JMM仅仅要求前一个 操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作A 的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，与操作A和操作B 按happens-before顺序执行的结果一致。在这种情况下，JMM会认为这种重排序并不非法（not illegal），JMM允许这种重排序。</p><p> 在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下， 尽可能提高并行度。编译器和处理器遵从这一目标，从happens-before的定义我们可以看出， JMM同样遵从这一目标。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。&lt;/p&gt;
&lt;h3 id=&quot;数据依赖性&quot;&gt;&lt;a href=&quot;#数据依赖性&quot; class=&quot;headerlink&quot; title=&quot;数据依赖性&quot;&gt;&lt;/a&gt;数据依赖性&lt;/h3&gt;&lt;p&gt;如果两个操作访问同一个变</summary>
      
    
    
    
    <category term="并发编程" scheme="http://example.com/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="JMM" scheme="http://example.com/tags/JMM/"/>
    
    <category term="并发编程" scheme="http://example.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    <category term="重排序" scheme="http://example.com/tags/%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>Java内存模式的基础</title>
    <link href="http://example.com/2022/04/17/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%9F%BA%E7%A1%80/"/>
    <id>http://example.com/2022/04/17/Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%9F%BA%E7%A1%80/</id>
    <published>2022-04-17T01:11:00.000Z</published>
    <updated>2022-04-17T01:52:43.054Z</updated>
    
    <content type="html"><![CDATA[<h3 id="并发编程模型的两个关键问题"><a href="#并发编程模型的两个关键问题" class="headerlink" title="并发编程模型的两个关键问题"></a>并发编程模型的两个关键问题</h3><p>在并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。</p><p>通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。</p><ul><li>在共享内存的并发模型里，线程之间共享程序的公共状态，通过写-读内存中的公共状态 进行隐式通信。</li><li>在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过发送消 息来显式进行通信。</li></ul><p>同步是指程序中用于控制不同线程间操作发生相对顺序的机制。</p><ul><li>在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。 </li><li>在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。</li></ul><p>Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对 程序员完全透明。如果编写多线程程序的Java程序员不理解隐式进行的线程之间通信的工作 机制，很可能会遇到各种奇怪的内存可见性问题。</p><h3 id="Java内存模型的抽象结构"><a href="#Java内存模型的抽象结构" class="headerlink" title="Java内存模型的抽象结构"></a>Java内存模型的抽象结构</h3><p>在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享 （本章用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local Variables），方 法定义参数（Java语言规范称之为Formal Method Parameters）和异常处理器参数（Exception Handler Parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影 响。</p><p>Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享 变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽 象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地 内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的 一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p><h3 id="从源代码到指令序列的重排序"><a href="#从源代码到指令序列的重排序" class="headerlink" title="从源代码到指令序列的重排序"></a>从源代码到指令序列的重排序</h3><p>在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。</p><ol><li>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句 的执行顺序。 </li><li>指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应 机器指令的执行顺序。 </li><li>内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上 去可能是在乱序执行。</li></ol><p>这些重排序可能会导致多线程程序 出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排 序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要 求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为 Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。</p><p>JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。</p><h3 id="并发编程模型的分类"><a href="#并发编程模型的分类" class="headerlink" title="并发编程模型的分类"></a>并发编程模型的分类</h3><p>现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线 持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以 批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总 线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器 可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行 顺序，不一定与内存实际发生的读/写操作顺序一致！</p><p> <img src="/images/pasted-200.png" alt="upload successful"><br> 这里处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存 中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3， B3）。当以这种时序执行时，程序就可以得到x=y=0的结果。 从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作 A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1→A2，但内存操作实际发生的顺 序却是A2→A1。此时，处理器A的内存操作顺序被重排序了（处理器B的情况和处理器A一样， 这里就不赘述了）。</p><p>这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的 顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写-读操作进行重排序。</p><pre><code>常见的处理器都允许Store-Load重排序；常见的处理器都不允许对 存在数据依赖的操作做重排序。sparc-TSO和X86拥有相对较强的处理器内存模型，它们仅允 许对写-读操作做重排序（因为它们都使用了写缓冲区）。</code></pre><p>为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁 止特定类型的处理器重排序。JMM把内存屏障指令分为4类</p><p> <img src="/images/pasted-201.png" alt="upload successful"><br> StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处 理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂 贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。</p><h3 id="happens-before简介"><a href="#happens-before简介" class="headerlink" title="happens-before简介"></a>happens-before简介</h3><p> 从JDK 5开始，Java使用新的JSR-133内存模型（除非特别说明，本文针对的都是JSR-133内 存模型）。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一 个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关 系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。</p><p>与程序员密切相关的happens-before规则如下。 </p><ul><li><p>程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。  </p></li><li><p>监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 </p></li><li><p>volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 </p></li><li><p>传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</p><pre><code>  注意：两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个 操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一 个操作按顺序排在第二个操作之前</code></pre></li></ul><p> <img src="/images/pasted-202.png" alt="upload successful"></p><p>一个happens-before规则对应于一个或多个编译器和处理器重排序规则。对 于Java程序员来说，happens-before规则简单易懂，它避免Java程序员为了理解JMM提供的内存 可见性保证而去学习复杂的重排序规则以及这些规则的具体实现方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;并发编程模型的两个关键问题&quot;&gt;&lt;a href=&quot;#并发编程模型的两个关键问题&quot; class=&quot;headerlink&quot; title=&quot;并发编程模型的两个关键问题&quot;&gt;&lt;/a&gt;并发编程模型的两个关键问题&lt;/h3&gt;&lt;p&gt;在并发编程中，需要处理两个关键问题：线程之间如何通信</summary>
      
    
    
    
    <category term="JMM" scheme="http://example.com/categories/JMM/"/>
    
    <category term="并发编程" scheme="http://example.com/categories/JMM/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="JMM" scheme="http://example.com/tags/JMM/"/>
    
    <category term="并发编程" scheme="http://example.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>First集和Follow集的构造</title>
    <link href="http://example.com/2022/04/14/First%E9%9B%86%E5%92%8CFollow%E9%9B%86%E7%9A%84%E6%9E%84%E9%80%A0/"/>
    <id>http://example.com/2022/04/14/First%E9%9B%86%E5%92%8CFollow%E9%9B%86%E7%9A%84%E6%9E%84%E9%80%A0/</id>
    <published>2022-04-14T10:57:00.000Z</published>
    <updated>2022-04-14T11:11:37.751Z</updated>
    
    <content type="html"><![CDATA[<p>在编译原理语法分析学习中，关于First集和Follow集的构造令我比较费解（课件上的白话太晦涩了，恕我看得一知半解），消化了好一会才明白，特此记录一下。</p><h3 id="关于First集"><a href="#关于First集" class="headerlink" title="关于First集"></a>关于First集</h3><p>对于 X -&gt; … 这条产生式而言：</p><ol><li><p>若右边第一个符号是终结符或 ε  ，则直接将其加入 First（X）</p></li><li><p>若右边第一个符号是非终结符，则将其 First 集的的非 ε  元素加入 First（X）</p></li><li><p>若右边第一个符号是非终结符而且紧随其后的是很多个非终结符，这个时候就要注意是否有 ε  。</p><p> 【3.1】若第 i 个非终结符的 First 集有 ε  ，则可将第 i+1 个非终结符去除 ε  的 First 集加入 First（X）。<br> 【3.2】若所有的非终结符都能够推导出 ε ，则将  ε  也加入到 First（X）</p><p>　　　<br> E.G. G[S]:</p></li></ol><p>　　　　　　S -&gt; ABCD</p><p>　　　　　　A -&gt; a |  ε  </p><p>　　　　　　B -&gt; b |  ε  </p><p>　　　　　　C -&gt; c</p><p>　　　　　　D -&gt; d</p><p>　　　　　　解：</p><p>　　　　　　　　First(S) = {a, b, c}，其中 c 是由上面所说的第二、三条规则所推得出来的，因为此时 A 和 B 都可以等于空串（ ε  ），所以非终结符 C 的 first 集合就被加入 G[S] 了。</p><p>　　　　　　　　如果这里 C，D 也能够产生 ε  的话，根据第三条规则中的第二小点，此时 First（S） = {a, b, c, d,  ε}</p><h3 id="关于Follow集"><a href="#关于Follow集" class="headerlink" title="关于Follow集"></a>关于Follow集</h3><ol><li><p>将所有产生式的候选式（即产生式右部）的非终结符都找到，定位到你想要求解 Follow 集的非终结符的位置，从当前位置往后挨个检查。设 A -&gt; aBC 是一个产生式，在这个产生式中， B 和 C 是非终结符，a 是终结符</p></li><li><p>先检验这个非终结符的右边还有没有别的符号（终结符或非终结符都可以），在例子中 B 是需要检查的第一个非终结符，它的右边是有非终结符 C 的。</p><ul><li><p>若右边有符号 -&gt; 将 First（右侧第一个符号）的非 ε 集合加入到 Follow（当前符号）中，如果 First（右侧第一个符号）含有 ε  ，即有 … -&gt; ε ，则将 Follow（产生式左部符号）加入 Follow（当前符号）中。</p></li><li><p>E.G.  用 A -&gt; aBC 来说就是，当前扫描到 B 了，而 B 的右侧有非终结符 C，则将去掉 ε  的 First（C）加入 Follow（B）中。若存在 C -&gt; ε  ，则将 Follow（A）也加入 Follow（B）中。</p></li><li><p>若右边没有符号了，例如这里的 C，那么可以将 Follow（A）中的元素全部加入到 Follow（C）中。</p></li></ul></li><li><p>判断当前符号是不是文法的开始符号，比如 G[A] 中的非终结符 A 就是 G[A] 文法的开始符号，如果是的话就将“#”也加入到 Follow（当前符号）中去</p></li></ol><h3 id="预测表的构造"><a href="#预测表的构造" class="headerlink" title="预测表的构造"></a>预测表的构造</h3><p>首先构造出预测分析表的第一行与第一列，第一行为文法出现的所有终结符以及‘#’（注意：没有 ε ，因为 Follow 集不含 ε），第一列为文法出现的所有终结符。</p><p>　　然后对文法 G 的每个产生式 A -&gt; ab 都执行如下操作：</p><p>　　　　【1】对于每个属于 First(ab) 的终结符 m ，都把 A -&gt; ab 添加到预测表中的 [A, m] 中去</p><p>　　　　【2】如果 ε 也属于 First(ab)，那么对于任何属于 Follow(A) 的字符 x，都把 A -&gt;  ε  加入到 [A, x] 中去</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在编译原理语法分析学习中，关于First集和Follow集的构造令我比较费解（课件上的白话太晦涩了，恕我看得一知半解），消化了好一会才明白，特此记录一下。&lt;/p&gt;
&lt;h3 id=&quot;关于First集&quot;&gt;&lt;a href=&quot;#关于First集&quot; class=&quot;headerlink</summary>
      
    
    
    
    <category term="编译原理" scheme="http://example.com/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
    
    <category term="上下文无关文法" scheme="http://example.com/tags/%E4%B8%8A%E4%B8%8B%E6%96%87%E6%97%A0%E5%85%B3%E6%96%87%E6%B3%95/"/>
    
    <category term="First" scheme="http://example.com/tags/First/"/>
    
    <category term="Follow" scheme="http://example.com/tags/Follow/"/>
    
  </entry>
  
  <entry>
    <title>初识LSM树</title>
    <link href="http://example.com/2022/04/14/%E5%88%9D%E8%AF%86LSM%E6%A0%91/"/>
    <id>http://example.com/2022/04/14/%E5%88%9D%E8%AF%86LSM%E6%A0%91/</id>
    <published>2022-04-14T01:09:00.000Z</published>
    <updated>2022-04-14T01:37:31.362Z</updated>
    
    <content type="html"><![CDATA[<p>今天在看MYSQL45讲的时候，看见一个新词LSM树，抱着好奇和求学的心态，上网查询了一下。对LMS树有了一个简单的认识。特以此篇来记录一下。摘抄自：<a href="https://zhuanlan.zhihu.com/p/181498475">https://zhuanlan.zhihu.com/p/181498475</a></p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>LSM树并不像B+树、红黑树一样是一颗严格的树状数据结构，它其实是一种存储结构，目前HBase,LevelDB,RocksDB这些NoSQL存储都是采用的LSM树。</p><p>对于传统关系型数据库使用btree或一些变体作为存储结构，其能高效进行查找。但保存在磁盘中时它也有一个明显的缺陷，那就是逻辑上相离很近但物理却可能相隔很远，这就可能造成大量的磁盘随机读写。随机读写比顺序读写慢很多，为了提升IO性能，我们需要一种能将随机操作变为顺序操作的机制，于是便有了LSM树。LSM树能让我们进行顺序写磁盘，从而大幅提升写操作，作为代价的是牺牲了一些读性能。</p><h3 id="LMS树的核心思想"><a href="#LMS树的核心思想" class="headerlink" title="LMS树的核心思想"></a>LMS树的核心思想</h3><p> <img src="/images/pasted-194.png" alt="upload successful"><br>由上图可知，LMS主要由三个部分组成：</p><ol><li>MemTable<br>MemTable是在内存中的数据结构，用于保存最近更新的数据，会按照Key有序地组织这些数据，LSM树对于具体如何组织有序地组织数据并没有明确的数据结构定义，例如Hbase使跳跃表来保证内存中key的有序。</li></ol><p>因为数据暂时保存在内存中，内存并不是可靠存储，如果断电会丢失数据，因此通常会通过WAL(Write-ahead logging，预写式日志)的方式来保证数据的可靠性。</p><ol start="2"><li>Immutable MemTable</li></ol><p>当 MemTable达到一定大小后，会转化成Immutable MemTable。Immutable MemTable是将转MemTable变为SSTable的一种中间状态。写操作由新的MemTable处理，在转存过程中不阻塞数据更新操作。</p><ol start="3"><li>SSTable(Sorted String Table)</li></ol><p>有序键值对集合，是LSM树组在磁盘中的数据结构。为了加快SSTable的读取，可以通过建立key的索引以及布隆过滤器来加快key的查找。</p><ul><li><p>这里需要关注一个重点，LSM树(Log-Structured-Merge-Tree)正如它的名字一样，LSM树会将所有的数据插入、修改、删除等操作记录(注意是操作记录)保存在内存之中，当此类操作达到一定的数据量后，再批量地顺序写入到磁盘当中。这与B+树不同，B+树数据的更新会直接在原数据所在处修改对应的值，但是LSM数的数据更新是日志式的，当一条数据更新是直接append一条更新记录完成的。这样设计的目的就是为了顺序写，不断地将Immutable MemTable flush到持久化存储即可，而不用去修改之前的SSTable中的key，保证了顺序写。</p></li><li><p>因此当MemTable达到一定大小flush到持久化存储变成SSTable后，在不同的SSTable中，可能存在相同Key的记录，当然最新的那条记录才是准确的。这样设计的虽然大大提高了写性能，但同时也会带来一些问题：</p><pre><code>1）冗余存储，对于某个key，实际上除了最新的那条记录外，其他的记录都是冗余无用的，但是仍然占用了存储空间。因此需要进行Compact操作(合并多个SSTable)来清除冗余的记录。2）读取时需要从最新的倒着查询，直到找到某个key的记录。最坏情况需要查询完所有的SSTable，这里可以通过前面提到的索引/布隆过滤器来优化查找速度。</code></pre></li></ul><h3 id="LSM树的Compact策略"><a href="#LSM树的Compact策略" class="headerlink" title="LSM树的Compact策略"></a>LSM树的Compact策略</h3><p>从上面可以看出，Compact操作是十分关键的操作，否则SSTable数量会不断膨胀。在Compact策略上，主要介绍两种基本策略：size-tiered和leveled。</p><p>不过在介绍这两种策略之前，先介绍三个比较重要的概念，事实上不同的策略就是围绕这三个概念之间做出权衡和取舍。</p><ol><li>读放大:读取数据时实际读取的数据量大于真正的数据量。例如在LSM树中需要先在MemTable查看当前key是否存在，不存在继续从SSTable中寻找。</li><li>写放大:写入数据时实际写入的数据量大于真正的数据量。例如在LSM树中写入时可能触发Compact操作，导致实际写入的数据量远大于该key的数据量。</li><li>空间放大:数据实际占用的磁盘空间比数据的真正大小更多。上面提到的冗余存储，对于一个key来说，只有最新的那条记录是有效的，而之前的记录都是可以被清理回收的。</li></ol><ol><li>size-tiered 策略</li></ol><p> <img src="/images/pasted-195.png" alt="upload successful"></p><p>size-tiered策略保证每层SSTable的大小相近，同时限制每一层SSTable的数量。如上图，每层限制SSTable为N，当每层SSTable达到N后，则触发Compact操作合并这些SSTable，并将合并后的结果写入到下一层成为一个更大的sstable。</p><p>由此可以看出，当层数达到一定数量时，最底层的单个SSTable的大小会变得非常大。并且size-tiered策略会导致空间放大比较严重。即使对于同一层的SSTable，每个key的记录是可能存在多份的，只有当该层的SSTable执行compact操作才会消除这些key的冗余记录。</p><ol start="2"><li>leveled策略</li></ol><p> <img src="/images/pasted-196.png" alt="upload successful"></p><p>leveled策略也是采用分层的思想，每一层限制总文件的大小。</p><p>但是跟size-tiered策略不同的是，leveled会将每一层切分成多个大小相近的SSTable。这些SSTable是这一层是全局有序的，意味着一个key在每一层至多只有1条记录，不存在冗余记录。之所以可以保证全局有序，是因为合并策略和size-tiered不同，接下来会详细提到。</p><p>假设存在以下这样的场景:</p><ol><li>L1的总大小超过L1本身大小限制：</li></ol><p> <img src="/images/pasted-197.png" alt="upload successful"></p><ol start="2"><li>此时会从L1中选择至少一个文件，然后把它跟L2有交集的部分(非常关键)进行合并。生成的文件会放在L2:</li></ol><p> <img src="/images/pasted-198.png" alt="upload successful"></p><p> 如上图所示，此时L1第二SSTable的key的范围覆盖了L2中前三个SSTable，那么就需要将L1中第二个SSTable与L2中前三个SSTable执行Compact操作。</p><ol start="3"><li>如果L2合并后的结果仍旧超出L5的阈值大小，需要重复之前的操作 —— 选至少一个文件然后把它合并到下一层:</li></ol><p> <img src="/images/pasted-199.png" alt="upload successful"></p><pre><code> 需要注意的是，多个不相干的合并是可以并发进行的</code></pre><p>leveled策略相较于size-tiered策略来说，每层内key是不会重复的，即使是最坏的情况，除开最底层外，其余层都是重复key，按照相邻层大小比例为10来算，冗余占比也很小。因此空间放大问题得到缓解。但是写放大问题会更加突出。举一个最坏场景，如果LevelN层某个SSTable的key的范围跨度非常大，覆盖了LevelN+1层所有key的范围，那么进行Compact时将涉及LevelN+1层的全部数据。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>从Btree到LSM，其设计思想都和底层息息相关，了解学习不同的思想和底层。有助于我们对不同的框架的学习和思考。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天在看MYSQL45讲的时候，看见一个新词LSM树，抱着好奇和求学的心态，上网查询了一下。对LMS树有了一个简单的认识。特以此篇来记录一下。摘抄自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/181498475&quot;&gt;https://zhuan</summary>
      
    
    
    
    <category term="LSM" scheme="http://example.com/categories/LSM/"/>
    
    
    <category term="LSM" scheme="http://example.com/tags/LSM/"/>
    
  </entry>
  
  <entry>
    <title>MySQL EXPLAIN 详解</title>
    <link href="http://example.com/2022/04/10/MySQL-EXPLAIN-%E8%AF%A6%E8%A7%A3/"/>
    <id>http://example.com/2022/04/10/MySQL-EXPLAIN-%E8%AF%A6%E8%A7%A3/</id>
    <published>2022-04-10T08:23:00.000Z</published>
    <updated>2022-04-10T08:44:36.967Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL 提供了一个EXPALIN 命令，可以用于对SQL语句的执行计划进行分析，并详细的输出分析结果，供开发人员进行针对性的优化。</p><p>我们想要查询一条sql有没有用上索引，有没有全表查询，这些都可以通过explain这个命令来查看。</p><p>通过explain命令，我们可以深入了解到MySQL的基于开销的优化器，还可以获得很多被优化器考虑到的访问策略的细节以及运行sql语句时哪种策略预计会被优化器采用。</p><p>xplain的使用十分简单，通过在查询语句前面加一个explain关键字即可。</p><h2 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h2><p>explain 命令一共返回12列信息，分别是：</p><pre><code>id、select_type、table、partitions、type、possible_keys、key、key_len、ref、rows、filtered、Extra</code></pre><h3 id="id-列"><a href="#id-列" class="headerlink" title="id 列"></a>id 列</h3><ul><li>每个select语句都会自动分配的一个唯一标识符</li><li>表示查询中，操作表的顺序，有三种情况<pre><code>id相同，执行顺序从上到下id不同，如果是子查询，id号会自增，id越大，优先级越高id相同的不相同的同时存在</code></pre></li><li>id列为null表示为结果集，不需要使用这个语句来查询</li></ul><h3 id="select-type-列（很重要）"><a href="#select-type-列（很重要）" class="headerlink" title="select_type 列（很重要）"></a>select_type 列（很重要）</h3><p>查询类型，主要用于区别 普通查询、联合查询（union、union all）、子查询等复杂查询。</p><ul><li><p>simple：表示不需要union操作或者不包含子查询的简单select查询。有连接查询时，外层的查询为simple，且只有一个。</p></li><li><p>primary：一个需要使用union的操作或者含有子查询的select，位于最外层的单位查询的select_type即为primary。且只有一个</p></li><li><p>subquery:除了from子句中包含的子查询外，其它地方出现的子查询都可能时subquery</p></li><li><p>dependent subquery:子查询的结果受到外层的影响</p></li><li><p>union、union result:union 连接的多表查询，第一个查询primary，后面的是union, 结果集是 union result</p></li><li><p>dependent union:和union一样，出现在union或者union all中，但是这个查询要受到外部查询的影响</p></li><li><p>derived:在from子句后面的子查询，也叫派生表,注意，在MySql5.6 对于此查询没有优化，所以查询类型是derived.在mysql 5.7 使用了 Merge Derived table 优化，查询类型变为SIMPLE。通过控制参数: optimizer_switch=’derived=on|off’ 决定开始还是优化。默认开启。</p></li></ul><h2 id="table列"><a href="#table列" class="headerlink" title="table列"></a>table列</h2><ul><li><p>显示的查询表名，如果查询使用了别名，那么这里显示的就是别名</p></li><li><p>如果不涉及对数据表的操作，那么这里就是null</p></li><li><p>如果显示为尖括号括起来<derived N>就表示这是一个临时表，N就是执行计划的id，表示结果来自这个查询</p></li><li><p>如果显示为尖括号括起来的&lt;union n,m&gt;也表示一个临时表，表示来自union查询id为n、m的结果集</p></li></ul><h2 id="partitions-列"><a href="#partitions-列" class="headerlink" title="partitions 列"></a>partitions 列</h2><p>分区信息</p><h2 id="type-列-（重要）"><a href="#type-列-（重要）" class="headerlink" title="type 列 （重要）"></a>type 列 （重要）</h2><p>依次从好到差：</p><pre><code>system、const、eq_ref、ref、full_text、ref_or_null、unique_subquery、index_subquery、range、index_merge、index、all</code></pre><p>除了 All 以外，其它的类型都可以用到索引，除了index_merge可以使用多个索引之外，其它的类型最多只能使用到一个索引。</p><ul><li><p>system：表中只有一行数据或者是空表</p></li><li><p>const：使用唯一索引或者主键，返回记录一定是一条的等值where条件时，通常type是const。</p></li><li><p>eq_ref:连接字段为主键或者唯一索引，此类型通常出现于多表的join查询，表示对于前表的每一个结果，都对应后表的唯一一条结果。并且查询的比较是=操作，查询效率比较高。</p></li><li><p>ref:</p><ol><li>非主键或者唯一键的等值查询</li><li>join连接字段是非主键或者唯一键</li><li>最左前缀索引匹配</li></ol></li><li><p>fulltext:全文检索索引。</p></li><li><p>ref_or_null:和ref类似，增加了null值判断</p></li><li><p>unique_subquery、 index_subquery:都是子查询，前者返回唯一值，后者返回可能有重复。</p></li><li><p>range (重要):索引范围扫描，常用于 &gt;&lt;,is null,between,in,like等</p></li><li><p>index_merge(索引合并):表示查询使用了两个或者以上的索引数量，常见于and或者or查询匹配上了多个不同索引的字段</p></li><li><p>index(辅助索引):减少回表次数,因为要查询的索引都在一颗索引树上</p></li><li><p>all: 全表扫描</p></li></ul><h2 id="possible-keys-列"><a href="#possible-keys-列" class="headerlink" title="possible_keys 列"></a>possible_keys 列</h2><p>此次查询中，可能选用的索引</p><h2 id="key列"><a href="#key列" class="headerlink" title="key列"></a>key列</h2><p>查询实际使用的索引，select_type为index_merge时，key列可能有多个索引，其它时候这里只会有一个</p><h2 id="key-len-列"><a href="#key-len-列" class="headerlink" title="key_len 列"></a>key_len 列</h2><ul><li>用于处理查询的索引长度，如果是单列索引，那么整个索引长度都会计算进去，如果是多列索引，那么查询不一定能使用到所有的列，具体使用了多少个列的索引，这里就会计算进去，没有使用到的索引，这里不会计算进去。</li><li>留意一下这个长度，计算一下就知道这个索引使用了多少列</li><li>另外，key_len 只计算 where 条件使用到索引长度，而排序和分组就算用到了索引也不会计算key_len</li></ul><h2 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h2><ul><li>如果是使用的常数等值查询，这里会显示const</li><li>如果是连接查询，被驱动表的执行计划这里会显示驱动表的关联字段</li><li>如果是条件使用了表达式或者函数，或者条件列发生了内部隐式转换，这里可能会显示func</li></ul><h2 id="rows"><a href="#rows" class="headerlink" title="rows"></a>rows</h2><p>执行计划估算的扫描行数，不是精确值（innodb不是精确值，myisam是精确值，主要是因为innodb使用了mvcc）</p><h2 id="extra"><a href="#extra" class="headerlink" title="extra"></a>extra</h2><p>这个列包含很多不适合在其它列显示的重要信息，有很多种，常用的有：</p><ul><li><p>using temporary</p></li><li><p>表示使用了临时表存储中间结果   </p></li><li><p>MySQL在对 order by和group by 时使用临时表</p></li><li><p>临时表可以是内存临时表和磁盘临时表，执行计划中看不出来，需要查看status变量：used_tmp_table、used_tmp_disk_table才可以看出来</p></li><li><p>no table used</p></li><li><p>不带from字句的查询或者from dual查询（explain select 1;）</p></li></ul><p>使用 not in() 形式的子查询查询或者not exists运算符的连接查询，这种叫做反链接</p><pre><code>即：一般连接先查询内表再查询外表，反链接就是先查询外表再查询内表</code></pre><ul><li><p>using filesort</p></li><li><p>排序时无法使用到所以就会出现这个，常见于order by和group by</p></li><li><p>说明MySQL会使用一个外部的索引进行排序，而不是按照索引顺序进行读取</p></li><li><p>MySQL中无法利用索引完成的排序就叫“文件排序”</p></li><li><p>using index 查询时候不需要回表</p><ul><li>表示相应的select查询中使用到了覆盖索引(Covering index)，避免访问表的数据行</li><li>如果同时出现了using where，说明索引被用来执行查询键值如果没有using where，表示读取数据而不是执行查找操作</li></ul></li><li><p>using where</p><ul><li>表示存储引擎返回的记录并不都是符合条件的，需要在server层进行筛选过滤，性能很低</li></ul></li><li><p>using index condition</p><ul><li>索引下推，不需要再在server层进行过滤,5.6.x开始支持</li></ul></li><li><p>first match</p><ul><li>5.6.x 开始出现的优化子查询的新特性之一，常见于where字句含有in()类型的子查询，如果内表数据量过大，可能出现</li></ul></li><li><p>loosescan</p><ul><li>5.6.x 开始出现的优化子查询的新特性之一，常见于where字句含有in()类型的子查询，如果内表返回有重复值，可能出现</li></ul></li></ul><h2 id="filtered-列"><a href="#filtered-列" class="headerlink" title="filtered 列"></a>filtered 列</h2><p>5.7之后的版本默认就有这个字段，不需要使用explain extended了。这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;MySQL 提供了一个EXPALIN 命令，可以用于对SQL语句的执行计划进行分析，并详细的输出分析结果，供开发人员进行针对性的优化。&lt;/p&gt;
&lt;p&gt;我们想要查询一条sql有没有用上索引，有没有全表查询，这些都可以通过explain这个命令来查看。&lt;/p&gt;
&lt;p&gt;通过exp</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="Explain" scheme="http://example.com/tags/Explain/"/>
    
  </entry>
  
  <entry>
    <title>MySQL日志和索引相关问题</title>
    <link href="http://example.com/2022/04/10/MySQL%E6%97%A5%E5%BF%97%E5%92%8C%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2022/04/10/MySQL%E6%97%A5%E5%BF%97%E5%92%8C%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</id>
    <published>2022-04-10T06:50:00.000Z</published>
    <updated>2022-04-10T07:15:47.220Z</updated>
    
    <content type="html"><![CDATA[<h3 id="MySQL怎么知道binlog是完整的"><a href="#MySQL怎么知道binlog是完整的" class="headerlink" title="MySQL怎么知道binlog是完整的?"></a>MySQL怎么知道binlog是完整的?</h3><p>一个事务的binlog是有完整格式的：</p><ul><li>statement格式的binlog，最后会有COMMIT； </li><li>row格式的binlog，最后会有一个XID event。<br>另外，在MySQL 5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性。对于binlog日志由于磁盘原因，可能会在日志中间出错的情况，MySQL可以通过校验checksum的结果来发现。所以，MySQL还是有办法验证事务binlog的完整性的。</li></ul><h3 id="redo-log-和binlog是怎么关联起来的"><a href="#redo-log-和binlog是怎么关联起来的" class="headerlink" title="redo log 和binlog是怎么关联起来的?"></a>redo log 和binlog是怎么关联起来的?</h3><p>它们有一个共同的数据字段，叫XID。崩溃恢复的时候，会按顺序扫描redo log：</p><ul><li>如果碰到既有prepare、又有commit的redo log，就直接提交； </li><li>如果碰到只有parepare、而没有commit的redo log，就拿着XID去binlog找对应的事务。</li></ul><h3 id="为什么需要两阶段提交？先写redo-log，崩溃恢复时，必须两个日志都完整才可以，不是一样的吗？"><a href="#为什么需要两阶段提交？先写redo-log，崩溃恢复时，必须两个日志都完整才可以，不是一样的吗？" class="headerlink" title="为什么需要两阶段提交？先写redo log，崩溃恢复时，必须两个日志都完整才可以，不是一样的吗？"></a>为什么需要两阶段提交？先写redo log，崩溃恢复时，必须两个日志都完整才可以，不是一样的吗？</h3><p>回答：其实，两阶段提交是经典的分布式系统问题，并不是MySQL独有的。 如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。 对于InnoDB引擎来说，如果redo log提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果redo log直接提交，然后binlog写入的时候失败，InnoDB又回滚不了，数据和binlog日志又不一致了。 两阶段提交就是为了给所有人一个机会，当每个人都说“我ok”的时候，再一起提交。</p><h3 id="不引入两个日志，也就没有两阶段提交。只需要用redolog支持崩溃恢复和归档不是也可以吗？"><a href="#不引入两个日志，也就没有两阶段提交。只需要用redolog支持崩溃恢复和归档不是也可以吗？" class="headerlink" title="不引入两个日志，也就没有两阶段提交。只需要用redolog支持崩溃恢复和归档不是也可以吗？"></a>不引入两个日志，也就没有两阶段提交。只需要用redolog支持崩溃恢复和归档不是也可以吗？</h3><p>回答：</p><p>如果只从崩溃恢复的角度来讲是可以的。你可以把binlog关掉，这样就没有两阶段提交了，但系统依然是crash-safe的。 </p><p>但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog都是开着的。因为binlog有着redo log无法替代的功能。 </p><p>一个是归档。redo log是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log也就起不到归档的作用。 </p><p>一个就是MySQL系统依赖于binlog。binlog作为MySQL一开始就有的功能，被用在了很多地方。 </p><p>其中，MySQL系统高可用的基础，就是binlog复制。 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费MySQL的binlog来更新 自己的数据。关掉binlog的话，这些下游系统就没法输入了。 总之，由于现在包括MySQL高可用在内的很多系统机制都依赖于binlog，所以“鸠占鹊巢”redo log还做不到。你看，发展生态是多么重要。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;MySQL怎么知道binlog是完整的&quot;&gt;&lt;a href=&quot;#MySQL怎么知道binlog是完整的&quot; class=&quot;headerlink&quot; title=&quot;MySQL怎么知道binlog是完整的?&quot;&gt;&lt;/a&gt;MySQL怎么知道binlog是完整的?&lt;/h3&gt;&lt;p&gt;</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
</feed>
