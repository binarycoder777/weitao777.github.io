<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-07-29T08:12:05.044Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>事件日志</title>
    <link href="http://example.com/2022/07/29/%E4%BA%8B%E4%BB%B6%E6%97%A5%E5%BF%97/"/>
    <id>http://example.com/2022/07/29/%E4%BA%8B%E4%BB%B6%E6%97%A5%E5%BF%97/</id>
    <published>2022-07-29T07:52:00.000Z</published>
    <updated>2022-07-29T08:12:05.044Z</updated>
    
    <content type="html"><![CDATA[<p>“日志用于记录系统运行期间发生过的离散事件。”</p><p> <img src="/images/pasted-248.png" alt="upload successful"></p><p> 从打印日志到分析查询之间，隔着收集、缓冲、聚合、加工、索引、存储等若干个步骤，这一整个链条中涉及大量值得注意的细节，复杂性并不亚于任何一项技术或业务功能的实现。</p><h3 id="日志输出"><a href="#日志输出" class="headerlink" title="日志输出"></a>日志输出</h3><p>从日志输出值得注意的事项开始，日志的输出应避免以下情况：</p><ul><li>避免打印敏感信息。</li><li>避免引用慢操作。</li><li>避免打印追踪诊断信息：日志中不要打印方法输入参数、输出结果、方法执行时长之类的调试信息。日志的职责是记录时间，追踪诊断应由链路系统去做。</li><li>避免误导他人：日志中给日后调试除错的人挖坑是十分恶劣却又常见的行为。</li><li>处理请求时的TraceID：服务收到请求时，如果该请求没有附带TraceID，就应该自动生成唯一的TraceID来对请求进行标记，并使用MDC自动输出到日志。“TraceID会贯穿整条调用链，目的是通过它把请求在分布式系统各个服务中的执行过程串联起来。TraceID通常也会随着请求的响应返回到客户端，如果响应内容出现了异常，用户便能通过此ID快速找到与问题相关的日志。”</li><li>系统运行过程中的关键事件</li><li>启动时输出配置信息。</li></ul><h3 id="收集与缓存"><a href="#收集与缓存" class="headerlink" title="收集与缓存"></a>收集与缓存</h3><p>“为了能看到跨节点的全部日志，就要有能覆盖整个链路的全局日志系统。这个需求决定了每个节点输出日志到文件后，必须将日志文件统一收集起来集中存储、索引，由此便催生了专门的日志收集器。”</p><p>“日志收集器不仅要保证能覆盖全部数据来源，还要尽力保证日志数据的连续性，这其实并不容易做到。譬如淘宝这类大型的互联网系统，每天的日志量超过了10 000TB（10PB）量级，日志收集器的部署实例数能到达百万量级[1]，此时归集到系统中的日志要与实际产生的日志保持绝对的一致性是非常困难的，也不应该为此付出过高成本。换言之，日志不追求绝对的完整精确，只追求在代价可承受的范围内尽可能地保证较高的数据质量。一种最常用的缓解压力的做法是将日志接收者从Logstash和Elasticsearch转移至抗压能力更强的队列缓存，譬如在Logstash之前架设一个Kafka或者Redis作为缓冲层，面对突发流量，Logstash或Elasticsearch处理能力出现瓶颈时自动削峰填谷，甚至当它们短时间停顿时，也不会丢失日志数据。”</p><h3 id="加工与聚合"><a href="#加工与聚合" class="headerlink" title="加工与聚合"></a>加工与聚合</h3><p>“在将日志集中收集之后，存入Elasticsearch之前，一般还要对它们进行加工转换和聚合处理。这是因为日志是非结构化数据，一行日志中通常会包含多项信息，如果不做处理，那在Elasticsearch中就只能以全文检索的原始方式去使用日志，既不利于统计对比，也不利于条件过滤。”</p><h3 id="存储与查询"><a href="#存储与查询" class="headerlink" title="存储与查询"></a>存储与查询</h3><p>“经过收集、缓冲、聚合、加工的日志数据，终于可以放入Elasticsearch中索引存储了。Elasticsearch是整个Elastic Stack技术栈的核心，其他步骤的工具，如Filebeat、Logstash、Kibana都有替代品，有自由选择的余地，唯独Elasticsearch在日志分析这方面完全没有什么值得一提的竞争者，几乎就是解决此问题的唯一答案。这样的结果与Elasticsearch本身是一款优秀产品有关，然而更关键的是Elasticsearch的优势正好与日志分析的需求完美契合。”</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;“日志用于记录系统运行期间发生过的离散事件。”&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-248.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
&lt;p&gt; 从打印日志到分析查询之间，隔着收集、缓冲、聚合、加工、索引、存储等若干个步骤</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="日志" scheme="http://example.com/tags/%E6%97%A5%E5%BF%97/"/>
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>可观测性</title>
    <link href="http://example.com/2022/07/29/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/"/>
    <id>http://example.com/2022/07/29/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/</id>
    <published>2022-07-29T07:41:00.000Z</published>
    <updated>2022-07-29T07:51:37.410Z</updated>
    
    <content type="html"><![CDATA[<p>可观测性即：可以由外部输出推断其内部状态。具体可以分解为：事件日志、链路追踪以及聚合度量三部分，这三个方向各有侧重，又有重合或者可以结合支出。</p><p> <img src="/images/pasted-247.png" alt="upload successful"></p><p> “日志（Logging）：日志的职责是记录离散事件，通过这些记录分析出程序的行为，譬如曾经调用过什么方法，曾经操作过哪些数据，等等。输出日志很容易，但收集和分析日志可能会很复杂，面对成千上万的集群节点，面对迅速滚动的事件信息，面对以TB计算的文本，传输与归集并不简单。对大多数程序员来说，分析日志也许就是最常遇见也最有实践可行性的“大数据系统”了。”</p><p>“·追踪（Tracing）：单体系统时代追踪的范畴基本只局限于栈追踪（Stack Tracing），例如调试程序时，在IDE打个断点，看到的调用栈视图上的内容便是追踪；编写代码时，处理异常调用了Exception::printStackTrace()方法，它输出的堆栈信息也是追踪。微服务时代，追踪就不只局限于调用栈了，一个外部请求需要内部若干服务的联动响应，这时候完整的调用轨迹将跨越多个服务，同时包括服务间的网络传输信息与各个服务内部的调用堆栈信息，因此，分布式系统中的追踪在国内常被称为“全链路追踪”（后文简称“链路追踪”），许多资料中也称它为“分布式追踪”（Distributed Tracing）。追踪的主要目的是排查故障，如分析调用链的哪一部分、哪个方法出现错误或阻塞，输入输出是否符合预期，等等。”</p><p>“度量（Metrics）：度量是指对系统中某一类信息的统计聚合。譬如，证券市场的每一只股票都会定期公布财务报表，通过财报上的营收、净利、毛利、资产、负载等一系列数据来体现过去一个财务周期中公司的经营状况，这便是一种信息聚合。Java天生自带一种基本的度量，即由虚拟机直接提供的JMX（Java Management eXtensions）度量，诸如内存大小、各分代的用量、峰值的线程数、垃圾收集的吞吐量、频率等都可以从JMX中获得。度量的主要目的是监控（Monitoring）和预警（Alert），如在某些度量指标达到风险阈值时触发事件，以便自动处理或者提醒管理员介入。”</p><p>“追踪方面的情况与日志、度量有所不同，追踪是与具体网络协议、程序语言密切相关的。收集日志不必关心这段日志是由Java程序输出的还是由Golang程序输出的，对程序来说它们就只是一段非结构化文本而已，同理，度量对程序来说也只是一个个聚合的数据指标而已。但链路追踪不一样，各个服务之间是使用HTTP还是gRPC来进行通信会直接影响追踪的实现，各个服务是使用Java、Golang还是Node.js来编写，也会直接影响进程内调用栈的追踪方式。这种特性决定了追踪工具本身有较强的侵入性，通常是以插件式的探针来实现；也决定了追踪领域很难出现一家独大的情况，通常要有多种产品来针对不同的语言和网络进行追踪。”</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;可观测性即：可以由外部输出推断其内部状态。具体可以分解为：事件日志、链路追踪以及聚合度量三部分，这三个方向各有侧重，又有重合或者可以结合支出。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-247.png&quot; alt=&quot;upload successful&quot;</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="可观测性" scheme="http://example.com/tags/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>事务处理（一）</title>
    <link href="http://example.com/2022/07/28/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://example.com/2022/07/28/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2022-07-28T02:03:00.000Z</published>
    <updated>2022-07-28T02:20:36.908Z</updated>
    
    <content type="html"><![CDATA[<p>“事务处理几乎在每一个信息系统中都会涉及，它存在的意义是为了保证系统中所有的数据都是符合期望的，且相互关联的数据之间不会产生矛盾，即数据状态的一致性（Consistency）。按照数据库的经典理论，要达成这个目标，需要三方面共同努力来保障。</p><p>·原子性（Atomic）：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。</p><p>·隔离性（Isolation）：在不同的业务处理过程中，事务保证了各业务正在读、写的数据相互独立，不会彼此影响。</p><p>·持久性（Durability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。”</p><p>“A、I、D是手段，C是目的，前者是因，后者是果”</p><p>“当一个服务只使用一个数据源时，通过A、I、D来获得一致性是最经典的做法，也是相对容易的。此时，多个并发事务所读写的数据能够被数据源感知是否存在冲突，并发事务的读写在时间线上的最终顺序是由数据源来确定的，这种事务间一致性被称为“内部一致性”。<br> ·当一个服务使用到多个不同的数据源，甚至多个不同服务同时涉及多个不同的数据源时，问题就变得困难了许多。此时，并发执行甚至是先后执行的多个事务，在时间线上的顺序并不由任何一个数据源来决定，这种涉及多个数据源的事务间一致性被称为“外部一致性”。”</p><p> “外部一致性问题通常很难使用A、I、D来解决，因为这样需要付出很大甚至不切实际的代价；但是外部一致性又是分布式系统中必然会遇到且必须要解决的问题，为此我们要转变观念，将一致性从“是或否”的二元属性转变为可以按不同强度分开讨论的多元属性，在确保代价可承受的前提下获得强度尽可能高的一致性保障”</p><h3 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h3><p>“本地事务是指仅操作单一事务资源的、不需要全局事务管理器进行协调的事务”</p><p>“本地事务是一种最基础的事务解决方案，只适用于单个服务使用单个数据源的场景。从应用角度看，它是直接依赖于数据源本身提供的事务能力来工作的，在程序代码层面，最多只能对事务接口做一层标准化的包装（如JDBC接口），并不能深入参与到事务的运作过程中，事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作，这一点与后续介绍的XA、TCC、SAGA等主要靠应用程序代码来实现的事务有着十分明显的区别。”</p><p>“原子性和持久性在事务里是密切相关的两个属性：原子性保证了事务的多个操作要么都生效要么都不生效，不会存在中间状态；持久性保证了一旦事务生效，就不会再因为任何原因而导致其修改的内容被撤销或丢失。”</p><p>“实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观存在着“正在写”的中间状态。由于写入中间状态与崩溃都不可能消除，所以如果不做额外保障措施的话，将内存中的数据写入磁盘，并不能保证原子性与持久性。”</p><p>“为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中的变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即以仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。只有在日志记录全部安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化，这种事务实现方法被称为“提交日志”（Commit Logging）。”</p><p>“通过日志实现事务的原子性和持久性是当今的主流方案，但并不是唯一的选择。除日志外，还有另外一种称为“Shadow Paging”（有中文资料翻译为“影子分页”）的事务实现机制，常用的轻量级数据库SQLite Version 3采用的事务机制就是Shadow Paging。”</p><p>“Shadow Paging的大体思路是对数据的变动会写到硬盘的数据中，但不是直接就地修改原先的数据，而是先复制一份副本，保留原数据，修改副本数据。在事务处理过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。当事务成功提交，所有数据的修改都成功持久化之后，最后一步是修改数据的引用指针，将引用从原数据改为新复制并“hadow Paging的大体思路是对数据的变动会写到硬盘的数据中，但不是直接就地修改原先的数据，而是先复制一份副本，保留原数据，修改副本数据。在事务处理过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。当事务成功提交，所有数据的修改都成功持久化之后，最后一步是修改数据的引用指针，将引用从原数据改为新复制并修改后的副本，最后的“修改指针”这个操作将被认为是原子操作，现代磁盘的写操作的作用可以认为是保证了在硬件上不会出现“改了半个值”的现象。所以Shadow Paging也可以保证原子性和持久性。Shadow Paging实现事务要比Commit Logging更加简单，但涉及隔离性与并发锁时，Shadow Paging实现的事务并发能力就相对有限，因此在高性能的数据库中应用”</p><p>隔离性：“不同隔离级别以及幻读、不可重复读、脏读等问题都只是表面现象，是各种锁在不同加锁时间上组合应用所产生的结果，以锁为手段来实现隔离性才是数据库表现出不同隔离级别的根本原因。”</p><h3 id="全局事务"><a href="#全局事务" class="headerlink" title="全局事务"></a>全局事务</h3><p>“本地事务相对的是全局事务（Global Transaction），在一些资料中也将其称为外部事务（External Transaction），在本节里，全局事务被限定为一种适用于单个服务使用多个数据源场景的事务解决方案。请注意，理论上真正的全局事务并没有“单个服务”的约束，它本来就是DTP（Distributed Transaction Processing，分布式事务处理）模型[1]中的概念，但本节讨论的是一种在分布式环境中仍追求强一致性的事务处理方案，对于多节点而且互相调用彼此服务的场合（典型的就是现在的微服务系统）是极不合适的，当前它几乎只实际应用于单服务多数据源的场合中，为了避免与后续介绍的放弃了ACID的弱一致性事务处理方式混淆，所以这里的全局事务的范围有所缩减，后续涉及多服务多数据源的事务，笔者将称其为“分布式事务”。”</p><p>“为了解决分布式事务的一致性问题，X/Open组织（后来并入了The Open Group）提出了一套名为X/Open XA（XA是eXtended Architecture的缩写）的处理事务架构，其核心内容是定义了全局的事务管理器（Transaction Manager，用于协调全局事务）和局部的资源管理器（Resource Manager，用于驱动本地事务）之间的通信接口。XA接口是双向的，能在一个事务管理器和多个资源管理器（Resource Manager）之间形成通信桥梁，通过协调多个数据源的一致动作，实现全局事务的统一提交或者统一回滚，现在我们在Java代码中还偶尔能看见的XADataSource、XAResource都源于此。</p><p>不过，XA并不是Java的技术规范（XA提出那时还没有Java），而是一套语言无关的通用规范，所以Java中专门定义了JSR 907 Java Transaction API，基于XA模式在Java语言中实现了全局事务处理的标准，这也是我们现在所熟知的JTA。”</p><p>“XA将事务提交拆分成两阶段。”</p><p>“准备阶段：又叫作投票阶段，在这一阶段，协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复Prepared，否则回复Non-Prepared。这里所说的准备操作跟人类语言中通常理解的准备不同，对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条Commit Record而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。</p><p>·提交阶段：又叫作执行阶段，协调者如果在上一阶段收到所有事务参与者回复的Prepared消息，则先自己在本地持久化事务状态为Commit，然后向所有参与者发送Commit指令，让所有参与者立即执行提交操作；否则，任意一个参与者回复了Non-Prepared消息，或任意一个参与者超时未回复时，协调者将在自己完成事务状态为[…]”</p><p>“以上这两个过程被称为“两段式提交”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件。”</p><p>“必须假设网络在提交阶段的短时间内是可靠的，即提交阶段不会丢失消息。同时也假设网络通信在全过程都不会出现误差，即可以丢失消息，但不会传递错误的消息，XA的设计目标并不是解决诸如拜占庭将军一类的问题。在两段式提交中，投票阶段失败了可以补救（回滚），提交阶段失败了则无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险。<br> ·必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，进而向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。”</p><p> <img src="/images/pasted-245.png" alt="upload successful"></p><p>三段式提交把原本的两段式提交的准备阶段再细分为两个阶段，分别称为CanCommit、PreCommit，把提交阶段改称为DoCommit阶段。其中，新增的CanCommit是一个询问阶段，即协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。将准备阶段一分为二的理由是这个阶段是重负载的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，它们所涉及的数据资源即被锁住，如果此时某一个参与者宣告无法完成提交，相当于大家都做了一轮无用功。所以，增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，这也意味着因某个参与者提交时发生崩溃而导致大家全部回滚的风险相对变小。因此，在事务需要回滚的场景中，三段式提交的性能通常要比两段式提交好很多，但在事务能够正常提交的场景中[…]”</p><p> <img src="/images/pasted-246.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;“事务处理几乎在每一个信息系统中都会涉及，它存在的意义是为了保证系统中所有的数据都是符合期望的，且相互关联的数据之间不会产生矛盾，即数据状态的一致性（Consistency）。按照数据库的经典理论，要达成这个目标，需要三方面共同努力来保障。&lt;/p&gt;
&lt;p&gt;·原子性（Atom</summary>
      
    
    
    
    <category term="事务" scheme="http://example.com/categories/%E4%BA%8B%E5%8A%A1/"/>
    
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>redis的二进制位数组</title>
    <link href="http://example.com/2022/07/27/redis%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BD%8D%E6%95%B0%E7%BB%84/"/>
    <id>http://example.com/2022/07/27/redis%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BD%8D%E6%95%B0%E7%BB%84/</id>
    <published>2022-07-27T13:40:00.000Z</published>
    <updated>2022-07-27T13:56:11.470Z</updated>
    
    <content type="html"><![CDATA[<p>redis提供了setbit、getbit、bitcount、bitop指令来处理二进制位数组。而实际上，redis是使用字符串对象的SDS来表示位数组的，因为SDS数据结构是二进制安全的，并且可以使用SDS的相关函数。但值得注意的是，关于其二进制数组在SDS数据结构中是逆序存放的，主要用于简化setbit命令时涉及到扩容时移动元素的问题。</p><h3 id="getbit命令的实现"><a href="#getbit命令的实现" class="headerlink" title="getbit命令的实现"></a>getbit命令的实现</h3><ol><li>计算byte = offset / 8 :byte记录了offset值记录的偏移量保存在那个字节</li><li>计算bit =  offset % 8 + 1 ：bit记录了在指定字节上的偏移量</li><li>根据byte和bit定位</li></ol><h3 id="setbit命令的实现"><a href="#setbit命令的实现" class="headerlink" title="setbit命令的实现"></a>setbit命令的实现</h3><ol><li>计算len = offset / 8 + 1：计算保存数据的偏移量</li><li>检测是否足够空间</li><li>不足够，扩容</li><li>足够，则加进去（根据byte和bit的偏移量）</li></ol><p>(逆序存放作用便在此，扩容不需要移动元素)</p><h3 id="bitcount命令的实现"><a href="#bitcount命令的实现" class="headerlink" title="bitcount命令的实现"></a>bitcount命令的实现</h3><p>我们很容易能想到通过遍历来实现该指令，但显然遍历的效率并不高，因此我们可以创建一个表，表的键为某种排列的数组，值为相应的数组中1的数量，但查表的实际效果收到内存和缓存的影响（特别是数据量大的时候）。在redis中，使用的是variable-precision SWAR算法来实现的。感兴趣的可以去查阅资料了解一下。</p><h3 id="bitop命令的实现"><a href="#bitop命令的实现" class="headerlink" title="bitop命令的实现"></a>bitop命令的实现</h3><p>常规的变量做比较，&amp;，|之类，因为SDS支持这些操作。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;redis提供了setbit、getbit、bitcount、bitop指令来处理二进制位数组。而实际上，redis是使用字符串对象的SDS来表示位数组的，因为SDS数据结构是二进制安全的，并且可以使用SDS的相关函数。但值得注意的是，关于其二进制数组在SDS数据结构中是逆</summary>
      
    
    
    
    <category term="Redis" scheme="http://example.com/categories/Redis/"/>
    
    
    <category term="Redis" scheme="http://example.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>CPU Cache的数据结构和读取过程</title>
    <link href="http://example.com/2022/07/10/CPU-Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E8%AF%BB%E5%8F%96%E8%BF%87%E7%A8%8B/"/>
    <id>http://example.com/2022/07/10/CPU-Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E8%AF%BB%E5%8F%96%E8%BF%87%E7%A8%8B/</id>
    <published>2022-07-10T13:43:00.000Z</published>
    <updated>2022-07-10T13:51:35.402Z</updated>
    
    <content type="html"><![CDATA[<p>CPU Cache 的数据是从内存中读取过来的，它是以⼀⼩块⼀⼩块读取数据的，⽽不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样⼀⼩块⼀⼩块的数据，称为Cache Line（缓存块）。</p><p>事实上，CPU 读取数据的时候，⽆论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读⼊到 Cache 中，CPU 再从 CPU Cache 读取数据。</p><p>那 CPU 怎么知道要访问的内存数据，是否在 Cache ⾥？如果在的话，如何找到 Cache 对应的数据呢？我们从最简单、基础的直接映射 Cache（Direct Mapped Cache）说起，来看看整个 CPU Cache 的数据结构和访问逻辑。</p><h3 id="直接映射"><a href="#直接映射" class="headerlink" title="直接映射"></a>直接映射</h3><p>对于直接映射 Cache 采⽤的策略，就是把内存块的地址始终「映射」在⼀个 CPU Line（缓存块）的地址，⾄于映射关系实现⽅式，则是使⽤「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line</p><p>举个例⼦，内存共被划分为 32 个内存块，CPU Cache 共有 8 个 CPU Line，假设 CPU 想要访问第 15 号内存块，如果 15 号内存块中的数据已经缓存在 CPU Line 中的话，则是⼀定映射在 7 号 CPU Line 中，因15 % 8 = 7</p><p>机智的你肯定发现了，使⽤取模⽅式映射的话，就会出现多个内存块对应同⼀个 CPU Line，⽐如上⾯的例⼦，除了 15 号内存块是映射在 7 号 CPU Line 中，还有 7 号、23 号、31 号内存块都是映射到 7 号 CPU Line 中。</p><p> <img src="/images/pasted-243.png" alt="upload successful"></p><p> 因此，为了区别不同的内存块，在对应的 CPU Line 中我们还会存储⼀个组标记（Tag）。这个组标记会记录当前 CPU Line 中存储的数据对应的内存块，我们可以⽤这个组标记来区分不同的内存块。</p><p> 除了组标记信息外，CPU Line 还有两个信息：</p><ul><li>⼀个是，从内存加载过来的实际存放数据（Data）。</li><li>另⼀个是，有效位（Valid bit），它是⽤来标记对应的 CPU Line 中的数据是否是有效的，如果有效位是 0，⽆论 CPU Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。</li></ul><p> CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，⽽是读取 CPU 所需要的⼀个数据⽚段，这样的数据统称为⼀个字（Word）。那怎么在对应的 CPU Line 中数据块中找到所需的字呢？答案是，需要⼀个偏移量（Offset）。</p><p> 因此，⼀个内存的访问地址，包括组标记、CPU Line 索引、偏移量这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。⽽对于 CPU Cache ⾥的数据结构，则是由索引 + 有效位 + 组标记 + 数据块组成。</p><p> <img src="/images/pasted-244.png" alt="upload successful"></p><p> 如果内存中的数据已经在 CPU Cahe 中了，那 CPU 访问⼀个内存地址的时候，会经历这 4 个步骤：</p><ol><li>根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Line 的地址；</li><li>找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是⽆效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执⾏；</li><li>对⽐内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执⾏；</li><li>根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字。<br>到这⾥，相信你对直接映射 Cache 有了⼀定认识，但其实除了直接映射 Cache 之外，还有其他通过内存地址找到 CPU Cache 中的数据的策略，⽐如全相连 Cache （Fully Associative Cache）、组相连 Cache（Set Associative Cache）等，这⼏种策策略的数据结构都⽐较相似，我们理解了直接映射 Cache 的⼯作⽅式，其他的策略如果你有兴趣去看，相信很快就能理解的了。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;CPU Cache 的数据是从内存中读取过来的，它是以⼀⼩块⼀⼩块读取数据的，⽽不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样⼀⼩块⼀⼩块的数据，称为Cache Line（缓存块）。&lt;/p&gt;
&lt;p&gt;事实上，CPU 读取数据的时候，⽆论数据是否存放到 C</summary>
      
    
    
    
    <category term="Cache" scheme="http://example.com/categories/Cache/"/>
    
    
    <category term="计算机组成原理" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    <category term="Cache" scheme="http://example.com/tags/Cache/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
  </entry>
  
  <entry>
    <title>hashCode 的计算逻辑中，为什么是 31 作为乘数？</title>
    <link href="http://example.com/2022/07/09/hashCode-%E7%9A%84%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E4%B8%AD%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-31-%E4%BD%9C%E4%B8%BA%E4%B9%98%E6%95%B0%EF%BC%9F/"/>
    <id>http://example.com/2022/07/09/hashCode-%E7%9A%84%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E4%B8%AD%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-31-%E4%BD%9C%E4%B8%BA%E4%B9%98%E6%95%B0%EF%BC%9F/</id>
    <published>2022-07-09T12:01:00.000Z</published>
    <updated>2022-07-09T12:13:44.655Z</updated>
    
    <content type="html"><![CDATA[<p> <img src="/images/pasted-241.png" alt="upload successful"><br> 在获取 hashCode 的源码中可以看到，有一个固定值 31，在 for 循环每次执行时<br>进行乘积计算，循环后的公式如下； s[0]*31^(n-1) + s[1]*31^(n-2) + … +<br>s[n-1]<br>那么这里为什么选择 31 作为乘积值呢？</p><ol><li>31 是一个奇质数，如果选择偶数会导致乘积运算时数据溢出。</li><li>另外在二进制中，2 个 5 次方是 32，那么也就是 31 * i == (i &lt;&lt; 5) - i。这主要是说乘积运算可以使用位移提升性能，同时目前的 JVM 虚拟机也会自动支持此类的优化。</li><li>经过大量测试，相对于其他数，31得到的hash碰撞结果最小</li></ol><p>当然一个好的哈希函数除了要尽量减少碰撞外，关于散列表也就是 hash，<br>还有一个非常重要的点，那就是要尽可能的让数据散列分布。只有这样才能减少<br>hash 碰撞次数。</p><h3 id="扰动函数"><a href="#扰动函数" class="headerlink" title="扰动函数"></a>扰动函数</h3><p>在 HashMap 存放元素时候有这样一段代码来处理哈希值，这是 java 8 的散列值<br>扰动函数，用于优化散列效果；</p><p> <img src="/images/pasted-242.png" alt="upload successful"></p><p> 理论上来说字符串的 hashCode是一个 int 类型值，那可以直接作为数组下标了，<br>且不会出现碰撞。但是这个 hashCode 的取值范围是[-2147483648, 2147483647]，<br>有将近 40 亿的长度，谁也不能把数组初始化的这么大，内存也是放不下的。</p><p>我们默认初始化的 Map 大小是 16 个长度 DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4，<br>所以获取的 Hash 值并不能直接作为下标使用，需要与数组长度进行取模运算得<br>到一个下标值，也就是我们上面做的散列列子。</p><p>那么，hashMap 源码这里不只是直接获取哈希值，还进行了一次扰动计算，(h =<br>key.hashCode()) ^ (h &gt;&gt;&gt; 16)。把哈希值右移 16 位，也就正好是自己长度的一<br>半，之后与原哈希值做异或运算，这样就混合了原哈希值中的高位和低位，增大<br>了随机性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;img src=&quot;/images/pasted-241.png&quot; alt=&quot;upload successful&quot;&gt;&lt;br&gt; 在获取 hashCode 的源码中可以看到，有一个固定值 31，在 for 循环每次执行时&lt;br&gt;进行乘积计算，循环后的公式如下； s[0]*31</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="HashMap" scheme="http://example.com/tags/HashMap/"/>
    
  </entry>
  
  <entry>
    <title>Thread.start（）启动原理</title>
    <link href="http://example.com/2022/07/09/Thread-start%EF%BC%88%EF%BC%89%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2022/07/09/Thread-start%EF%BC%88%EF%BC%89%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86/</id>
    <published>2022-07-09T09:00:00.000Z</published>
    <updated>2022-07-09T10:52:32.322Z</updated>
    
    <content type="html"><![CDATA[<p>java中启动一个线程很简单</p><p>new Thread(()-&gt;{</p><p>// TODD</p><p>}).start();</p><p>但是这个线程是如何启动起来的呢？主要会经过下面这个流程</p><p> <img src="/images/pasted-237.png" alt="upload successful"></p><ol><li>线程的启动涉及到本地方法JNI的调用</li><li>具体的线程是映射到操作系统层面由操作系统处理</li><li>线程的启动涉及到线程的生命周期状态以及唤醒操作，所有有回调操作run()</li></ol><p>具体的UML图如下<br> <img src="/images/pasted-238.png" alt="upload successful"></p><h3 id="Java-层面-Thread-启动"><a href="#Java-层面-Thread-启动" class="headerlink" title="Java 层面 Thread 启动"></a>Java 层面 Thread 启动</h3><p>new Thread(() -&gt; {</p><p>// todo</p><p>}).start();</p><p>// JDK 源码</p><p>public synchronized void start() {</p><p>if (threadStatus != 0)</p><p>throw new IllegalThreadStateException();</p><p>group.add(this);</p><p>boolean started = false;</p><p>try {</p><p>start0();</p><p>started = true;</p><p>} finally {</p><p>try {</p><p>if (!started) {</p><p>group.threadStartFailed(this);</p><p>} } catch (Throwable ignore) {}</p><p>} }</p><p> 线程启动方法 start()，在它的方法英文注释中已经把核心内容描述出来。<br>Causes this thread to begin execution; the Java Virtual<br>Machine calls the run method of this thread. 这段话的意思<br>是：由 JVM 调用此线程的 run 方法，使线程开始执行。其实这就是一个 JVM 的<br>回调过程，下文源码分析中会讲到</p><p> 另外 start() 是一个 synchronized 方法，但为了避免多次调用，在方法中<br>会由线程状态判断。threadStatus != 0。 </p><p> group.add(this)，是把当前线程加入到线程组，ThreadGroup。 </p><p> start0()，是一个本地方法，通过 JNI 方式调用执行。这一步的操作才是启动<br>线程的核心步骤。</p><p> <img src="/images/pasted-239.png" alt="upload successful"></p><p> start0()，是一个本地方法，用于启动线程。</p><p> registerNatives()，这个方法是用于注册线程执行过程中需要的一些本地方<br>法，比如：start0、isAlive、yield、sleep、interrupt0 等。</p><p>后面线程的启动过程涉及到了 JVM 的参与，整个源码分析可以结合着代码调用 UML 时序图进行观看，基本核心过程包括：<br>Java 创建线程和启动、调用本地方法 start0()、JVM 中<br>JVM_StartThread 的创建和启动、设置线程状态等待被唤醒、根据不同<br>的 OS 启动线程并唤醒、最后回调 run() 方法启动 Java 线程</p><p>待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;java中启动一个线程很简单&lt;/p&gt;
&lt;p&gt;new Thread(()-&amp;gt;{&lt;/p&gt;
&lt;p&gt;// TODD&lt;/p&gt;
&lt;p&gt;}).start();&lt;/p&gt;
&lt;p&gt;但是这个线程是如何启动起来的呢？主要会经过下面这个流程&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="线程" scheme="http://example.com/tags/%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>打破双亲委派机制的一些场景</title>
    <link href="http://example.com/2022/07/05/%E6%89%93%E7%A0%B4%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF/"/>
    <id>http://example.com/2022/07/05/%E6%89%93%E7%A0%B4%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF/</id>
    <published>2022-07-05T11:42:00.000Z</published>
    <updated>2022-07-05T12:29:39.462Z</updated>
    
    <content type="html"><![CDATA[<p>前言：在说打破双亲委派机制的一些场景前，先聊一聊为什么需要双亲委派机制。</p><p>在双亲委派机制中，父子类通过组合的方式聚合在一起。由应用类加载器开始到系统类加器。主要是这几步：</p><ol><li>在自身的loadclass方法中先检查类是否已经被加载过</li><li>若没有加载则调用父类加载器的loadclass方法加载，若父类为空则默认用启动类加载器作为父加载器加载。</li><li>如果父类加载器失败，抛出异常classnotfoundexception后，调用自身的findclass方法进行加载类</li></ol><p>这样做的好处是一方面可以避免类的重复加载，当父类加载器已经加载过这个类时，子类不会再去加载。另一方面，通过这样的方式可以保证安全性。因为引导类加载在加载的时候只会加载JAVA_HOME的jar包，这个类及时被同名的类破坏也不会有影响，除非你本地jdk的jar被改写。即可以有效的防止核心java api被篡改。</p><p>而既然知道了双亲委派机制的实现，那么想要破坏双亲委派机制就简单了。只需要自定义一个类加载器，重写其中的loadclass方法，使其不进行双亲委派机制。而如果我们要自定义一个类加载器而又不想破坏双亲委派机制，只需集成classloader然后重写findclass方法。</p><p>而在某些场景下，我们却需要去打破双亲委派机制，比如我下面将要提到的几种</p><h3 id="JNDI、JDBC等"><a href="#JNDI、JDBC等" class="headerlink" title="JNDI、JDBC等"></a>JNDI、JDBC等</h3><p>在我们通过API调用一些java的基类时，存在一种SPI机制。比如JDBC。在类加载时，会先加载驱动DriverManger类，该类由类加载器加载。因为java.sql.DriverManger类位于rt.jar下面，会被根类加载器加载。而在其加载时，会执行静态方法，静态方法会尝试加载classpath下的所有实现driver接口的类。但这些实现类基本由各大数据库厂商实现，如果根据双亲委派机制来执行时行不通的。因为第三方的类不能被根加载器加载。因此，在jdbc中引入了线程上下文加载器的方式破坏双亲委派机制。</p><h3 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h3><p>在tomcat中为了应用程序访问不同存储库中的类和资源，达到应用类之间隔离的目的，打破了双亲委派机制。即为给个容器单独提供一个WebAppClassLoader加载器（优先加载web应用自身的类，即优先由WebAppClassLoader加载，加载不到在由CommonClassLoader加载，这和双亲委派刚好相反）。</p><p>Tomcat整体类加载器结构如下：<br> <img src="/images/pasted-235.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前言：在说打破双亲委派机制的一些场景前，先聊一聊为什么需要双亲委派机制。&lt;/p&gt;
&lt;p&gt;在双亲委派机制中，父子类通过组合的方式聚合在一起。由应用类加载器开始到系统类加器。主要是这几步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在自身的loadclass方法中先检查类是否已经被加载过&lt;/l</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="类加载机制" scheme="http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
    
    <category term="双亲委派机制" scheme="http://example.com/tags/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>Spring编程式事务</title>
    <link href="http://example.com/2022/06/17/Spring%E7%BC%96%E7%A8%8B%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2022/06/17/Spring%E7%BC%96%E7%A8%8B%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2022-06-17T08:55:00.000Z</published>
    <updated>2022-06-17T12:43:17.962Z</updated>
    
    <content type="html"><![CDATA[<p>描述：今天在做项目实现活动领取功能模块时，考虑到在系统中，用户的领取次数表和领取活动表的后续开销问题，在设计时通过自研的分库分表db-router-Spring-boot-starter组件对该功能涉及的两张表进行了分库操作。即让不同uid的用户产生的领取活动信息和活动次数信息打到不同的数据库上，减轻数据库的压力。但在后续开发时，发现涉及到两张表的修改，而这里又用到了分库操作，对数据源进行了切换。导致常用的@trancation注解在这里并不适用。为此，去温习了一下编程式事务，用于解决此处的问题。在这里记录一下。</p><p>编程式事务主要有2种用法</p><ul><li>方式1：通过PlatformTransactionManager控制事务</li><li>方式2：通过TransactionTemplate控制事务</li></ul><h3 id="方式1：PlatformTransactionManager"><a href="#方式1：PlatformTransactionManager" class="headerlink" title="方式1：PlatformTransactionManager"></a>方式1：PlatformTransactionManager</h3><ol><li>定义事务管理器PlatformTransactionManager<br>（事务管理器相当于一个管理员，这个管理员就是用来帮你控制事务的，比如开启事务，提交事务，回滚事务等等。spring中使用PlatformTransactionManager这个接口来表示事务管理器，PlatformTransactionManager多个实现类，用来应对不同的环境<br>）</li></ol><ul><li><p>JpaTransactionManager：如果你用jpa来操作db，那么需要用这个管理器来帮你控制事务。</p></li><li><p>DataSourceTransactionManager：如果你用是指定数据源的方式，比如操作数据库用的是：JdbcTemplate、mybatis、ibatis，那么需要用这个管理器来帮你控制事务。</p></li><li><p>HibernateTransactionManager：如果你用hibernate来操作db，那么需要用这个管理器来帮你控制事务。</p></li><li><p>JtaTransactionManager：如果你用的是java中的jta来操作db，这种通常是分布式事务，此时需要用这种管理器来控制事务。<br><img src="/images/pasted-234.png" alt="upload successful"></p></li></ul><ol start="2"><li><p>定义事务属性TransactionDefinition：定义事务属性，比如事务隔离级别、事务超时时间、事务传播方式、是否是只读事务等等。spring中使用TransactionDefinition接口来表示事务的定义信息，有个子类比较常用：DefaultTransactionDefinition。</p></li><li><p>开启事务：调用事务管理器的getTransaction方法，即可以开启一个事务，这个方法会返回一个TransactionStatus表示事务状态的一个对象，通过TransactionStatus提供的一些方法可以用来控制事务的一些状态，比如事务最终是需要回滚还是需要提交。（执行了getTransaction后，spring内部会执行一些操作。将数据源datasource和connection映射起来放在了ThreadLocal中。通过resources这个ThreadLocal获取datasource其对应的connection对象）</p></li><li><p>执行业务操作：用同一个dataSource，而事务管理器开启事务的时候，会创建一个连接，将datasource和connection映射之后丢在了ThreadLocal中，而JdbcTemplate内部执行db操作的时候，也需要获取连接，JdbcTemplate会以自己内部的datasource去上面的threadlocal中找有没有关联的连接，如果有直接拿来用，若没找到将重新创建一个连接，而此时是可以找到的，那么JdbcTemplate就参与到spring的事务中了。</p></li><li><p>提交或回滚</p></li></ol><p>分析：</p><p>TransactionTemplate，主要有2个方法：</p><p>executeWithoutResult：无返回值场景</p><p>executeWithoutResult(Consumer<TransactionStatus> action)：没有返回值的，需传递一个Consumer对象，在accept方法中做业务操作</p><p>execute：有返回值场景</p><p><T> T execute(TransactionCallback<T> action)：有返回值的，需要传递一个TransactionCallback对象，在doInTransaction方法中做业务操作</p><p>  通过上面2个方法，事务管理器会自动提交事务或者回滚事务。</p><p>什么时候事务会回滚，有2种方式</p><p>方式1</p><p>在execute或者executeWithoutResult内部执行transactionStatus.setRollbackOnly();将事务状态标注为回滚状态，spring会自动让事务回滚</p><p>方式2</p><p>execute方法或者executeWithoutResult方法内部抛出任意异常即可回滚。</p><p>总结：平时我们用的最多的是声明式事务，声明式事务的底层还是使用上面这种方式来控制事务的，只不过对其进行了封装，让我们用起来更容易些。了解不同的方法有助于我们在不同的场景的应用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;描述：今天在做项目实现活动领取功能模块时，考虑到在系统中，用户的领取次数表和领取活动表的后续开销问题，在设计时通过自研的分库分表db-router-Spring-boot-starter组件对该功能涉及的两张表进行了分库操作。即让不同uid的用户产生的领取活动信息和活动次数</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
    <category term="Spring" scheme="http://example.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>误删数据库后除了跑路，还能怎么办？</title>
    <link href="http://example.com/2022/06/15/%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/"/>
    <id>http://example.com/2022/06/15/%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/</id>
    <published>2022-06-15T14:23:00.000Z</published>
    <updated>2022-06-15T15:43:59.602Z</updated>
    
    <content type="html"><![CDATA[<p>传统的高可用架构是不能预防误删除数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。</p><p>为了找到解决误删数据库的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：</p><ol><li>使用delete语句误删数据行</li><li>使用drop table或者truncate table语句误删数据库</li><li>使用drop database语句误删数据库</li><li>使用rm命令误删整个MySQL实例</li></ol><h3 id="误删行"><a href="#误删行" class="headerlink" title="误删行"></a>误删行</h3><p>方案：使用delete语句误删了数据行，可以用Flashback工具通过闪回把数据恢复回来。</p><p>原理：修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row和binlog_row_image=FULL。</p><p>具体：</p><ol><li>对于insert语句，对应的binlog event类型是Write_rows event，把它改成Delete_rows event即可。</li><li>同理，对于delete语句，也是将Delete_rows event改为Write_rows event。</li><li>而如果是Update_rows的话,binlog里面记录了数据行修改前和修改后的值,对调这两行的位置即可。</li></ol><p>而对于误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。</p><p>当然恢复过程并不建议在主库上进行，而是恢复出一个备份，或者找一个从库作为临时库，在临时库上执行恢复操作，确认过数据无误后，在恢复回主库。（原因：一个在执行线上逻辑的主库，数据状态往往是有关联的。可能由于发现数据问题的实际晚了一点，就导致已经在之前误删的基础上，业务代码逻辑又继续修改了其他数据，如果这时进行数据恢复，未经确认，会导致出现对数据的二次破坏）</p><pre><code>    注意：不止要了解误删数据的事后处理方法，更重要的是做到事前预防。    建议：    1. 把sql_safe_updates参数设置成on，在delete或者update语句中写where，或者where条件不包含索引字段，这条语句就会报错。    2. 代码上线前，必须经过SQL审计</code></pre><h3 id="误删库-表"><a href="#误删库-表" class="headerlink" title="误删库/表"></a>误删库/表</h3><p>这种情况下，想要恢复数据就需要使用全量备份了，加增量日志的方式。这个方案要求线上定期的全量备份，并且实时备份binlog（因为对于drop/turncate table/database binlog记录的是statement格式，没法通过flasback进行恢复）</p><p>恢复数据的流程：</p><ol><li>取最近一次全量备份（假设是一天一备，上次备份是当天0点）</li><li>用备份恢复出一个临时库</li><li>从日志备份里面，取出凌晨0点之后的日志</li><li>把这些日志，除了误删除数据的语句外，全部应用到临时库</li></ol><p>说明：为了加速数据恢复，可以在mysqlbinlog加上-database，用来指定误删除表所在的库，但是这样还是不够快（1.误删表，不能指定解析一个表的日志；2.用mysqlbinlog解析出日志应用，应用日志的过程就只能是单线程）</p><p>误删库或表后，恢复数据的思路主要就是通过备份，再加上应用binlog的方式。最好把数据恢复功能做成自动化工具。</p><h3 id="延迟复制备库"><a href="#延迟复制备库" class="headerlink" title="延迟复制备库"></a>延迟复制备库</h3><p>延迟复制备库是一种特殊的备库，通过CHANGE MASTER TO_DELAY = N命令，可以指定这个备库持续保持主库有N秒的延迟。</p><h3 id="预防误删库表的方法"><a href="#预防误删库表的方法" class="headerlink" title="预防误删库表的方法"></a>预防误删库表的方法</h3><ul><li>账号分离，权限控制</li><li>制定操作规范</li><li>定期给开发进行培训</li><li>搭建延迟备库</li><li>做好sql审计</li><li>做好备份</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;传统的高可用架构是不能预防误删除数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。&lt;/p&gt;
&lt;p&gt;为了找到解决误删数据库的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：&lt;/p&gt;</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>关于ZAB协议</title>
    <link href="http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EZAB%E5%8D%8F%E8%AE%AE/"/>
    <id>http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EZAB%E5%8D%8F%E8%AE%AE/</id>
    <published>2022-05-25T14:02:00.000Z</published>
    <updated>2022-05-25T14:19:02.540Z</updated>
    
    <content type="html"><![CDATA[<p>Zab 借鉴了 Paxos 算法，是特别为 Zookeeper 设计的支持崩溃恢复的原子广播协议。基于该协议，Zookeeper 设计为只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader 客户端将数据同步到其他 Follower 节点。Zookeeper 只有一个 Leader 可以发起提案</p><p>Zab协议包括两种基本的模式：消息广播、崩溃恢复。</p><h3 id="消息广播"><a href="#消息广播" class="headerlink" title="消息广播"></a>消息广播</h3><p>ZAB协议针对事务请求的处理过程类似于一个两阶段提交过程</p><p>（1）广播事务阶段</p><p>（2）广播提交操作<br>这两阶段提交模型如下，有可能因为Leader宕机带来数据不一致，比如</p><p>（1） Leader 发 起 一 个 事 务Proposal1 后 就 宕 机 ， Follower 都 没有Proposal1 </p><p>（2）Leader收到半数ACK宕 机，没来得及向Follower发送Commit<br>怎么解决呢？ZAB引入了崩溃恢复模式。</p><p> <img src="/images/pasted-231.png" alt="upload successful"></p><p>（1）客户端发起一个写操作请求。 </p><p>（2）Leader服务器将客户端的请求转化为事务Proposal 提案，同时为每个Proposal 分配一个全局的ID，即zxid。 </p><p>（3）Leader服务器为每个Follower服务器分配一个单独的队列，然后将需要广播的 Proposal依次放到队列中去，并且根据FIFO策略进行消息发送。 </p><p>（4）Follower接收到Proposal后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向Leader反馈一个Ack响应消息。 </p><p>（5）Leader接收到超过半数以上Follower的Ack响应消息后，即认为消息发送成功，可以发送commit消息。 </p><p>（6）Leader向所有Follower广播commit消息，同时自身也会完成事务提交。Follower 接收到commit消息后，会将上一条事务提交。 </p><p>（7）Zookeeper采用Zab协议的核心，就是只要有一台服务器提交了Proposal，就要确保所有的服务器最终都能正确提交Proposal。</p><h3 id="崩溃恢复——异常假设"><a href="#崩溃恢复——异常假设" class="headerlink" title="崩溃恢复——异常假设"></a>崩溃恢复——异常假设</h3><p> 一旦Leader服务器出现崩溃或者由于网络原因导致Leader服务器失去了与过半 Follower的联系，那么就会进入崩溃恢复模式。</p><p> <img src="/images/pasted-232.png" alt="upload successful"></p><p> 假设两种服务器异常情况</p><ol><li>假设一个事务在Leader提出之后，Leader挂了</li><li>一个事务在Leader上提交了，并且过半的Follower都响应ACK了，但是Leader在Commit消息发出之前挂了。</li></ol><p> Zab协议崩溃恢复要满足以下两个要求</p><p> 1、 确保已经被Leader提交的提案Proposal，必须最终被所有的Follower服务器提交。 （已经产生的提案，Follower必须执行） </p><p> 2、 确保丢弃已经被Leader提出的，但是没有被提交的Proposal。（丢弃胎死腹中的提案）</p><p> 崩溃恢复主要包括两部分：Leader选举和数据恢复。</p><h3 id="崩溃恢复—Leader选举"><a href="#崩溃恢复—Leader选举" class="headerlink" title="崩溃恢复—Leader选举"></a>崩溃恢复—Leader选举</h3><p> <img src="/images/pasted-233.png" alt="upload successful"></p><p>Leader选举：根据上述要求，Zab协议需要保证选举出来的Leader需要满足以下条件：</p><p>（1）新选举出来的Leader不能包含未提交的Proposal。即新Leader必须都是已经提交了Proposal的Follower服务器节点。</p><p>（2）新选举的Leader节点中含有最大的zxid。这样做的好处是可以避免Leader服务器检查Proposal的提交和丢弃工作。</p><h3 id="崩溃恢复——数据恢复"><a href="#崩溃恢复——数据恢复" class="headerlink" title="崩溃恢复——数据恢复"></a>崩溃恢复——数据恢复</h3><p>Zab如何数据同步： </p><p>（1）完成Leader选举后，在正式开始工作之前（接收事务请求，然后提出新的Proposal），Leader服务器会首先确认事务日志中的所有的Proposal 是否已经被集群中过半的服务器Commit。</p><p>（2）Leader服务器需要确保所有的Follower服务器能够接收到每一条事务的Proposal，并且能将所有已经提交的事务Proposal应用到内存数据中。等到Follower将所有尚未同步的事务Proposal都从Leader服务器上同步过，并且应用到内存数据中以后，<br>Leader才会把该Follower加入到真正可用的Follower列表中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Zab 借鉴了 Paxos 算法，是特别为 Zookeeper 设计的支持崩溃恢复的原子广播协议。基于该协议，Zookeeper 设计为只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader 客户端将数据同步到其他 Follower 节点。Zookeepe</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="ZAB协议" scheme="http://example.com/tags/ZAB%E5%8D%8F%E8%AE%AE/"/>
    
    <category term="数据一致性" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>关于Paxos算法</title>
    <link href="http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EPaxos%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EPaxos%E7%AE%97%E6%B3%95/</id>
    <published>2022-05-25T13:38:00.000Z</published>
    <updated>2022-05-25T13:59:20.676Z</updated>
    
    <content type="html"><![CDATA[<p>Paxos算法是一种基于消息传递且具有高度容错特性的一致性算法。其通常用于快速正确的在一个分布式系统中对某个数据值达成一致，并且保证无论发送任何异常都不会破坏整个系统的一致性。</p><p> <img src="/images/pasted-226.png" alt="upload successful"></p><p> 在一个Paxos系统中，首先将所有节点划分为Proposer（提议者）、Acceptor（接受者）和Learner（学习者）</p><pre><code>     注意：每个节点可以身兼数职    </code></pre><p>一个完整的Paxos算法流程分为三个阶段</p><ol><li><p>Prepare准备阶段</p><ol><li>Proposer向多个Acceptor发出Propose请求Promise（承诺）</li><li>Acceptor针对收到的Propose请求进行Promise（承诺）</li></ol></li><li><p>Accept接受阶段</p><ol><li>Proposer收到多数Acceptor承诺的Promise后，向Acceptor发出Propose请求</li><li>Acceptor针对收到的Propose请求进行Accept处理</li></ol></li><li><p>Learn学习阶段</p><ol><li>Proposer将形成的决议发送给所有Learners</li></ol></li></ol><p> <img src="/images/pasted-227.png" alt="upload successful"></p><p> 1、 Prepare: Proposer生成全局唯一且递增的Proposal ID，向所有Acceptor发送Propose请求，这里无需携带提案内容，只携带Proposal ID即可。</p><p> 2、 Promise: Acceptor收到Propose请求后，做出“两个承诺，一个应答”。<br>    - 不再接受Proposal ID小于等于（注意：这里是&lt;= ）当前请求的Propose请求。<br>    - 不再接受Proposal ID小于（注意：这里是&lt; ）当前请求的Accept请求。<br>    - 不违背以前做出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。</p><p>3、 Propose: Proposer收到多数Acceptor的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptor发送Propose请求。</p><p>4、 Accept: Acceptor收到Propose请求后，在不违背自己之前做出的承诺下，接受并持久化当前Proposal ID和提案Value。</p><p>5、 Learn: Proposer收到多数Acceptor的Accept后，决议形成，将形成的决议发送给所有Learner。</p><p>下面举例以说明：</p><ol><li>情况1：</li></ol><p> <img src="/images/pasted-228.png" alt="upload successful"></p><ul><li>有A1, A2, A3, A4, A5 5位议员，就税率问题进行决议。</li><li>A1发起1号Proposal的Propose，等待Promise承诺； </li><li>A2-A5回应Promise； </li><li>A1在收到两份回复时就会发起税率10%的Proposal； </li><li>A2-A5回应Accept； </li><li>通过Proposal，税率10%。</li></ul><ol start="2"><li>情况2：</li></ol><p> <img src="/images/pasted-229.png" alt="upload successful"><br>     - 现在我们假设在A1提出提案的同时, A5决定将税率定为20%<br>     - A2承诺A1，A4承诺A5，A3行为成为关键<br>     - 情况1：A3先收到A1消息，承诺A1。<br>     - A1发起Proposal（1，10%），A2，A3接受。<br>     - 之后A3又收到A5消息，回复A1：（1，10%），并承诺A5<br>     - A5发起Proposal（2，20%），A3，A4接受。之后A1，A5同时广播决议。</p><pre><code>    由此可见Paxos 算法缺陷：在网络复杂的情况下，一个应用 Paxos 算法的分布式系统，可能很久无法收敛，甚至陷入活锁的情况。</code></pre><ol start="3"><li>情况3：</li></ol><p> <img src="/images/pasted-230.png" alt="upload successful"></p><pre><code> - 现在我们假设在A1提出提案的同时, A5决定将税率定为20% - A1，A5同时发起Propose（序号分别为1，2） - A2承诺A1，A4承诺A5，A3行为成为关键 - 情况2：A3先收到A1消息，承诺A1。之后立刻收到A5消息，承诺A5。 - A1发起Proposal（1，10%），无足够响应，A1重新Propose （序号3），A3再次承诺A1。 - A5发起Proposal（2，20%），无足够相应。A5重新Propose （序号4），A3再次承诺A5。</code></pre><p> 造成这种情况的原因是系统中有一个以上的 Proposer，多个 Proposers 相互争夺 Acceptor，造成迟迟无法达成一致的情况。针对这种情况，一种改进的 Paxos 算法被提出：从系统中选出一个节点作为 Leader，只有 Leader 能够发起提案。这样，一次 Paxos 流程中只有一个Proposer，不会出现活锁的情况，此时只会出现例子中第一种情况。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Paxos算法是一种基于消息传递且具有高度容错特性的一致性算法。其通常用于快速正确的在一个分布式系统中对某个数据值达成一致，并且保证无论发送任何异常都不会破坏整个系统的一致性。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-226.png&quot; alt=&quot;u</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="Paxos" scheme="http://example.com/tags/Paxos/"/>
    
    <category term="一致性算法" scheme="http://example.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper选举机制</title>
    <link href="http://example.com/2022/05/25/Zookeeper%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2022/05/25/Zookeeper%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/</id>
    <published>2022-05-25T12:24:00.000Z</published>
    <updated>2022-05-25T12:40:27.471Z</updated>
    
    <content type="html"><![CDATA[<p>在了解Zookeeper的选举机制之前，首先需要了解</p><ul><li>SID(服务器ID，用于唯一标识一台Zookeeper集群中的机器，每台机器不能重复，和myid一致)</li><li>ZXID（事务ID。用来标识一次服务器状态的变更。在某一时刻，集群中的每台机器的ZXID值不一定完全一致，这和Zookeeper服务器对于客户端“更新请求”的处理逻辑有关）</li><li>Epoch(每个Leader任期的代号。没有Leader时同一轮投票过程中的逻辑时钟是相同的。每投完一次票，这个数据会增加)</li></ul><p>了解上述三个参数之后，后续Zookeeper的选举机制便和其有关。关于其选举机制可以分为两种情况。</p><p>第一种情况是第一次启动集群时，Leader的选举是根据其myid的大小进行选举的。</p><pre><code>    例如：目前有一个五台Zookeeper的集群。当启动id为1的Zookeeper时，它投自己一票。此时不满足Leader成立的条件。票数半数以上。因此进入looking状态。然后id为2的服务器启动，id1和id2的服务器都投自己一票，然后交换选票信息。此时服务器1发现服务器2的id比自己大，因此服务器1转投服务器2一票。服务器1只有0票，而服务器2有2票。但此时还是不满足半数以上，因此两者都进入looking状态。然后服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING；服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为 1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING；服务器5启动，同4一样当小弟。    </code></pre><p>而第二种情况是非第一次启动，而是在集群运行中，Leader宕机了，需要重新选举Leader。</p><pre><code>    例如：假设ZooKeeper由5台服务器组成，SID分别为1、2、3、4、5，ZXID分别为8、8、8、7、7，并且此时SID为3的服务器是Leader。某一时刻，3和5服务器出现故障，因此开始进行Leader选举。</code></pre><p> <img src="/images/pasted-225.png" alt="upload successful"></p><p> 选举Leader规则： ①EPOCH大的直接胜出 ②EPOCH相同，事务id大的胜出 ③事务id相同，服务器id大的胜出</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在了解Zookeeper的选举机制之前，首先需要了解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SID(服务器ID，用于唯一标识一台Zookeeper集群中的机器，每台机器不能重复，和myid一致)&lt;/li&gt;
&lt;li&gt;ZXID（事务ID。用来标识一次服务器状态的变更。在某一时刻，集群中的每</summary>
      
    
    
    
    <category term="Zookeeper" scheme="http://example.com/categories/Zookeeper/"/>
    
    
    <category term="Zookeeper" scheme="http://example.com/tags/Zookeeper/"/>
    
    <category term="选举机制" scheme="http://example.com/tags/%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>为什么要使用泛型程序设计？</title>
    <link href="http://example.com/2022/05/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%EF%BC%9F/"/>
    <id>http://example.com/2022/05/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%EF%BC%9F/</id>
    <published>2022-05-15T13:49:00.000Z</published>
    <updated>2022-05-18T11:13:31.973Z</updated>
    
    <content type="html"><![CDATA[<p>最近一直忙于编译原理的学习，难得空闲下来，重新巩固了一下泛型的知识。在此小记一下。</p><p>泛型程序设计意味着编写的代码可以被很多不同类型的对象重用</p><h2 id="泛型类"><a href="#泛型类" class="headerlink" title="泛型类"></a>泛型类</h2><p>在java中增加泛型类前，泛型程序设计时通过继承等方式实现的。例如：ArrayList维护一个Object数组的引用。 这种方式存在着两个问题：</p><ol><li>当获取一个值时，必须进行强制类型转换。</li><li>没有进行任何检测，可以向其中添加任何类的对象。</li></ol><p>因此，对于调用，编译和运行都不会出错。但在某些情况下进行了错误的强制类型转换使用。就会报错。</p><p>对此，泛型提供了更好的解决方案：类型参数。这不仅使得代码更具可读性，也使得代码更加安全。因为编译器可以根据这个信息推断出get时的类型，不需要进行强制类型转换。在编译期间检查出类型错误，而不是在运行时才检测出。</p><p>一个泛型类就是具有一个或多个类型变量的类。（使用大写形式，且比较短。在java中，E表示集合类型，K和V则是键值对，T表示任意类型）</p><h2 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h2><p>泛型方法的类型变量放在修饰符后，返回值前面。泛型方法可以定义在普通类中，也可以定义在泛型类中。</p><p>当调用一个泛型方法时，在方法名前的尖括号中放入具体的类型。当然在大多数情况下，编译器可以推导出类型，意味着我们可以省去。（在某些情况下，编译器无法推导出，此时需要指明）</p><h2 id="类型变量的限定"><a href="#类型变量的限定" class="headerlink" title="类型变量的限定"></a>类型变量的限定</h2><p>有时候类或方法需要对类型变量加以约束，&lt; T extends Object &gt; T</p><p>当做出这样的限定后，泛型的变量类型便被约束了。当然一个类型变量或通配符可以有多个限定，只需要用&amp;隔开即可。&lt; T extends Object1 &amp; Object2 &gt; T<br>值得注意的是，在java中可以根据需要拥有多个接口超类型，但限定中至多有一个类。如果用一个类作为限定，它必须位于限定列表的第一个</p><p>extends决定了泛型变量的上限。</p><h2 id="泛型代码和虚拟机"><a href="#泛型代码和虚拟机" class="headerlink" title="泛型代码和虚拟机"></a>泛型代码和虚拟机</h2><p>虚拟机没有泛型类对象，所有对象都是属于普通对象。</p><ul><li><p>类型擦除：无论何时定义一个泛型类型，都自动提供了一个相应的原始类型。原始类型的名字就是删去类型参数后的泛型类型名。擦除类型变量，并替换为限定类型类型。（无限定的变量用Object）</p></li><li><p>翻译泛型表达式：当程序调用泛型方法时，如果擦除返回类型，编译器会插入强制类型转换。</p></li><li><p>翻译泛型方法：类型擦除也会出现在泛型方法中，只留下限定类型。但这可能会导致类型擦除和多态发生冲突。</p></li></ul><h2 id="约束与局限性"><a href="#约束与局限性" class="headerlink" title="约束与局限性"></a>约束与局限性</h2><ul><li><p>不能用基本数据类型实例化类型参数，即不能有&lt; double &gt;，但可以有&lt; Double &gt;,原因是类型擦除。</p></li><li><p>运行时类型查询只适用于原始类型，而不适用于泛型类型。当试图查询一个对象是否属于某个泛型类型时，倘若使用instanceof会得到一个编译器错误。同样的道理，getClass方法总是返回原始类型。</p></li><li><p>不能创建参数化类型的数组，例如：Pair&lt; String &gt;[] table = new Pair&lt; String &gt; [10];类型擦除之后，table类型时Pair[],，可以把它转化为Object[],数组会记住其元素类型，如果试图存其他类型，则会报错。不过对于泛型，这种机制会使之无效。不过仍会导致一个类型错误。因此，不能创建参数化类型的数组。当然可以声明通配类型的数组，然后进行类型转换。</p></li><li><p>不能构造泛型数组，因为数组本身也有类型，用来监控存在虚拟机中的数组。</p></li><li><p>泛型类的静态上下文中类型变量无效：不能在静态域或方法中使用类型变量。</p></li><li><p>不能抛出或捕获泛型类的实例：可以消除对受查异常的检查</p></li><li><p>注意擦除后的冲突：要想支持擦除的转换，就需要强制限制一个类或类型变量不能同时成为两个接口类型的子类，而这两个接口时同一接口的不同参数。</p></li></ul><h2 id="泛型类型的继承规则"><a href="#泛型类型的继承规则" class="headerlink" title="泛型类型的继承规则"></a>泛型类型的继承规则</h2><ul><li>无论S和T有什么关系，通常calssName &lt; S &gt; 和 calssName &lt; T &gt; 没有任何关系</li></ul><p>待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近一直忙于编译原理的学习，难得空闲下来，重新巩固了一下泛型的知识。在此小记一下。&lt;/p&gt;
&lt;p&gt;泛型程序设计意味着编写的代码可以被很多不同类型的对象重用&lt;/p&gt;
&lt;h2 id=&quot;泛型类&quot;&gt;&lt;a href=&quot;#泛型类&quot; class=&quot;headerlink&quot; title=&quot;泛</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="泛型" scheme="http://example.com/tags/%E6%B3%9B%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>关于lambda表达式</title>
    <link href="http://example.com/2022/05/02/%E5%85%B3%E4%BA%8Elambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://example.com/2022/05/02/%E5%85%B3%E4%BA%8Elambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/</id>
    <published>2022-05-02T14:46:00.000Z</published>
    <updated>2022-05-02T15:19:37.907Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h3><p>lambda表达式是一个可传递的代码块，可以在以后执行一次或多次。</p><p>表达形式：(参数)-&gt;{表达式}</p><ul><li><p>如果可以推导出lambda表达式的参数类型，则可以忽略</p></li><li><p>如果只有一个参数，且参数类型可以推断，则（）可以省略</p></li><li><p>无需指定其返回类型，lambda表达式的返回类型可以根据上下文推断得出</p><pre><code>  注意：如果一个lambda表达式在某些分支返回值，而在另一些分支不返还，这是错误的</code></pre></li></ul><h3 id="函数式接口"><a href="#函数式接口" class="headerlink" title="函数式接口"></a>函数式接口</h3><p>对于只有一个抽象方法的接口，需要这种接口的对象时，就可以通过提供一个lambda表达式。这种接口称为函数式接口。</p><p>java.util.function包中定义了不少非常通用的函数式接口。例如其中一个接口BiFunction&lt;T,U,R&gt;描述了参数类型为T和U且返回类型为R的函数。（比如可以把比较的lambda表达式保存在这个类型的变量中。当然，没多少人喜欢在sort的时候接收一个BiFunction。）</p><h3 id="方法引用"><a href="#方法引用" class="headerlink" title="方法引用"></a>方法引用</h3><p>对象或类型::方法名</p><ul><li>object::instanceMethod</li><li>Class::staticMethod</li><li>Class::instanceMethod</li></ul><p>前两种方法引用等价于提供方法参数的lambda表达式，而对于第三种，第一个参数会成为方法的目标</p><p>例子：Arrays.sort(strings,String::compareToIgnoreCase)不考虑字母的大小写进行排序</p><h3 id="构造器引用"><a href="#构造器引用" class="headerlink" title="构造器引用"></a>构造器引用</h3><p>构造器引用同方法引用类似，不过方法名为new。如：String:new</p><h3 id="变量的作用域"><a href="#变量的作用域" class="headerlink" title="变量的作用域"></a>变量的作用域</h3><p>lambda表达式的三个部分：</p><ol><li>代码块</li><li>参数</li><li>自由变量的值（非参数，且不在代码块中定义的变量）<pre><code> 注意：即对于自由变量，lambda表达式需要数据结构对其进行存储，而为了明确其捕获到的自由变量的值，lambda表达式中只能引用值不会改变的变量（常量） 补充：关于代码块和自由变量值有一个术语：闭包</code></pre>在lambda表达式中使用this关键字，值创建这个lambda表达式的方法的this参数<h3 id="处理lambda表达式"><a href="#处理lambda表达式" class="headerlink" title="处理lambda表达式"></a>处理lambda表达式</h3>使用lambda表达式的重点是延迟执行。而希望一个代码延迟执行的原因有很多：</li><li>在一个单独的线程中运行的代码</li><li>多次运行代码</li><li>在算法的适当位置运行代码（如排序比较）</li><li>发生某种事件时执行代码（如点击一个按钮之类）<br>…</li></ol><h3 id="常用函数式接口"><a href="#常用函数式接口" class="headerlink" title="常用函数式接口"></a>常用函数式接口</h3><p> <img src="/images/pasted-223.png" alt="upload successful"></p><h3 id="基本类型函数式接口"><a href="#基本类型函数式接口" class="headerlink" title="基本类型函数式接口"></a>基本类型函数式接口</h3><p><img src="/images/pasted-224.png" alt="upload successful"><br>可以使用这些来减少装箱拆箱</p><pre><code>    补充：如果自己设计接口，其中只有一个抽象方法，可以使用@Functionallnterface注解来标记这个接口（好处：一方面无意增加了另一个抽象方法编译器会提示报错，另一方面javadoc页会指出这是一个函数式接口）</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;简单介绍&quot;&gt;&lt;a href=&quot;#简单介绍&quot; class=&quot;headerlink&quot; title=&quot;简单介绍&quot;&gt;&lt;/a&gt;简单介绍&lt;/h3&gt;&lt;p&gt;lambda表达式是一个可传递的代码块，可以在以后执行一次或多次。&lt;/p&gt;
&lt;p&gt;表达形式：(参数)-&amp;gt;{表达式}&lt;/</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="lambda表达式" scheme="http://example.com/tags/lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>SLF4J那些事</title>
    <link href="http://example.com/2022/04/29/SLF4J%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <id>http://example.com/2022/04/29/SLF4J%E9%82%A3%E4%BA%9B%E4%BA%8B/</id>
    <published>2022-04-29T07:21:00.000Z</published>
    <updated>2022-04-29T08:49:21.775Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Java中的日志框架"><a href="#Java中的日志框架" class="headerlink" title="Java中的日志框架"></a>Java中的日志框架</h3><p> <img src="/images/pasted-216.png" alt="upload successful"></p><h3 id="门面日志框架"><a href="#门面日志框架" class="headerlink" title="门面日志框架"></a>门面日志框架</h3><p> <img src="/images/pasted-217.png" alt="upload successful"><br>不同的日志框架，有着不同的api和配置文件，为了统一应用中不同的日志框架所带来的统一管理问题，引入了门面日志框架，向上提供了统一的接口管理，向下对接不同的日志框架实现。<br> <img src="/images/pasted-218.png" alt="upload successful"></p><h3 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a>具体流程</h3><p> <img src="/images/pasted-219.png" alt="upload successful"></p><h3 id="关于SL4J的适配"><a href="#关于SL4J的适配" class="headerlink" title="关于SL4J的适配"></a>关于SL4J的适配</h3><p> <img src="/images/pasted-220.png" alt="upload successful"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>引入jar包slf4-api.jar</li><li>引入适配层jar包（如果需要的话）</li><li>引入底层日志框架的jar包</li><li>确认是否版本安全<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><img src="/images/pasted-221.png" alt="upload successful"></li></ol><p> <img src="/images/pasted-222.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Java中的日志框架&quot;&gt;&lt;a href=&quot;#Java中的日志框架&quot; class=&quot;headerlink&quot; title=&quot;Java中的日志框架&quot;&gt;&lt;/a&gt;Java中的日志框架&lt;/h3&gt;&lt;p&gt; &lt;img src=&quot;/images/pasted-216.png&quot; alt</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="日志" scheme="http://example.com/tags/%E6%97%A5%E5%BF%97/"/>
    
    <category term="SL4J" scheme="http://example.com/tags/SL4J/"/>
    
  </entry>
  
  <entry>
    <title>Java SPI机制</title>
    <link href="http://example.com/2022/04/29/Java-SPI%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2022/04/29/Java-SPI%E6%9C%BA%E5%88%B6/</id>
    <published>2022-04-29T01:06:00.000Z</published>
    <updated>2022-04-29T01:35:01.943Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>SPI（Serivce Provider Interface）：它是从java6开始引入的，一种基于classloader来发现并加载服务的机制。</p><p>一个标准的SPI有三个组件构成：<br>    - Service：是一个公开的接口或抽象类，定义了一个抽象的功能模块<br>    - Service Provider：service的一个实现类<br>    - ServiceLoader：核心组件，负责在运行时发现并加载service provider</p><h2 id="SPI运行流程"><a href="#SPI运行流程" class="headerlink" title="SPI运行流程"></a>SPI运行流程</h2><p> <img src="/images/pasted-211.png" alt="upload successful"></p><p> Application无需关注service的具体实现，只需面向接口编程</p><h2 id="Java-SPI在JDBC中的应用"><a href="#Java-SPI在JDBC中的应用" class="headerlink" title="Java SPI在JDBC中的应用"></a>Java SPI在JDBC中的应用</h2><p> <img src="/images/pasted-212.png" alt="upload successful"></p><ul><li>在Java SPI前，我们需要编码去注册驱动Class.forName(“com.mysql.jdbc.Driver”)</li><li>在引入Java SPI后，我们只需要日引入对应的依赖jar包即可</li></ul><h3 id="Java-SPI的三大规范要素"><a href="#Java-SPI的三大规范要素" class="headerlink" title="Java SPI的三大规范要素"></a>Java SPI的三大规范要素</h3><p> <img src="/images/pasted-214.png" alt="upload successful"></p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>作用：提供了一种组件发现和注册的方式，可以用于实现各种插件，或者灵活替换所使用的组件</li><li>优点：面向接口编程，优雅的实现模块之间的解耦</li><li>设计思想：面向接口+配置文件+反射技术</li><li>应用场景：JDBC、SLF4J等</li></ul><h3 id="补充：Java-SPI和SPringBoot自动装配"><a href="#补充：Java-SPI和SPringBoot自动装配" class="headerlink" title="补充：Java SPI和SPringBoot自动装配"></a>补充：Java SPI和SPringBoot自动装配</h3><p> <img src="/images/pasted-215.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h2&gt;&lt;p&gt;SPI（Serivce Provider Interface）：它是从java6开始引入的，一种基于classloader来</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="SPI" scheme="http://example.com/tags/SPI/"/>
    
  </entry>
  
  <entry>
    <title>MySQL行转列，列转行</title>
    <link href="http://example.com/2022/04/26/MySQL%E8%A1%8C%E8%BD%AC%E5%88%97%EF%BC%8C%E5%88%97%E8%BD%AC%E8%A1%8C/"/>
    <id>http://example.com/2022/04/26/MySQL%E8%A1%8C%E8%BD%AC%E5%88%97%EF%BC%8C%E5%88%97%E8%BD%AC%E8%A1%8C/</id>
    <published>2022-04-26T12:09:00.000Z</published>
    <updated>2022-04-26T12:41:41.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h2><ul><li><p>建表</p><pre><code>CREATE TABLE tb_score(    id INT(11) NOT NULL auto_increment,    userid VARCHAR(20) NOT NULL COMMENT &#39;用户id&#39;,    subject VARCHAR(20) COMMENT &#39;科目&#39;,    score DOUBLE COMMENT &#39;成绩&#39;,    PRIMARY KEY(id))ENGINE = INNODB DEFAULT CHARSET = utf8;</code></pre></li><li><p>插入数据</p><pre><code>INSERT INTO tb_score(userid,subject,score) VALUES (&#39;001&#39;,&#39;语文&#39;,90);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;001&#39;,&#39;数学&#39;,92);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;001&#39;,&#39;英语&#39;,80);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;002&#39;,&#39;语文&#39;,88);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;002&#39;,&#39;数学&#39;,90);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;002&#39;,&#39;英语&#39;,75.5);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;语文&#39;,70);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;数学&#39;,85);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;英语&#39;,90);INSERT INTO tb_score(userid,subject,score) VALUES (&#39;003&#39;,&#39;政治&#39;,82);</code></pre></li></ul><p> 查询数据表中的内容（即转换前的结果）</p><pre><code>    select * from tb_score;</code></pre><p> <img src="/images/pasted-206.png" alt="upload successful"></p><ol><li>使用case…when….then 进行行转列<pre><code> SELECT userid,SUM(CASE `subject` WHEN &#39;语文&#39; THEN score ELSE 0 END) AS &#39;语文&#39;,SUM(CASE `subject` WHEN &#39;数学&#39; THEN score ELSE 0 END) AS &#39;数学&#39;,SUM(CASE `subject` WHEN &#39;英语&#39; THEN score ELSE 0 END) AS &#39;英语&#39;,SUM(CASE `subject` WHEN &#39;政治&#39; THEN score ELSE 0 END) AS &#39;政治&#39;FROM tb_scoreGROUP BY userid</code></pre></li></ol><p> <img src="/images/pasted-207.png" alt="upload successful"></p><ol start="2"><li>使用IF() 进行行转列：<pre><code>SELECT userid,SUM(IF(`subject`=&#39;语文&#39;,score,0)) AS &#39;语文&#39;,SUM(IF(`subject`=&#39;数学&#39;,score,0)) AS &#39;数学&#39;,SUM(IF(`subject`=&#39;英语&#39;,score,0)) AS &#39;英语&#39;,SUM(IF(`subject`=&#39;政治&#39;,score,0)) AS &#39;政治&#39;FROM tb_scoreGROUP BY userid</code></pre></li></ol><p> <img src="/images/pasted-208.png" alt="upload successful"></p><blockquote><p>注意点：</p></blockquote><blockquote><blockquote><p>（1）SUM() 是为了能够使用GROUP BY根据userid进行分组，因为每一个userid对应的subject=”语文”的记录只有一条，所以SUM() 的值就等于对应那一条记录的score的值。假如userid =’001’ and subject=’语文’ 的记录有两条，则此时SUM() 的值将会是这两条记录的和，同理，使用Max()的值将会是这两条记录里面值最大的一个。但是正常情况下，一个user对应一个subject只有一个分数，因此可以使用SUM()、MAX()、MIN()、AVG()等聚合函数都可以达到行转列的效果。</p></blockquote></blockquote><blockquote><blockquote><p>（2）IF(<code>subject</code>=’语文’,score,0) 作为条件，即对所有subject=’语文’的记录的score字段进行SUM()、MAX()、MIN()、AVG()操作，如果score没有值则默认为0。</p></blockquote></blockquote><ol start="3"><li>计算行列和<pre><code> SELECT IFNULL(userid,&#39;TOTAL&#39;) AS userid, SUM(IF(`subject`=&#39;语文&#39;,score,0)) AS 语文, SUM(IF(`subject`=&#39;数学&#39;,score,0)) AS 数学, SUM(IF(`subject`=&#39;英语&#39;,score,0)) AS 英语, SUM(IF(`subject`=&#39;政治&#39;,score,0)) AS 政治, SUM(score) AS TOTAL  FROM tb_score GROUP BY userid WITH ROLLUP;</code></pre></li></ol><p> <img src="/images/pasted-209.png" alt="upload successful"></p><ol start="4"><li><p>合并字段显示：利用group_concat()</p><pre><code>  SELECT userid,GROUP_CONCAT(`subject`,&quot;:&quot;,score)AS 成绩 FROM tb_score  GROUP BY userid</code></pre></li></ol><p> <img src="/images/pasted-210.png" alt="upload successful"></p><h3 id="列转行"><a href="#列转行" class="headerlink" title="列转行"></a>列转行</h3><p>将每个userid对应的多个科目的成绩查出来，通过UNION ALL将结果集加起来</p><pre><code>附：UNION与UNION ALL的区别（摘）：1.对重复结果的处理：UNION会去掉重复记录，UNION ALL不会；2.对排序的处理：UNION会排序，UNION ALL只是简单地将两个结果集合并；3.效率方面的区别：因为UNION 会做去重和排序处理，因此效率比UNION ALL慢很多；</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;行转列&quot;&gt;&lt;a href=&quot;#行转列&quot; class=&quot;headerlink&quot; title=&quot;行转列&quot;&gt;&lt;/a&gt;行转列&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;建表&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE tb_score(
    id INT(11) N</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="查询" scheme="http://example.com/tags/%E6%9F%A5%E8%AF%A2/"/>
    
    <category term="行列转换" scheme="http://example.com/tags/%E8%A1%8C%E5%88%97%E8%BD%AC%E6%8D%A2/"/>
    
  </entry>
  
  <entry>
    <title>记一次安装Zookeeper启动失败的坑</title>
    <link href="http://example.com/2022/04/21/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%AE%89%E8%A3%85Zookeeper%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%9D%91/"/>
    <id>http://example.com/2022/04/21/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%AE%89%E8%A3%85Zookeeper%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%9D%91/</id>
    <published>2022-04-21T13:36:00.000Z</published>
    <updated>2022-04-21T13:43:12.434Z</updated>
    
    <content type="html"><![CDATA[<p>今天在阿里云上安装ZooKeeper，然后启动时一直报: Starting zookeeper … FAILED TO START。折腾了一会，经查阅资料发现，原来和版本有莫大关系…</p><h3 id="1-下载的版本问题（-gt-3-5-5）"><a href="#1-下载的版本问题（-gt-3-5-5）" class="headerlink" title="1. 下载的版本问题（&gt;= 3.5.5）"></a>1. 下载的版本问题（&gt;= 3.5.5）</h3><p>实际上只要 &gt;= 3.5.5 版本都会出现这种问题。</p><p>问题原因：下载了错误的版本文件，Zookeeper 从3.5.5后开始拆分为两个版本，而且他们的结构还很类似。</p><ul><li>标准版本（Apache ZooKeeper x.y.z ），下载的文件名为：apache-zookeeper-x.y.z-bin.tar.gz</li><li>另一个是源码版本（Apache ZooKeeper x.y.z Source Release），下载的文件名为：apache-zookeeper-x.y.z.tar.gz</li></ul><p> <img src="/images/pasted-204.png" alt="upload successful"></p><p> <img src="/images/pasted-205.png" alt="upload successful"><br> 所以下载 Zookeeper 的时候要注意，应该下载第一个(本人头铁，下载了第二个)。</p><h3 id="2-端口冲突问题（-gt-3-5-0）"><a href="#2-端口冲突问题（-gt-3-5-0）" class="headerlink" title="2. 端口冲突问题（&gt;=3.5.0）"></a>2. 端口冲突问题（&gt;=3.5.0）</h3><p> 在3.5.5版本及以上，Zookeeper 提供了一个内嵌的Jetty容器来运行 AdminServer，默认占用的是 8080端口，AdminServer 主要是来查看 Zookeeper 的一些状态，如果机器上有其他程序（比如：Tomcat）占用了 8080 端口，也会导致 Starting zookeeper … FAILED TO START 的问题。</p><p>可以通过以下几种方式去解决：</p><ul><li><p>禁用 AdminServer 服务</p><pre><code>  admin.enableServer=false</code></pre></li><li><p>修改器端口号：</p><pre><code>  admin.serverPort=9000</code></pre></li></ul><p>转载自：<a href="https://blog.csdn.net/peng2hui1314/article/details/107255142">https://blog.csdn.net/peng2hui1314/article/details/107255142</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天在阿里云上安装ZooKeeper，然后启动时一直报: Starting zookeeper … FAILED TO START。折腾了一会，经查阅资料发现，原来和版本有莫大关系…&lt;/p&gt;
&lt;h3 id=&quot;1-下载的版本问题（-gt-3-5-5）&quot;&gt;&lt;a href=&quot;#1</summary>
      
    
    
    
    <category term="Zookeeper" scheme="http://example.com/categories/Zookeeper/"/>
    
    
    <category term="Zookeeper" scheme="http://example.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>重排序</title>
    <link href="http://example.com/2022/04/17/%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    <id>http://example.com/2022/04/17/%E9%87%8D%E6%8E%92%E5%BA%8F/</id>
    <published>2022-04-17T02:01:00.000Z</published>
    <updated>2022-04-17T02:13:06.463Z</updated>
    
    <content type="html"><![CDATA[<p>重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。</p><h3 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h3><p>如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间 就存在数据依赖性。数据依赖分为下列3种类型</p><p> <img src="/images/pasted-203.png" alt="upload successful"></p><p> 上面3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。 而编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。 这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作， 不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。</p><h3 id="as-if-serial语义"><a href="#as-if-serial语义" class="headerlink" title="as-if-serial语义"></a>as-if-serial语义</h3><p> as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程） 程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p><p> 为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因 为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被 编译器和处理器重排序。</p><p> as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器 共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as- if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p><h3 id="程序顺序规则"><a href="#程序顺序规则" class="headerlink" title="程序顺序规则"></a>程序顺序规则</h3><p> 1）A happens-before B。 </p><p> 2）B happens-before C。 </p><p> 3）A happens-before C。</p><p> 这里的第3个happens-before关系，是根据happens-before的传递性推导出来的。 这里A happens-before B，但实际执行时B却可以排在A之前执行（看上面的重排序后的执 行顺序）。如果A happens-before B，JMM并不要求A一定要在B之前执行。JMM仅仅要求前一个 操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作A 的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，与操作A和操作B 按happens-before顺序执行的结果一致。在这种情况下，JMM会认为这种重排序并不非法（not illegal），JMM允许这种重排序。</p><p> 在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下， 尽可能提高并行度。编译器和处理器遵从这一目标，从happens-before的定义我们可以看出， JMM同样遵从这一目标。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。&lt;/p&gt;
&lt;h3 id=&quot;数据依赖性&quot;&gt;&lt;a href=&quot;#数据依赖性&quot; class=&quot;headerlink&quot; title=&quot;数据依赖性&quot;&gt;&lt;/a&gt;数据依赖性&lt;/h3&gt;&lt;p&gt;如果两个操作访问同一个变</summary>
      
    
    
    
    <category term="并发编程" scheme="http://example.com/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="JMM" scheme="http://example.com/tags/JMM/"/>
    
    <category term="并发编程" scheme="http://example.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
    <category term="重排序" scheme="http://example.com/tags/%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
</feed>
