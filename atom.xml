<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-03-12T05:32:23.547Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka-Kraft 模式</title>
    <link href="http://example.com/2022/03/12/Kafka-Kraft-%E6%A8%A1%E5%BC%8F/"/>
    <id>http://example.com/2022/03/12/Kafka-Kraft-%E6%A8%A1%E5%BC%8F/</id>
    <published>2022-03-12T05:30:00.000Z</published>
    <updated>2022-03-12T05:32:23.547Z</updated>
    
    <content type="html"><![CDATA[<p> <img src="/images/pasted-154.png" alt="upload successful"></p><p> 左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由controller 进行 Kafka 集群管理。右图为 kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理。</p><p> 这样做的好处有以下几个：</p><p> ⚫ Kafka 不再依赖外部框架，而是能够独立运行； </p><p> ⚫ controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升； </p><p> ⚫ 由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制； </p><p> ⚫ controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;img src=&quot;/images/pasted-154.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
&lt;p&gt; 左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由controller 进行 Kaf</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="Kraft模式" scheme="http://example.com/tags/Kraft%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Kafka数据积压（消费者如何提高吞吐量）</title>
    <link href="http://example.com/2022/03/12/Kafka%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B%EF%BC%88%E6%B6%88%E8%B4%B9%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%89/"/>
    <id>http://example.com/2022/03/12/Kafka%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B%EF%BC%88%E6%B6%88%E8%B4%B9%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%89/</id>
    <published>2022-03-12T05:28:00.000Z</published>
    <updated>2022-03-12T05:29:37.815Z</updated>
    
    <content type="html"><![CDATA[<p>1）如果是Kafka消费能力不足，则可以考虑增 加Topic的分区数，并且同时提升消费组的消费者<br>数量，消费者数 = 分区数。（两者缺一不可）</p><p>2）如果是下游的数据处理不及时：提高每批次拉取的数<br>量。批次拉取数据过少（拉取数据/处理时间 &lt; 生产速度），<br>使处理的数据小于生产的数据，也会造成数据积压。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1）如果是Kafka消费能力不足，则可以考虑增 加Topic的分区数，并且同时提升消费组的消费者&lt;br&gt;数量，消费者数 = 分区数。（两者缺一不可）&lt;/p&gt;
&lt;p&gt;2）如果是下游的数据处理不及时：提高每批次拉取的数&lt;br&gt;量。批次拉取数据过少（拉取数据/处理时间 &amp;lt; </summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="数据积压" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B/"/>
    
    <category term="消费者" scheme="http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    
  </entry>
  
  <entry>
    <title>Kafka消费者漏消费和重复消费问题</title>
    <link href="http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E6%BC%8F%E6%B6%88%E8%B4%B9%E5%92%8C%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E6%BC%8F%E6%B6%88%E8%B4%B9%E5%92%8C%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98/</id>
    <published>2022-03-12T05:12:00.000Z</published>
    <updated>2022-03-12T05:27:39.970Z</updated>
    
    <content type="html"><![CDATA[<p>重复消费：已经消费了数据，但是 offset 没提交，下次还会消费到当前数据。</p><p>漏消费：先提交 offset 后消费，有可能会造成数据的漏消费。</p><p> <img src="/images/pasted-153.png" alt="upload successful"></p><p>如果想完成Consumer端的精准一次性消费（既不漏消费也不重复消费），那么需要Kafka消费端将消费过程和提交offset<br>过程做原子绑定。此时我们需要将Kafka的offset保存到支持事务的自定义介质（比 如MySQL）。</p><pre><code>参考：https://blog.csdn.net/qingqing7/article/details/80054281?spm=1001.2101.3001.6650.14&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-14.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-14.pc_relevant_default&amp;utm_relevant_index=25</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;重复消费：已经消费了数据，但是 offset 没提交，下次还会消费到当前数据。&lt;/p&gt;
&lt;p&gt;漏消费：先提交 offset 后消费，有可能会造成数据的漏消费。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-153.png&quot; alt=&quot;upload suc</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="消费者" scheme="http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    
    <category term="漏消费" scheme="http://example.com/tags/%E6%BC%8F%E6%B6%88%E8%B4%B9/"/>
    
    <category term="重复消费" scheme="http://example.com/tags/%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9/"/>
    
  </entry>
  
  <entry>
    <title>Kafka消费者的offset提交</title>
    <link href="http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84offset%E6%8F%90%E4%BA%A4/"/>
    <id>http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84offset%E6%8F%90%E4%BA%A4/</id>
    <published>2022-03-12T05:00:00.000Z</published>
    <updated>2022-03-12T05:11:59.292Z</updated>
    
    <content type="html"><![CDATA[<p>offset偏移量表明了该消费者当前消费的数据到哪一步，其存储在系统主题_consumer_offset中（0.9版本之前是存在Zookeeper中），以key,value形式，每隔一段时间kafka都会对其Compact（即保留当前最新的数据）。</p><p>1、自动提交offset：为了能让我们专注于业务处理，Kafka提供了自动提交offset功能，通过参数</p><p>⚫ enable.auto.commit：是否开启自动提交offset功能，默认是true</p><p>⚫ auto.commit.interval.ms：自动提交offset的时间间隔，默认是5s</p><p>2、手动提交：自动提交固然遍历，但基于时间的提交，我们很难把握那个度，因此更多时候，我们可以选择手动提交。</p><p>1）同步提交：同步提交会阻塞当前线程，一直到成功为止，并且失败会自动重试</p><p>2）异步提交：异步提交则不会阻塞当前线程，且没有重试机制，可能提交失败。</p><p>两者都会将本次提交的一批数据最高偏移量提交。</p><p>指定offset消费：auto.offset.reset = earliest | latest | none 默认是 latest。</p><p>当kafka中没有初始偏移量（消费者组第一次消费）或服务器上不存在当前偏移量时（数据被删除）需要指定offset消费。</p><p>1）earliest：自动将偏移量重置为最早的偏移量，–from-beginning。</p><p>2）latest（默认值）：自动将偏移量重置为最新偏移量。</p><p>（3）none：如果未找到消费者组的先前偏移量，则向消费者抛出异常。</p><p>（4）任意指定 offset 位移开始消费</p><p>指定时间消费：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。例如要求按照时间消费前一天的数据</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;offset偏移量表明了该消费者当前消费的数据到哪一步，其存储在系统主题_consumer_offset中（0.9版本之前是存在Zookeeper中），以key,value形式，每隔一段时间kafka都会对其Compact（即保留当前最新的数据）。&lt;/p&gt;
&lt;p&gt;1、自动提</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="消费者" scheme="http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    
    <category term="offset" scheme="http://example.com/tags/offset/"/>
    
  </entry>
  
  <entry>
    <title>Kafka消费者分区的分配以及再平衡</title>
    <link href="http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%9A%84%E5%88%86%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1/"/>
    <id>http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%9A%84%E5%88%86%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1/</id>
    <published>2022-03-12T04:47:00.000Z</published>
    <updated>2022-03-12T04:53:38.116Z</updated>
    
    <content type="html"><![CDATA[<p>一个consumer group中有多个consumer组成，一个 topic有多个partition组成，现在的问题是，到底由哪个consumer来消费哪个partition的数据。 </p><p>2、Kafka有四种主流的分区分配策略：<br> Range、RoundRobin、Sticky、CooperativeSticky。<br>可以通过配置参数partition.assignment.strategy，修改分区的分配策略。默认策略是Range + CooperativeSticky。Kafka可以同时使用多个分区分配策略。</p><p>1）Range 是对每个 topic 而言的。</p><p>首先对同一个 topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。</p><p>假如现在有 7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6；消费者排序完之后将会是C0,C1,C2。例如，7/3 = 2 余 1 ，除不尽，那么 消费者 C0 便会多消费 1 个分区。 8/3=2余2，除不尽，那么C0和C1分别多消费一个。</p><p>通过 partitions数/consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多<br>消费 1 个分区。</p><p>注意：如果只是针对 1 个 topic 而言，C0消费者多消费1个分区影响不是很大。但是如果有 N 多个 topic，那么针对个 topic，消费者 C0都将多消费 1 个分区，topic越多，C0消 费的分区会比其他消费者明显多消费 N 个分区。容易产生数据倾斜！</p><p>（注意：说明：某个消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。）</p><p>2）RoundRobin 分区策略原理：</p><p>RoundRobin 针对集群中所有Topic而言。<br>RoundRobin 轮询分区策略，是把所有的 partition 和所有的<br>consumer 都列出来，然后按照 hashcode 进行排序，最后<br>通过轮询算法来分配 partition 给到各个消费者。</p><p>3） Sticky 以及再平衡：</p><p>粘性分区定义：可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，<br>考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。<br>粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区<br>到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分<br>区不变化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;一个consumer group中有多个consumer组成，一个 topic有多个partition组成，现在的问题是，到底由哪个consumer来消费哪个partition的数据。 &lt;/p&gt;
&lt;p&gt;2、Kafka有四种主流的分区分配策略：&lt;br&gt; Range、Round</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="消费者" scheme="http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    
    <category term="分区分配策略" scheme="http://example.com/tags/%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/"/>
    
  </entry>
  
  <entry>
    <title>Kafka高效读写数据</title>
    <link href="http://example.com/2022/03/12/Kafka%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE/"/>
    <id>http://example.com/2022/03/12/Kafka%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE/</id>
    <published>2022-03-12T03:23:00.000Z</published>
    <updated>2022-03-12T03:24:21.616Z</updated>
    
    <content type="html"><![CDATA[<p>1）Kafka 本身是分布式集群，可以采用分区技术，并行度高</p><p>2）读数据采用稀疏索引，可以快速定位要消费的数据</p><p>3）顺序写磁盘（Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。）</p><p>4）页缓存 + 零拷贝技术</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1）Kafka 本身是分布式集群，可以采用分区技术，并行度高&lt;/p&gt;
&lt;p&gt;2）读数据采用稀疏索引，可以快速定位要消费的数据&lt;/p&gt;
&lt;p&gt;3）顺序写磁盘（Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。官网有数</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="高效读写" scheme="http://example.com/tags/%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99/"/>
    
  </entry>
  
  <entry>
    <title>Kafka文件清理策略</title>
    <link href="http://example.com/2022/03/12/Kafka%E6%96%87%E4%BB%B6%E6%B8%85%E7%90%86%E7%AD%96%E7%95%A5/"/>
    <id>http://example.com/2022/03/12/Kafka%E6%96%87%E4%BB%B6%E6%B8%85%E7%90%86%E7%AD%96%E7%95%A5/</id>
    <published>2022-03-12T03:19:00.000Z</published>
    <updated>2022-03-12T03:23:07.944Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 中默认的日志保存时间为 7 天，可以通过调整如下参数修改保存时间。<br>⚫ log.retention.hours，最低优先级小时，默认 7 天。</p><p>⚫ log.retention.minutes，分钟。 </p><p>⚫ log.retention.ms，最高优先级毫秒。 </p><p>⚫log.retention.check.interval.ms，负责设置检查周期，默认 5 分钟。</p><p>对于超过设置事件的数据，有两种清楚策略，delete和Compact</p><p>1）delete 日志删除：将过期数据删除</p><p>⚫ log.cleanup.policy = delete 所有数据启用删除策略</p><p>（1）基于时间：默认打开。以 segment 中所有记录中的最大时间戳作为该文件时间戳。</p><p>（2）基于大小：默认关闭。超过设置的所有日志总大小，删除最早segment。log.retention.bytes，默认等于-1，表示无穷大。</p><p>2）compact 日志压缩</p><p>compact日志压缩：对于相同key的不同value值，只保留最后一个版本。</p><p>⚫ log.cleanup.policy = compact 所有数据启用压缩策略</p><p> <img src="/images/pasted-152.png" alt="upload successful"></p><p>压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，将会拿到比这个offset大 的offset对应的消息，实际上会拿到offset为7的消息，并从这个位置开始消费。</p><p>这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息<br>集里就保存了所有用户最新的资料。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Kafka 中默认的日志保存时间为 7 天，可以通过调整如下参数修改保存时间。&lt;br&gt;⚫ log.retention.hours，最低优先级小时，默认 7 天。&lt;/p&gt;
&lt;p&gt;⚫ log.retention.minutes，分钟。 &lt;/p&gt;
&lt;p&gt;⚫ log.retenti</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="清楚策略" scheme="http://example.com/tags/%E6%B8%85%E6%A5%9A%E7%AD%96%E7%95%A5/"/>
    
  </entry>
  
  <entry>
    <title>Kafka文件存储机制</title>
    <link href="http://example.com/2022/03/12/Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2022/03/12/Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/</id>
    <published>2022-03-12T03:16:00.000Z</published>
    <updated>2022-03-12T03:19:20.616Z</updated>
    
    <content type="html"><![CDATA[<p>Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制， 将每个partition分为多个segment。每个segment包括：“.index”文件、“.log”文件和.timeindex等文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号，例如：first-0。</p><p> <img src="/images/pasted-150.png" alt="upload successful"></p><p> Log文件和Index文件详解：</p><p> <img src="/images/pasted-151.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="文件存储" scheme="http://example.com/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Leader Partition 负载平衡</title>
    <link href="http://example.com/2022/03/12/Leader-Partition-%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1/"/>
    <id>http://example.com/2022/03/12/Leader-Partition-%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1/</id>
    <published>2022-03-12T03:11:00.000Z</published>
    <updated>2022-03-12T03:15:02.258Z</updated>
    
    <content type="html"><![CDATA[<p>正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡。</p><p>策略：</p><p>1、auto.leader.rebalance.enable，默认是true。（自动Leader Partition 平衡）</p><p>2、leader.imbalance.per.broker.percentage，默认是10%。每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。</p><p>3、leader.imbalance.check.interval.seconds，默认值300秒。检查leader负载是否平衡的间隔时间。</p><p>例如：针对broker0节点，分区2的AR优先副本是0节点，但是0节点却不是Leader节点，所以不平衡数加1，AR副本总数是4，所以broker0节点不平衡率为1/4&gt;10%，需要再平衡。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="Leader" scheme="http://example.com/tags/Leader/"/>
    
    <category term="Partition" scheme="http://example.com/tags/Partition/"/>
    
  </entry>
  
  <entry>
    <title>Leader 和 Follower 故障处理细节</title>
    <link href="http://example.com/2022/03/12/Leader-%E5%92%8C-Follower-%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E7%BB%86%E8%8A%82/"/>
    <id>http://example.com/2022/03/12/Leader-%E5%92%8C-Follower-%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E7%BB%86%E8%8A%82/</id>
    <published>2022-03-12T03:06:00.000Z</published>
    <updated>2022-03-12T03:10:07.966Z</updated>
    
    <content type="html"><![CDATA[<p>LEO（Log End Offset）：每个副本的最后一个offset，LEO其实就是最新的offset + 1。</p><p>HW（High Watermark）：所有副本中最小的LEO 。</p><p>1）Follower故障：</p><p>（1） Follower发生故障后会被临时踢出ISR</p><p>（2） 这个期间Leader和Follower继续接收数据</p><p>（3）待该Follower恢复后，Follower会读取本地磁盘记录的<br>上次的HW，并将log文件高于HW的部分截取掉，从HW开始向Leader进行同步。</p><p>（4）等该Follower的LEO大于等于该Partition的HW，即<br>Follower追上Leader之后，就可以重新加入ISR了。</p><p>2）Leader故障：</p><p>（1） Leader发生故障之后，会从ISR中选出一个新的Leader</p><p>（2）为保证多个副本之间的数据一致性，其余的Follower会先将各自的log文件高于HW的部分截掉，然后从新的Leader同步数据。</p><p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;LEO（Log End Offset）：每个副本的最后一个offset，LEO其实就是最新的offset + 1。&lt;/p&gt;
&lt;p&gt;HW（High Watermark）：所有副本中最小的LEO 。&lt;/p&gt;
&lt;p&gt;1）Follower故障：&lt;/p&gt;
&lt;p&gt;（1） Followe</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="Leader和Follower故障" scheme="http://example.com/tags/Leader%E5%92%8CFollower%E6%95%85%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>Kafka Broker总体工作流程</title>
    <link href="http://example.com/2022/03/12/Kafka-Broker%E6%80%BB%E4%BD%93%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"/>
    <id>http://example.com/2022/03/12/Kafka-Broker%E6%80%BB%E4%BD%93%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/</id>
    <published>2022-03-12T03:00:00.000Z</published>
    <updated>2022-03-12T03:00:21.303Z</updated>
    
    <content type="html"><![CDATA[<p> <img src="/images/pasted-149.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;img src=&quot;/images/pasted-149.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="工作流程" scheme="http://example.com/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper中存储的Kafka 信息</title>
    <link href="http://example.com/2022/03/12/Zookeeper%E4%B8%AD%E5%AD%98%E5%82%A8%E7%9A%84Kafka-%E4%BF%A1%E6%81%AF/"/>
    <id>http://example.com/2022/03/12/Zookeeper%E4%B8%AD%E5%AD%98%E5%82%A8%E7%9A%84Kafka-%E4%BF%A1%E6%81%AF/</id>
    <published>2022-03-12T02:52:00.000Z</published>
    <updated>2022-03-12T02:53:19.813Z</updated>
    
    <content type="html"><![CDATA[<p>在zookeeper的服务端存储的Kafka相关信息：</p><p>1）/kafka/brokers/ids [0,1,2] 记录有哪些服务器</p><p>2）/kafka/brokers/topics/first/partitions/0/state<br>{“leader”:1 ,”isr”:[1,0,2] } 记录谁是Leader，有哪些服务器可用</p><p>3）/kafka/controller<br>{“brokerid”:0}<br>辅助选举Leader</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在zookeeper的服务端存储的Kafka相关信息：&lt;/p&gt;
&lt;p&gt;1）/kafka/brokers/ids [0,1,2] 记录有哪些服务器&lt;/p&gt;
&lt;p&gt;2）/kafka/brokers/topics/first/partitions/0/state&lt;br&gt;{“lea</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    <category term="Zookeeper" scheme="http://example.com/categories/Kafka/Zookeeper/"/>
    
    
    <category term="Zookeeper" scheme="http://example.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Kafka数据乱序</title>
    <link href="http://example.com/2022/03/12/Kafka%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F/"/>
    <id>http://example.com/2022/03/12/Kafka%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F/</id>
    <published>2022-03-12T02:47:00.000Z</published>
    <updated>2022-03-12T02:50:26.550Z</updated>
    
    <content type="html"><![CDATA[<p>1）kafka在1.x版本之前保证数据单分区有序，条件如下：<br>max.in.flight.requests.per.connection=1（不需要考虑是否开启幂等性）。 </p><p>2）kafka在1.x及以后版本保证数据单分区有序，条件如下：</p><p>（1）未开启幂等性<br>max.in.flight.requests.per.connection需要设置为1。</p><p>（2）开启幂等性<br>max.in.flight.requests.per.connection需要设置小于等于5。 </p><p>原因说明：因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，故无论如何，都可以保证最近5个request的数据都是有序的。</p><p> <img src="/images/pasted-148.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1）kafka在1.x版本之前保证数据单分区有序，条件如下：&lt;br&gt;max.in.flight.requests.per.connection=1（不需要考虑是否开启幂等性）。 &lt;/p&gt;
&lt;p&gt;2）kafka在1.x及以后版本保证数据单分区有序，条件如下：&lt;/p&gt;
&lt;p&gt;（</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="数据有序" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>Kafka的生产者事务原理</title>
    <link href="http://example.com/2022/03/12/Kafka%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2022/03/12/Kafka%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86/</id>
    <published>2022-03-12T02:29:00.000Z</published>
    <updated>2022-03-12T02:33:52.261Z</updated>
    
    <content type="html"><![CDATA[<p>注意：开启事务，必须要开启幂等性。另外Procuder在使用事务功能前，必须先自定义一个唯一的transaction.id。有了transaction.id，即使客户端挂掉了，它重启后也能继续处理未完成的事务。</p><p> <img src="/images/pasted-147.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;注意：开启事务，必须要开启幂等性。另外Procuder在使用事务功能前，必须先自定义一个唯一的transaction.id。有了transaction.id，即使客户端挂掉了，它重启后也能继续处理未完成的事务。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/paste</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Kafka保证生产者生产的数据不重复：幂等性+至少一次</title>
    <link href="http://example.com/2022/03/12/Kafka%E4%BF%9D%E8%AF%81%E7%94%9F%E4%BA%A7%E8%80%85%E7%94%9F%E4%BA%A7%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E9%87%8D%E5%A4%8D%EF%BC%9A%E5%B9%82%E7%AD%89%E6%80%A7-%E8%87%B3%E5%B0%91%E4%B8%80%E6%AC%A1/"/>
    <id>http://example.com/2022/03/12/Kafka%E4%BF%9D%E8%AF%81%E7%94%9F%E4%BA%A7%E8%80%85%E7%94%9F%E4%BA%A7%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E9%87%8D%E5%A4%8D%EF%BC%9A%E5%B9%82%E7%AD%89%E6%80%A7-%E8%87%B3%E5%B0%91%E4%B8%80%E6%AC%A1/</id>
    <published>2022-03-12T02:25:00.000Z</published>
    <updated>2022-03-12T02:34:13.739Z</updated>
    
    <content type="html"><![CDATA[<p>至少一次：ack级别设置为-1+分区副本大于等于2+ISR里面的应答最小副本大于等于2（保证数据不会丢失）</p><p>幂等性：指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。（重复数据的判断标准：具有&lt;PID, Partition, SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其 中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。）</p><p>因此幂等性只能保证的是在单分区单会话内不重复。</p><p>如何使用幂等性：开启参数 enable.idempotence 默认为 true，false 关闭。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;至少一次：ack级别设置为-1+分区副本大于等于2+ISR里面的应答最小副本大于等于2（保证数据不会丢失）&lt;/p&gt;
&lt;p&gt;幂等性：指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。（重复数据的判断标准：具有&amp;lt;PID,</summary>
      
    
    
    
    <category term="Kafka" scheme="http://example.com/categories/Kafka/"/>
    
    <category term="消息队列" scheme="http://example.com/categories/Kafka/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="Kafka" scheme="http://example.com/tags/Kafka/"/>
    
    <category term="数据" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Spring Security认证过程</title>
    <link href="http://example.com/2022/03/11/Spring-Security%E8%AE%A4%E8%AF%81%E8%BF%87%E7%A8%8B/"/>
    <id>http://example.com/2022/03/11/Spring-Security%E8%AE%A4%E8%AF%81%E8%BF%87%E7%A8%8B/</id>
    <published>2022-03-11T13:54:00.000Z</published>
    <updated>2022-03-11T14:09:54.174Z</updated>
    
    <content type="html"><![CDATA[<p>我们知道Spring Security的核心就是认证和授权，但是具体它是如何进行认证和授权的呢？下面让我们来聊聊Spring Security的认证过程，具体步骤如下图所示：</p><p> <img src="/images/pasted-146.png" alt="upload successful"></p><p> 在开始之前，我们需要了解一下如下类：</p><p>AuthenticationManager核心验证器，该对象提供了认证方法的入口，接收一个Authentiation对象作为参数。</p><pre><code>      public interface AuthenticationManager &#123;        Authentication authenticate(Authentication authentication)                throws AuthenticationException;    &#125;    </code></pre><p>ProviderManager：它是 AuthenticationManager 的一个实现类，提供了基本的认证逻辑和方法；它包含了一个 List<AuthenticationProvider> 对象，通过 AuthenticationProvider 接口来扩展出不同的认证提供者(当Spring Security默认提供的实现类不能满足需求的时候可以扩展AuthenticationProvider 覆盖supports(Class&lt;?&gt; authentication)方法)；</p><p>具体验证逻辑：</p><p>AuthenticationManager 接收 Authentication 对象作为参数，并通过 authenticate(Authentication) 方法对其进行验证；AuthenticationProvider实现类用来支撑对 Authentication 对象的验证动作；UsernamePasswordAuthenticationToken实现了 Authentication主要是将用户输入的用户名和密码进行封装，并供给 AuthenticationManager 进行验证；验证完成以后将返回一个认证成功的 Authentication 对象；</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我们知道Spring Security的核心就是认证和授权，但是具体它是如何进行认证和授权的呢？下面让我们来聊聊Spring Security的认证过程，具体步骤如下图所示：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-146.png&quot; alt=&quot;up</summary>
      
    
    
    
    <category term="Spring Security" scheme="http://example.com/categories/Spring-Security/"/>
    
    
    <category term="认证" scheme="http://example.com/tags/%E8%AE%A4%E8%AF%81/"/>
    
  </entry>
  
  <entry>
    <title>Spring的AOP是在哪个阶段创建的动态代理？</title>
    <link href="http://example.com/2022/03/10/Spring%E7%9A%84AOP%E6%98%AF%E5%9C%A8%E5%93%AA%E4%B8%AA%E9%98%B6%E6%AE%B5%E5%88%9B%E5%BB%BA%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%EF%BC%9F/"/>
    <id>http://example.com/2022/03/10/Spring%E7%9A%84AOP%E6%98%AF%E5%9C%A8%E5%93%AA%E4%B8%AA%E9%98%B6%E6%AE%B5%E5%88%9B%E5%BB%BA%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%EF%BC%9F/</id>
    <published>2022-03-10T00:44:00.000Z</published>
    <updated>2022-03-10T00:47:08.519Z</updated>
    
    <content type="html"><![CDATA[<p>1、正常情况下会在bean的生命周期“初始化”后，通过BeanPostProcessor.postProcessAfterInitialization创建AOP的动态代理</p><p>2、特殊情况下，即存在循环依赖的时候，Bean会在生命周期的“属性注入”时，通过MergedBeanDefinitionPostProcessor.postProcessMergedBeanDefinition创建aop动态代理</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1、正常情况下会在bean的生命周期“初始化”后，通过BeanPostProcessor.postProcessAfterInitialization创建AOP的动态代理&lt;/p&gt;
&lt;p&gt;2、特殊情况下，即存在循环依赖的时候，Bean会在生命周期的“属性注入”时，通过Merg</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="AOP" scheme="http://example.com/tags/AOP/"/>
    
    <category term="面试题" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>什么情况下AOP会失效,怎么解决？</title>
    <link href="http://example.com/2022/03/10/%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8BAOP%E4%BC%9A%E5%A4%B1%E6%95%88-%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%EF%BC%9F/"/>
    <id>http://example.com/2022/03/10/%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8BAOP%E4%BC%9A%E5%A4%B1%E6%95%88-%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%EF%BC%9F/</id>
    <published>2022-03-10T00:37:00.000Z</published>
    <updated>2022-03-10T00:42:55.549Z</updated>
    
    <content type="html"><![CDATA[<p>1、方法是private</p><p>2、目标类没有配置为Bean</p><p>3、切点表达式没有写正确</p><p>4、jdk动态代理下内部调用不会触发AOP（</p><p>原因：</p><p>内部进行自调用，是走的实例对象，而不是代理对象。</p><p>解决：</p><p>1、在本类中自动注入当前的bean</p><p>2、@EnableAspectJAutoProxy(exposProxy = true)</p><p>设置暴露当前代理对象到本地线程，可以通过AopContent.currentProxy()拿到当前的动态代理对象。<br>）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1、方法是private&lt;/p&gt;
&lt;p&gt;2、目标类没有配置为Bean&lt;/p&gt;
&lt;p&gt;3、切点表达式没有写正确&lt;/p&gt;
&lt;p&gt;4、jdk动态代理下内部调用不会触发AOP（&lt;/p&gt;
&lt;p&gt;原因：&lt;/p&gt;
&lt;p&gt;内部进行自调用，是走的实例对象，而不是代理对象。&lt;/p&gt;
&lt;p&gt;解决</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="AOP" scheme="http://example.com/tags/AOP/"/>
    
    <category term="面试题" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>AOP有几种实现方式 </title>
    <link href="http://example.com/2022/03/10/AOP%E6%9C%89%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"/>
    <id>http://example.com/2022/03/10/AOP%E6%9C%89%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</id>
    <published>2022-03-10T00:34:00.000Z</published>
    <updated>2022-03-10T00:36:27.821Z</updated>
    
    <content type="html"><![CDATA[<p>1、Spring 1.2 基于接口的配置：最早的 Spring AOP 是完全基于几个接口的，想看源码的同学可以从这里起步。</p><p>2、Spring 2.0 schema-based 配置：Spring 2.0 以后使用 XML 的方式来配置，使用 命名空间 <aop ></aop></p><p>3、Spring 2.0 @AspectJ 配置：使用注解的方式来配置，这种方式感觉是最方便的，还有，这里虽然叫<br>做 @AspectJ，但是这个和 AspectJ 其实没啥关系。</p><p>4、AspectJ  方式，这种方式其实和Spring没有关系，采用AspectJ 进行动态织入的方式实现AOP，需要用<br>AspectJ 单独编译。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1、Spring 1.2 基于接口的配置：最早的 Spring AOP 是完全基于几个接口的，想看源码的同学可以从这里起步。&lt;/p&gt;
&lt;p&gt;2、Spring 2.0 schema-based 配置：Spring 2.0 以后使用 XML 的方式来配置，使用 命名空间 &lt;ao</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="AOP" scheme="http://example.com/tags/AOP/"/>
    
  </entry>
  
  <entry>
    <title>Spring的AOP通知执行顺序</title>
    <link href="http://example.com/2022/03/09/Spring%E7%9A%84AOP%E9%80%9A%E7%9F%A5%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/"/>
    <id>http://example.com/2022/03/09/Spring%E7%9A%84AOP%E9%80%9A%E7%9F%A5%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/</id>
    <published>2022-03-09T13:25:00.000Z</published>
    <updated>2022-03-09T13:28:17.294Z</updated>
    
    <content type="html"><![CDATA[<p>执行顺序：</p><pre><code>5.2.7之前：1、正常执行：@Before­­­&gt;方法­­­­&gt;@After­­­&gt;@AfterReturning2、异常执行：@Before­­­&gt;方法­­­­&gt;@After­­­&gt;@AfterThrowing5.2.7之后：1、正常执行：@Before­­­&gt;方法­­­­&gt;@AfterReturning­­­&gt;@After2、异常执行：@Before­­­&gt;方法­­­­&gt;@AfterThrowing­­­&gt;@After</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;执行顺序：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;5.2.7之前：

1、正常执行：@Before­­­&amp;gt;方法­­­­&amp;gt;@After­­­&amp;gt;@AfterReturning
2、异常执行：@Before­­­&amp;gt;方法­­­­&amp;gt;@After­­­&amp;gt;@A</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="AOP" scheme="http://example.com/tags/AOP/"/>
    
    <category term="面试题" scheme="http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    
  </entry>
  
</feed>
