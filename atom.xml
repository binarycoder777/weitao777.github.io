<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-04-03T11:42:52.074Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Java中的Queue那些事</title>
    <link href="http://example.com/2022/04/03/Java%E4%B8%AD%E7%9A%84Queue%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <id>http://example.com/2022/04/03/Java%E4%B8%AD%E7%9A%84Queue%E9%82%A3%E4%BA%9B%E4%BA%8B/</id>
    <published>2022-04-03T08:37:00.000Z</published>
    <updated>2022-04-03T11:42:52.074Z</updated>
    
    <content type="html"><![CDATA[<h2 id="PriorityQueue"><a href="#PriorityQueue" class="headerlink" title="PriorityQueue"></a>PriorityQueue</h2><p>优先级队列，是0个或多个元素的集合，集合中的每个元素都有一个权重值，每次出队都弹出优先级最大或最小的元素。</p><h3 id="主要属性"><a href="#主要属性" class="headerlink" title="主要属性"></a>主要属性</h3><p>（1）默认容量是11；</p><p>（2）queue，元素存储在数组中，堆一般使用数组来存储；</p><p>（3）comparator，比较器，在优先级队列中，也有两种方式比较元素，一种是元素的自然顺序，一种是通过比较器来比较；</p><p>（4）modCount，修改次数，有这个属性表示PriorityQueue也是fast-fail的；</p><h3 id="入队"><a href="#入队" class="headerlink" title="入队"></a>入队</h3><p>（1）入队不允许null元素；</p><p>（2）如果数组不够用了，先扩容；</p><p>（3）如果还没有元素，就插入下标0的位置；</p><p>（4）如果有元素了，就插入到最后一个元素往后的一个位置（实际并没有插入哈）；</p><p>（5）自下而上堆化，一直往上跟父节点比较；</p><p>（6）如果比父节点小，就与父节点交换位置，直到出现比父节点大为止；</p><p>（7）由此可见，PriorityQueue是一个小顶堆。</p><h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><p>（1）当数组比较小（小于64）的时候每次扩容容量翻倍；</p><p>（2）当数组比较大的时候每次扩容只增加一半的容量；</p><h3 id="出队"><a href="#出队" class="headerlink" title="出队"></a>出队</h3><p>（1）将队列首元素弹出；</p><p>（2）将队列末元素移到队列首；</p><p>（3）自上而下堆化，一直往下与最小的子节点比较；</p><p>（4）如果比最小的子节点大，就交换位置，再继续与最小的子节点比较；</p><p>（5）如果比最小的子节点小，就不用交换位置了，堆化结束；</p><p>（6）这就是堆中的删除堆顶元素；</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>（1）PriorityQueue是一个小顶堆；</p><p>（2）PriorityQueue是非线程安全的；</p><p>（3）PriorityQueue不是有序的，只有堆顶存储着最小的元素；</p><p>（4）入队就是堆的插入元素的实现；</p><p>（5）出队就是堆的删除元素的实现；</p><h2 id="ArrayBlockingQueue"><a href="#ArrayBlockingQueue" class="headerlink" title="ArrayBlockingQueue"></a>ArrayBlockingQueue</h2><p>ArrayBlockingQueue是java并发包下一个以数组实现的阻塞队列，它是线程安全的</p><h3 id="主要属性-1"><a href="#主要属性-1" class="headerlink" title="主要属性"></a>主要属性</h3><p>（1）利用数组存储元素；</p><p>（2）通过放指针和取指针来标记下一次操作的位置；</p><p>（3）利用重入锁来保证并发安全；</p><h3 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h3><p>（1）ArrayBlockingQueue初始化时必须传入容量，也就是数组的大小；</p><p>（2）可以通过构造方法控制重入锁的类型是公平锁还是非公平锁；</p><h3 id="入队-1"><a href="#入队-1" class="headerlink" title="入队"></a>入队</h3><p>（1）add(e)时如果队列满了则抛出异常；</p><p>（2）offer(e)时如果队列满了则返回false；</p><p>（3）put(e)时如果队列满了则使用notFull等待；</p><p>（4）offer(e, timeout, unit)时如果队列满了则等待一段时间后如果队列依然满就返回false；</p><p>（5）利用放指针循环使用数组来存储元素；</p><h3 id="出队-1"><a href="#出队-1" class="headerlink" title="出队"></a>出队</h3><p>（1）remove()时如果队列为空则抛出异常；</p><p>（2）poll()时如果队列为空则返回null；</p><p>（3）take()时如果队列为空则阻塞等待在条件notEmpty上；</p><p>（4）poll(timeout, unit)时如果队列为空则阻塞等待一段时间后如果还为空就返回null；</p><p>（5）利用取指针循环从数组中取元素；</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>（1）ArrayBlockingQueue不需要扩容，因为是初始化时指定容量，并循环利用数组；</p><p>（2）ArrayBlockingQueue利用takeIndex和putIndex循环利用数组；</p><p>（3）入队和出队各定义了四组方法为满足不同的用途；</p><p>（4）利用重入锁和两个条件保证并发安全；</p><h3 id="ArrayBlockingQueue有哪些缺点呢？"><a href="#ArrayBlockingQueue有哪些缺点呢？" class="headerlink" title="ArrayBlockingQueue有哪些缺点呢？"></a>ArrayBlockingQueue有哪些缺点呢？</h3><p>a）队列长度固定且必须在初始化时指定，所以使用之前一定要慎重考虑好容量；</p><p>b）如果消费速度跟不上入队速度，则会导致提供者线程一直阻塞，且越阻塞越多，非常危险；</p><p>c）只使用了一个锁来控制入队出队，效率较低，可以借助分段的思想把入队出队分裂成两个锁。</p><h2 id="LinkedBlockingQueue"><a href="#LinkedBlockingQueue" class="headerlink" title="LinkedBlockingQueue"></a>LinkedBlockingQueue</h2><p>LinkedBlockingQueue是java并发包下一个以单链表实现的阻塞队列，它是线程安全的</p><h3 id="主要属性-2"><a href="#主要属性-2" class="headerlink" title="主要属性"></a>主要属性</h3><p>（1）capacity，有容量，可以理解为LinkedBlockingQueue是有界队列</p><p>（2）head, last，链表头、链表尾指针</p><p>（3）takeLock，notEmpty，take锁及其对应的条件</p><p>（4）putLock, notFull，put锁及其对应的条件</p><p>（5）入队、出队使用两个不同的锁控制，锁分离，提高效率</p><h3 id="入队-2"><a href="#入队-2" class="headerlink" title="入队"></a>入队</h3><p>（1）使用putLock加锁；</p><p>（2）如果队列满了就阻塞在notFull条件上；</p><p>（3）否则就入队；</p><p>（4）如果入队后元素数量小于容量，唤醒其它阻塞在notFull条件上的线程；</p><p>（5）释放锁；</p><p>（6）如果放元素之前队列长度为0，就唤醒notEmpty条件；</p><h3 id="出队-2"><a href="#出队-2" class="headerlink" title="出队"></a>出队</h3><p>（1）使用takeLock加锁；</p><p>（2）如果队列空了就阻塞在notEmpty条件上；</p><p>（3）否则就出队；</p><p>（4）如果出队前元素数量大于1，唤醒其它阻塞在notEmpty条件上的线程；</p><p>（5）释放锁；</p><p>（6）如果取元素之前队列长度等于容量，就唤醒notFull条件；</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>（1）LinkedBlockingQueue采用单链表的形式实现；</p><p>（2）LinkedBlockingQueue采用两把锁的锁分离技术实现入队出队互不阻塞；</p><p>（3）LinkedBlockingQueue是有界队列，不传入容量时默认为最大int值；</p><h3 id="LinkedBlockingQueue与ArrayBlockingQueue对比？"><a href="#LinkedBlockingQueue与ArrayBlockingQueue对比？" class="headerlink" title="LinkedBlockingQueue与ArrayBlockingQueue对比？"></a>LinkedBlockingQueue与ArrayBlockingQueue对比？</h3><p>a）后者入队出队采用一把锁，导致入队出队相互阻塞，效率低下；</p><p>b）前才入队出队采用两把锁，入队出队互不干扰，效率较高；</p><p>c）二者都是有界队列，如果长度相等且出队速度跟不上入队速度，都会导致大量线程阻塞；</p><p>d）前者如果初始化不传入初始容量，则使用最大int值，如果出队速度跟不上入队速度，会导致队列特别长，占用大量内存；</p><h2 id="SynchronousQueue"><a href="#SynchronousQueue" class="headerlink" title="SynchronousQueue"></a>SynchronousQueue</h2><p>SynchronousQueue是java并发包下无缓冲阻塞队列，它用来在两个线程之间移交元素</p><h3 id="主要属性-3"><a href="#主要属性-3" class="headerlink" title="主要属性"></a>主要属性</h3><p>（1）这个阻塞队列里面是会自旋的；</p><p>（2）它使用了一个叫做transferer的东西来交换元素；</p><h3 id="主要内部类"><a href="#主要内部类" class="headerlink" title="主要内部类"></a>主要内部类</h3><p>（1）定义了一个抽象类Transferer，里面定义了一个传输元素的方法；</p><p>（2）有两种传输元素的方法，一种是栈，一种是队列；</p><p>（3）栈的特点是后进先出，队列的特点是先进行出；</p><p>（4）栈只需要保存一个头节点就可以了，因为存取元素都是操作头节点；</p><p>（5）队列需要保存一个头节点一个尾节点，因为存元素操作尾节点，取元素操作头节点；</p><p>（6）每个节点中保存着存储的元素、等待着的线程，以及下一个节点；</p><h3 id="构造方法-1"><a href="#构造方法-1" class="headerlink" title="构造方法"></a>构造方法</h3><p>（1）默认使用非公平模式，也就是栈结构；</p><p>（2）公平模式使用队列，非公平模式使用栈；</p><h3 id="入队-3"><a href="#入队-3" class="headerlink" title="入队"></a>入队</h3><p>调用transferer的transfer()方法，传入元素e，说明是生产者</p><h3 id="出队-3"><a href="#出队-3" class="headerlink" title="出队"></a>出队</h3><p>调用transferer的transfer()方法，传入null，说明是消费者。</p><h3 id="transferer"><a href="#transferer" class="headerlink" title="transferer"></a>transferer</h3><p>（1）如果栈中没有元素，或者栈顶元素跟将要入栈的元素模式一样，就入栈；</p><p>（2）入栈后自旋等待一会看有没有其它线程匹配到它，自旋完了还没匹配到元素就阻塞等待；</p><p>（3）阻塞等待被唤醒了说明其它线程匹配到了当前的元素，就返回匹配到的元素；</p><p>（4）如果两者模式不一样，且头节点没有在匹配中，就拿当前节点跟它匹配，匹配成功了就返回匹配到的元素；</p><p>（5）如果两者模式不一样，且头节点正在匹配中，当前线程就协助去匹配，匹配完成了再让当前节点重新入栈重新匹配；</p><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><p>1）SynchronousQueue是java里的无缓冲队列，用于在两个线程之间直接移交元素；</p><p>（2）SynchronousQueue有两种实现方式，一种是公平（队列）方式，一种是非公平（栈）方式；</p><p>（3）栈方式中的节点有三种模式：生产者、消费者、正在匹配中；</p><p>（4）栈方式的大致思路是如果栈顶元素跟自己一样的模式就入栈并等待被匹配，否则就匹配，匹配到了就返回；</p><h3 id="SynchronousQueue真的是无缓冲的队列吗？"><a href="#SynchronousQueue真的是无缓冲的队列吗？" class="headerlink" title="SynchronousQueue真的是无缓冲的队列吗？"></a>SynchronousQueue真的是无缓冲的队列吗？</h3><p>通过源码分析，我们可以发现其实SynchronousQueue内部或者使用栈或者使用队列来存储包含线程和元素值的节点，如果同一个模式的节点过多的话，它们都会存储进来，且都会阻塞着，所以，严格上来说，SynchronousQueue并不能算是一个无缓冲队列。</p><h3 id="SynchronousQueue有什么缺点呢？"><a href="#SynchronousQueue有什么缺点呢？" class="headerlink" title="SynchronousQueue有什么缺点呢？"></a>SynchronousQueue有什么缺点呢？</h3><p>试想一下，如果有多个生产者，但只有一个消费者，如果消费者处理不过来，是不是生产者都会阻塞起来？反之亦然。</p><p>这是一件很危险的事，所以，SynchronousQueue一般用于生产、消费的速度大致相当的情况，这样才不会导致系统中过多的线程处于阻塞状态。</p><h2 id="PriorityBlockingQueue"><a href="#PriorityBlockingQueue" class="headerlink" title="PriorityBlockingQueue"></a>PriorityBlockingQueue</h2><p>PriorityBlockingQueue是java并发包下的优先级阻塞队列，它是线程安全的</p><h3 id="主要属性-4"><a href="#主要属性-4" class="headerlink" title="主要属性"></a>主要属性</h3><p>（1）依然是使用一个数组来使用元素；</p><p>（2）使用一个锁加一个notEmpty条件来保证并发安全；</p><p>（3）使用一个变量的CAS操作来控制扩容；</p><h3 id="入队-4"><a href="#入队-4" class="headerlink" title="入队"></a>入队</h3><p>入队的整个操作跟PriorityQueue几乎一致：</p><p>（1）加锁；</p><p>（2）判断是否需要扩容；</p><p>（3）添加元素并做自下而上的堆化；</p><p>（4）元素个数加1并唤醒notEmpty条件，唤醒取元素的线程；</p><p>（5）解锁；</p><h3 id="扩容-1"><a href="#扩容-1" class="headerlink" title="扩容"></a>扩容</h3><p>（1）解锁，解除offer()方法中加的锁；</p><p>（2）使用allocationSpinLock变量的CAS操作来控制扩容的过程；</p><p>（3）旧容量小于64则翻倍，旧容量大于64则增加一半；</p><p>（4）创建新数组；</p><p>（5）修改allocationSpinLock为0，相当于解锁；</p><p>（6）其它线程在扩容的过程中要让出CPU；</p><p>（7）再次加锁；</p><p>（8）新数组创建成功，把旧数组元素拷贝过来，并返回到offer()方法中继续添加元素操作；</p><h3 id="出队-4"><a href="#出队-4" class="headerlink" title="出队"></a>出队</h3><p>（1）加锁；</p><p>（2）判断是否出队成功，未成功就阻塞在notEmpty条件上；</p><p>（3）出队时弹出堆顶元素，并把堆尾元素拿到堆顶；</p><p>（4）再做自上而下的堆化；</p><p>（5）解锁；</p><h3 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h3><p>（1）PriorityBlockingQueue整个入队出队的过程与PriorityQueue基本是保持一致的；</p><p>（2）PriorityBlockingQueue使用一个锁+一个notEmpty条件控制并发安全；</p><p>（3）PriorityBlockingQueue扩容时使用一个单独变量的CAS操作来控制只有一个线程进行扩容；</p><p>（4）入队使用自下而上的堆化；</p><p>（5）出队使用自上而下的堆化；</p><ul><li><p>为什么PriorityBlockingQueue不需要notFull条件？</p></li><li><p>因为PriorityBlockingQueue在入队的时候如果没有空间了是会自动扩容的，也就不存在队列满了的状态，也就是不需要等待通知队列不满了可以放元素了，所以也就不需要notFull条件了。</p></li></ul><h2 id="LinkedTransferQueue"><a href="#LinkedTransferQueue" class="headerlink" title="LinkedTransferQueue"></a>LinkedTransferQueue</h2><p>LinkedTransferQueue是LinkedBlockingQueue、SynchronousQueue（公平模式）、ConcurrentLinkedQueue三者的集合体，它综合了这三者的方法，并且提供了更加高效的实现方式。</p><h3 id="继承体系"><a href="#继承体系" class="headerlink" title="继承体系"></a>继承体系</h3><p>LinkedTransferQueue实现了TransferQueue接口，而TransferQueue接口是继承自BlockingQueue的，所以LinkedTransferQueue也是一个阻塞队列。</p><h3 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h3><p>LinkedTransferQueue使用了一个叫做dual data structure的数据结构，或者叫做dual queue，译为双重数据结构或者双重队列。</p><p>双重队列是什么意思呢？</p><p>放取元素使用同一个队列，队列中的节点具有两种模式，一种是数据节点，一种是非数据节点。</p><p>放元素时先跟队列头节点对比，如果头节点是非数据节点，就让他们匹配，如果头节点是数据节点，就生成一个数据节点放在队列尾端（入队）。</p><p>取元素时也是先跟队列头节点对比，如果头节点是数据节点，就让他们匹配，如果头节点是非数据节点，就生成一个非数据节点放在队列尾端（入队）。<br>不管是放元素还是取元素，都先跟头节点对比，如果二者模式不一样就匹配它们，如果二者模式一样，就入队。</p><p>典型的单链表结构，内部除了存储元素的值和下一个节点的指针外，还包含了是否为数据节点和持有元素的线程。是无界的一个阻塞队列。</p><h3 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h3><p>（1）LinkedTransferQueue可以看作LinkedBlockingQueue、SynchronousQueue（公平模式）、ConcurrentLinkedQueue三者的集合体；</p><p>（2）LinkedTransferQueue的实现方式是使用一种叫做双重队列的数据结构；</p><p>（3）不管是取元素还是放元素都会入队；</p><p>（4）先尝试跟头节点比较，如果二者模式不一样，就匹配它们，组成CP，然后返回对方的值；</p><p>（5）如果二者模式一样，就入队，并自旋或阻塞等待被唤醒；</p><p>（6）至于是否入队及阻塞有四种模式，NOW、ASYNC、SYNC、TIMED；</p><p>（7）LinkedTransferQueue全程都没有使用synchronized、重入锁等比较重的锁，基本是通过 自旋+CAS 实现；</p><p>（8）对于入队之后，先自旋一定次数后再调用LockSupport.park()或LockSupport.parkNanos阻塞；</p><ul><li>LinkedTransferQueue与SynchronousQueue（公平模式）有什么异同呢？</li></ul><p>（1）在java8中两者的实现方式基本一致，都是使用的双重队列；</p><p>（2）前者完全实现了后者，但比后者更灵活；</p><p>（3）后者不管放元素还是取元素，如果没有可匹配的元素，所在的线程都会阻塞；</p><p>（4）前者可以自己控制放元素是否需要阻塞线程，比如使用四个添加元素的方法就不会阻塞线程，只入队元素，使用transfer()会阻塞线程；</p><p>（5）取元素两者基本一样，都会阻塞等待有新的元素进入被匹配到；</p><h2 id="ConcurrentLinkedQueue"><a href="#ConcurrentLinkedQueue" class="headerlink" title="ConcurrentLinkedQueue"></a>ConcurrentLinkedQueue</h2><p>ConcurrentLinkedQueue只实现了Queue接口，并没有实现BlockingQueue接口，所以它不是阻塞队列，也不能用于线程池中，但是它是线程安全的，可用于多线程环境中。</p><h3 id="主要属性-5"><a href="#主要属性-5" class="headerlink" title="主要属性"></a>主要属性</h3><p>就这两个主要属性，一个头节点，一个尾节点。这是一个无界的单链表实现的队列。</p><h3 id="入队-5"><a href="#入队-5" class="headerlink" title="入队"></a>入队</h3><p>入队整个流程还是比较清晰的，这里有个前提是出队时会把出队的那个节点的next设置为节点本身。</p><p>（1）定位到链表尾部，尝试把新节点到后面；</p><p>（2）如果尾部变化了，则重新获取尾部，再重试；</p><h3 id="出队-5"><a href="#出队-5" class="headerlink" title="出队"></a>出队</h3><p>（1）定位到头节点，尝试更新其值为null；</p><p>（2）如果成功了，就成功出队；</p><p>（3）如果失败或者头节点变化了，就重新寻找头节点，并重试；</p><p>（4）整个出队过程没有一点阻塞相关的代码，所以出队的时候不会阻塞线程，没找到元素就返回null；</p><h3 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h3><p>（1）ConcurrentLinkedQueue不是阻塞队列；</p><p>（2）ConcurrentLinkedQueue不能用在线程池中；</p><p>（3）ConcurrentLinkedQueue使用（CAS+自旋）更新头尾节点控制出队入队操作；</p><ul><li>ConcurrentLinkedQueue与LinkedBlockingQueue对比？</li></ul><p>（1）两者都是线程安全的队列；</p><p>（2）两者都可以实现取元素时队列为空直接返回null，后者的poll()方法可以实现此功能；</p><p>（3）前者全程无锁，后者全部都是使用重入锁控制的；</p><p>（4）前者效率较高，后者效率较低；</p><p>（5）前者无法实现如果队列为空等待元素到来的操作；</p><p>（6）前者是非阻塞队列，后者是阻塞队列；</p><p>（7）前者无法用在线程池中，后者可以；</p><h2 id="DelayQueue"><a href="#DelayQueue" class="headerlink" title="DelayQueue"></a>DelayQueue</h2><p>DelayQueue是java并发包下的延时阻塞队列，常用于实现定时任务。</p><p>从继承体系可以看到，DelayQueue实现了BlockingQueue，所以它是一个阻塞队列。</p><p>另外，DelayQueue还组合了一个叫做Delayed的接口，DelayQueue中存储的所有元素必须实现Delayed接口。</p><p>Delayed是一个继承自Comparable的接口，并且定义了一个getDelay()方法，用于表示还有多少时间到期，到期了应返回小于等于0的数值。</p><h3 id="主要属性-6"><a href="#主要属性-6" class="headerlink" title="主要属性"></a>主要属性</h3><p>从属性我们可以知道，延时队列主要使用优先级队列来实现，并辅以重入锁和条件来控制并发安全。</p><p>因为优先级队列是无界的，所以这里只需要一个条件就可以了。</p><h3 id="入队-6"><a href="#入队-6" class="headerlink" title="入队"></a>入队</h3><p>（1）加锁；</p><p>（2）添加元素到优先级队列中；</p><p>（3）如果添加的元素是堆顶元素，就把leader置为空，并唤醒等待在条件available上的线程；</p><p>（4）解锁；</p><h3 id="出队-6"><a href="#出队-6" class="headerlink" title="出队"></a>出队</h3><p>（1）加锁；</p><p>（2）检查第一个元素，如果为空或者还没到期，就返回null；</p><p>（3）如果第一个元素到期了就调用poll()弹出第一个元素；</p><p>（4）解锁。</p><h3 id="总结-6"><a href="#总结-6" class="headerlink" title="总结"></a>总结</h3><p>（1）DelayQueue是阻塞队列；</p><p>（2）DelayQueue内部存储结构使用优先级队列；</p><p>（3）DelayQueue使用重入锁和条件来控制并发安全；</p><p>（4）DelayQueue常用于定时任务；</p><ul><li>java中的线程池实现定时任务是直接用的DelayQueue吗？</li></ul><p>当然不是，ScheduledThreadPoolExecutor中使用的是它自己定义的内部类DelayedWorkQueue，其实里面的实现逻辑基本都是一样的，只不过DelayedWorkQueue里面没有使用现在的PriorityQueue，而是使用数组又实现了一遍优先级队列，本质上没有什么区别。</p><h2 id="ArrayDeque"><a href="#ArrayDeque" class="headerlink" title="ArrayDeque"></a>ArrayDeque</h2><p>双端队列是一种特殊的队列，它的两端都可以进出元素，故而得名双端队列。</p><p>ArrayDeque是一种以数组方式实现的双端队列，它是非线程安全的。</p><p>通过继承体系可以看，ArrayDeque实现了Deque接口，Deque接口继承自Queue接口，它是对Queue的一种增强。</p><p>从属性我们可以看到，ArrayDeque使用数组存储元素，并使用头尾指针标识队列的头和尾，其最小容量是8。</p><p>通过构造方法，我们知道默认初始容量是16，最小容量是8。</p><h2 id="入队-7"><a href="#入队-7" class="headerlink" title="入队"></a>入队</h2><p>（1）入队有两种方式，从队列头或者从队列尾；</p><p>（2）如果容量不够了，直接扩大为两倍；</p><p>（3）通过取模的方式让头尾指针在数组范围内循环；</p><p>（4）x &amp; (len - 1) = x % len，使用&amp;的方式更快；</p><h3 id="出队-7"><a href="#出队-7" class="headerlink" title="出队"></a>出队</h3><p>（1）出队有两种方式，从队列头或者从队列尾；</p><p>（2）通过取模的方式让头尾指针在数组范围内循环；</p><p>（3）出队之后没有缩容哈哈^^</p><h3 id="总结-7"><a href="#总结-7" class="headerlink" title="总结"></a>总结</h3><p>（1）ArrayDeque是采用数组方式实现的双端队列；</p><p>（2）ArrayDeque的出队入队是通过头尾指针循环利用数组实现的；</p><p>（3）ArrayDeque容量不足时是会扩容的，每次扩容容量增加一倍；</p><p>（4）ArrayDeque可以直接作为栈使用；</p><h2 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h2><p>（1）LinkedList是一个以双链表实现的List；</p><p>（2）LinkedList还是一个双端队列，具有队列、双端队列、栈的特性；</p><p>（3）LinkedList在队列首尾添加、删除元素非常高效，时间复杂度为O(1)；</p><p>（4）LinkedList在中间添加、删除元素比较低效，时间复杂度为O(n)；</p><p>（5）LinkedList不支持随机访问，所以访问非队列首尾的元素比较低效；</p><p>（6）LinkedList在功能上等于ArrayList + ArrayDeque；</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;PriorityQueue&quot;&gt;&lt;a href=&quot;#PriorityQueue&quot; class=&quot;headerlink&quot; title=&quot;PriorityQueue&quot;&gt;&lt;/a&gt;PriorityQueue&lt;/h2&gt;&lt;p&gt;优先级队列，是0个或多个元素的集合，集合中的每个元素</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    <category term="集合" scheme="http://example.com/categories/Java/%E9%9B%86%E5%90%88/"/>
    
    
    <category term="集合" scheme="http://example.com/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="Queue" scheme="http://example.com/tags/Queue/"/>
    
  </entry>
  
  <entry>
    <title>Java中的Set那些事</title>
    <link href="http://example.com/2022/04/03/Java%E4%B8%AD%E7%9A%84Set%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <id>http://example.com/2022/04/03/Java%E4%B8%AD%E7%9A%84Set%E9%82%A3%E4%BA%9B%E4%BA%8B/</id>
    <published>2022-04-03T07:31:00.000Z</published>
    <updated>2022-04-03T08:00:23.733Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h2><p>（1）HashSet内部使用HashMap的key存储元素，以此来保证元素不重复；</p><p>（2）HashSet是无序的，因为HashMap的key是无序的；</p><p>（3）HashSet中允许有一个null元素，因为HashMap允许key为null；</p><p>（4）HashSet是非线程安全的；</p><p>（5）HashSet是没有get()方法的；</p><pre><code> public class HashSet&lt;E&gt;        extends AbstractSet&lt;E&gt;        implements Set&lt;E&gt;, Cloneable, java.io.Serializable    &#123;        static final long serialVersionUID = -5024744406713321676L;            // 内部元素存储在HashMap中        private transient HashMap&lt;E,Object&gt; map;            // 虚拟元素，用来存到map元素的value中的，没有实际意义        private static final Object PRESENT = new Object();            // 空构造方法        public HashSet() &#123;            map = new HashMap&lt;&gt;();        &#125;            // 把另一个集合的元素全都添加到当前Set中        // 注意，这里初始化map的时候是计算了它的初始容量的        public HashSet(Collection&lt;? extends E&gt; c) &#123;            map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16));            addAll(c);        &#125;            // 指定初始容量和装载因子        public HashSet(int initialCapacity, float loadFactor) &#123;            map = new HashMap&lt;&gt;(initialCapacity, loadFactor);        &#125;            // 只指定初始容量        public HashSet(int initialCapacity) &#123;            map = new HashMap&lt;&gt;(initialCapacity);        &#125;            // LinkedHashSet专用的方法        // dummy是没有实际意义的, 只是为了跟上上面那个操持方法签名不同而已        HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123;            map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);        &#125;            // 迭代器        public Iterator&lt;E&gt; iterator() &#123;            return map.keySet().iterator();        &#125;            // 元素个数        public int size() &#123;            return map.size();        &#125;            // 检查是否为空        public boolean isEmpty() &#123;            return map.isEmpty();        &#125;            // 检查是否包含某个元素        public boolean contains(Object o) &#123;            return map.containsKey(o);        &#125;            // 添加元素        public boolean add(E e) &#123;            return map.put(e, PRESENT)==null;        &#125;            // 删除元素        public boolean remove(Object o) &#123;            return map.remove(o)==PRESENT;        &#125;            // 清空所有元素        public void clear() &#123;            map.clear();        &#125;            // 克隆方法        @SuppressWarnings(&quot;unchecked&quot;)        public Object clone() &#123;            try &#123;                HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone();                newSet.map = (HashMap&lt;E, Object&gt;) map.clone();                return newSet;            &#125; catch (CloneNotSupportedException e) &#123;                throw new InternalError(e);            &#125;        &#125;            // 序列化写出方法        private void writeObject(java.io.ObjectOutputStream s)            throws java.io.IOException &#123;            // 写出非static非transient属性            s.defaultWriteObject();                // 写出map的容量和装载因子            s.writeInt(map.capacity());            s.writeFloat(map.loadFactor());                // 写出元素个数            s.writeInt(map.size());                // 遍历写出所有元素            for (E e : map.keySet())                s.writeObject(e);        &#125;            // 序列化读入方法        private void readObject(java.io.ObjectInputStream s)            throws java.io.IOException, ClassNotFoundException &#123;            // 读入非static非transient属性            s.defaultReadObject();                // 读入容量, 并检查不能小于0            int capacity = s.readInt();            if (capacity &lt; 0) &#123;                throw new InvalidObjectException(&quot;Illegal capacity: &quot; +                                                 capacity);            &#125;                // 读入装载因子, 并检查不能小于等于0或者是NaN(Not a Number)            // java.lang.Float.NaN = 0.0f / 0.0f;            float loadFactor = s.readFloat();            if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) &#123;                throw new InvalidObjectException(&quot;Illegal load factor: &quot; +                                                 loadFactor);            &#125;                // 读入元素个数并检查不能小于0            int size = s.readInt();            if (size &lt; 0) &#123;                throw new InvalidObjectException(&quot;Illegal size: &quot; +                                                 size);            &#125;            // 根据元素个数重新设置容量            // 这是为了保证map有足够的容量容纳所有元素, 防止无意义的扩容            capacity = (int) Math.min(size * Math.min(1 / loadFactor, 4.0f),                    HashMap.MAXIMUM_CAPACITY);                // 再次检查某些东西, 不重要的代码忽视掉            SharedSecrets.getJavaOISAccess()                         .checkArray(s, Map.Entry[].class, HashMap.tableSizeFor(capacity));                // 创建map, 检查是不是LinkedHashSet类型            map = (((HashSet&lt;?&gt;)this) instanceof LinkedHashSet ?                   new LinkedHashMap&lt;E,Object&gt;(capacity, loadFactor) :                   new HashMap&lt;E,Object&gt;(capacity, loadFactor));                // 读入所有元素, 并放入map中            for (int i=0; i&lt;size; i++) &#123;                @SuppressWarnings(&quot;unchecked&quot;)                    E e = (E) s.readObject();                map.put(e, PRESENT);            &#125;        &#125;            // 可分割的迭代器, 主要用于多线程并行迭代处理时使用        public Spliterator&lt;E&gt; spliterator() &#123;            return new HashMap.KeySpliterator&lt;E,Object&gt;(map, 0, -1, 0, 0);        &#125;    &#125;</code></pre><h2 id="LinkedHashSet"><a href="#LinkedHashSet" class="headerlink" title="LinkedHashSet"></a>LinkedHashSet</h2><p>（1）LinkedHashSet的底层使用LinkedHashMap存储元素。</p><p>（2）LinkedHashSet是有序的，它是按照插入的顺序排序的。</p><ul><li>注意：LinkedHashSet是不支持按访问顺序对元素排序的，只能按插入顺序排序。<pre><code>  package java.util;    // LinkedHashSet继承自HashSet  public class LinkedHashSet&lt;E&gt;      extends HashSet&lt;E&gt;      implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123;        private static final long serialVersionUID = -2851667679971038690L;        // 传入容量和装载因子      public LinkedHashSet(int initialCapacity, float loadFactor) &#123;          super(initialCapacity, loadFactor, true);      &#125;        // 只传入容量, 装载因子默认为0.75      public LinkedHashSet(int initialCapacity) &#123;          super(initialCapacity, .75f, true);      &#125;        // 使用默认容量16, 默认装载因子0.75      public LinkedHashSet() &#123;          super(16, .75f, true);      &#125;        // 将集合c中的所有元素添加到LinkedHashSet中      // 好奇怪, 这里计算容量的方式又变了      // HashSet中使用的是Math.max((int) (c.size()/.75f) + 1, 16)      // 这一点有点不得其解, 是作者偷懒？      public LinkedHashSet(Collection&lt;? extends E&gt; c) &#123;          super(Math.max(2*c.size(), 11), .75f, true);          addAll(c);      &#125;        // 可分割的迭代器, 主要用于多线程并行迭代处理时使用      @Override      public Spliterator&lt;E&gt; spliterator() &#123;          return Spliterators.spliterator(this, Spliterator.DISTINCT | Spliterator.ORDERED);      &#125;  &#125;</code></pre></li></ul><h2 id="TreeSet"><a href="#TreeSet" class="headerlink" title="TreeSet"></a>TreeSet</h2><p>（1）TreeSet底层使用NavigableMap存储元素；</p><p>（2）TreeSet是有序的；</p><p>（3）TreeSet是非线程安全的；</p><p>（4）TreeSet实现了NavigableSet接口，而NavigableSet继承自SortedSet接口；</p><p>（5）TreeSet实现了SortedSet接口；</p><pre><code>package java.util;        // TreeSet实现了NavigableSet接口，所以它是有序的    public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt;        implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable    &#123;        // 元素存储在NavigableMap中        // 注意它不一定就是TreeMap        private transient NavigableMap&lt;E,Object&gt; m;            // 虚拟元素, 用来作为value存储在map中        private static final Object PRESENT = new Object();            // 直接使用传进来的NavigableMap存储元素        // 这里不是深拷贝,如果外面的map有增删元素也会反映到这里        // 而且, 这个方法不是public的, 说明只能给同包使用        TreeSet(NavigableMap&lt;E,Object&gt; m) &#123;            this.m = m;        &#125;            // 使用TreeMap初始化        public TreeSet() &#123;            this(new TreeMap&lt;E,Object&gt;());        &#125;            // 使用带comparator的TreeMap初始化        public TreeSet(Comparator&lt;? super E&gt; comparator) &#123;            this(new TreeMap&lt;&gt;(comparator));        &#125;            // 将集合c中的所有元素添加的TreeSet中        public TreeSet(Collection&lt;? extends E&gt; c) &#123;            this();            addAll(c);        &#125;            // 将SortedSet中的所有元素添加到TreeSet中        public TreeSet(SortedSet&lt;E&gt; s) &#123;            this(s.comparator());            addAll(s);        &#125;            // 迭代器        public Iterator&lt;E&gt; iterator() &#123;            return m.navigableKeySet().iterator();        &#125;            // 逆序迭代器        public Iterator&lt;E&gt; descendingIterator() &#123;            return m.descendingKeySet().iterator();        &#125;            // 以逆序返回一个新的TreeSet        public NavigableSet&lt;E&gt; descendingSet() &#123;            return new TreeSet&lt;&gt;(m.descendingMap());        &#125;            // 元素个数        public int size() &#123;            return m.size();        &#125;            // 判断是否为空        public boolean isEmpty() &#123;            return m.isEmpty();        &#125;            // 判断是否包含某元素        public boolean contains(Object o) &#123;            return m.containsKey(o);        &#125;            // 添加元素, 调用map的put()方法, value为PRESENT        public boolean add(E e) &#123;            return m.put(e, PRESENT)==null;        &#125;            // 删除元素        public boolean remove(Object o) &#123;            return m.remove(o)==PRESENT;        &#125;            // 清空所有元素        public void clear() &#123;            m.clear();        &#125;            // 添加集合c中的所有元素        public  boolean addAll(Collection&lt;? extends E&gt; c) &#123;            // 满足一定条件时直接调用TreeMap的addAllForTreeSet()方法添加元素            if (m.size()==0 &amp;&amp; c.size() &gt; 0 &amp;&amp;                c instanceof SortedSet &amp;&amp;                m instanceof TreeMap) &#123;                SortedSet&lt;? extends E&gt; set = (SortedSet&lt;? extends E&gt;) c;                TreeMap&lt;E,Object&gt; map = (TreeMap&lt;E, Object&gt;) m;                Comparator&lt;?&gt; cc = set.comparator();                Comparator&lt;? super E&gt; mc = map.comparator();                if (cc==mc || (cc != null &amp;&amp; cc.equals(mc))) &#123;                    map.addAllForTreeSet(set, PRESENT);                    return true;                &#125;            &#125;            // 不满足上述条件, 调用父类的addAll()通过遍历的方式一个一个地添加元素            return super.addAll(c);        &#125;            // 子set（NavigableSet中的方法）        public NavigableSet&lt;E&gt; subSet(E fromElement, boolean fromInclusive,                                      E toElement,   boolean toInclusive) &#123;            return new TreeSet&lt;&gt;(m.subMap(fromElement, fromInclusive,                                           toElement,   toInclusive));        &#125;            // 头set（NavigableSet中的方法）        public NavigableSet&lt;E&gt; headSet(E toElement, boolean inclusive) &#123;            return new TreeSet&lt;&gt;(m.headMap(toElement, inclusive));        &#125;            // 尾set（NavigableSet中的方法）        public NavigableSet&lt;E&gt; tailSet(E fromElement, boolean inclusive) &#123;            return new TreeSet&lt;&gt;(m.tailMap(fromElement, inclusive));        &#125;            // 子set（SortedSet接口中的方法）        public SortedSet&lt;E&gt; subSet(E fromElement, E toElement) &#123;            return subSet(fromElement, true, toElement, false);        &#125;            // 头set（SortedSet接口中的方法）        public SortedSet&lt;E&gt; headSet(E toElement) &#123;            return headSet(toElement, false);        &#125;            // 尾set（SortedSet接口中的方法）        public SortedSet&lt;E&gt; tailSet(E fromElement) &#123;            return tailSet(fromElement, true);        &#125;            // 比较器        public Comparator&lt;? super E&gt; comparator() &#123;            return m.comparator();        &#125;            // 返回最小的元素        public E first() &#123;            return m.firstKey();        &#125;            // 返回最大的元素        public E last() &#123;            return m.lastKey();        &#125;            // 返回小于e的最大的元素        public E lower(E e) &#123;            return m.lowerKey(e);        &#125;            // 返回小于等于e的最大的元素        public E floor(E e) &#123;            return m.floorKey(e);        &#125;            // 返回大于等于e的最小的元素        public E ceiling(E e) &#123;            return m.ceilingKey(e);        &#125;            // 返回大于e的最小的元素        public E higher(E e) &#123;            return m.higherKey(e);        &#125;            // 弹出最小的元素        public E pollFirst() &#123;            Map.Entry&lt;E,?&gt; e = m.pollFirstEntry();            return (e == null) ? null : e.getKey();        &#125;            public E pollLast() &#123;            Map.Entry&lt;E,?&gt; e = m.pollLastEntry();            return (e == null) ? null : e.getKey();        &#125;            // 克隆方法        @SuppressWarnings(&quot;unchecked&quot;)        public Object clone() &#123;            TreeSet&lt;E&gt; clone;            try &#123;                clone = (TreeSet&lt;E&gt;) super.clone();            &#125; catch (CloneNotSupportedException e) &#123;                throw new InternalError(e);            &#125;                clone.m = new TreeMap&lt;&gt;(m);            return clone;        &#125;            // 序列化写出方法        private void writeObject(java.io.ObjectOutputStream s)            throws java.io.IOException &#123;            // Write out any hidden stuff            s.defaultWriteObject();                // Write out Comparator            s.writeObject(m.comparator());                // Write out size            s.writeInt(m.size());                // Write out all elements in the proper order.            for (E e : m.keySet())                s.writeObject(e);        &#125;            // 序列化写入方法        private void readObject(java.io.ObjectInputStream s)            throws java.io.IOException, ClassNotFoundException &#123;            // Read in any hidden stuff            s.defaultReadObject();                // Read in Comparator            @SuppressWarnings(&quot;unchecked&quot;)                Comparator&lt;? super E&gt; c = (Comparator&lt;? super E&gt;) s.readObject();                // Create backing TreeMap            TreeMap&lt;E,Object&gt; tm = new TreeMap&lt;&gt;(c);            m = tm;                // Read in size            int size = s.readInt();                tm.readTreeSet(size, s, PRESENT);        &#125;            // 可分割的迭代器        public Spliterator&lt;E&gt; spliterator() &#123;            return TreeMap.keySpliteratorFor(m);        &#125;            // 序列化id        private static final long serialVersionUID = -2479143000061671589L;    &#125;    </code></pre><p>（1）我们知道TreeSet和LinkedHashSet都是有序的，那它们有何不同？</p><ul><li>LinkedHashSet并没有实现SortedSet接口，它的有序性主要依赖于LinkedHashMap的有序性，所以它的有序性是指按照插入顺序保证的有序性；而TreeSet实现了SortedSet接口，它的有序性主要依赖于NavigableMap的有序性，而NavigableMap又继承自SortedMap，这个接口的有序性是指按照key的自然排序保证的有序性，而key的自然排序又有两种实现方式，一种是key实现Comparable接口，一种是构造方法传入Comparator比较器。</li></ul><p>（2）TreeSet里面真的是使用TreeMap来存储元素的吗？</p><ul><li>我们知道TreeSet里面实际上是使用的NavigableMap来存储元素，虽然大部分时候这个map确实是TreeMap，但不是所有时候都是TreeMap。所以，TreeSet的底层不完全是使用TreeMap来实现的，更准确地说，应该是NavigableMap。</li></ul><h2 id="CopyOnWriteArraySet"><a href="#CopyOnWriteArraySet" class="headerlink" title="CopyOnWriteArraySet"></a>CopyOnWriteArraySet</h2><p>（1）CopyOnWriteArraySet是用Map实现的吗？</p><ul><li>CopyOnWriteArraySet底层是使用CopyOnWriteArrayList存储元素的，所以它并不是使用Map来存储元素的。</li></ul><p>（2）CopyOnWriteArraySet是有序的吗？</p><ul><li>是有序的</li></ul><p>（3）CopyOnWriteArraySet是并发安全的吗？</p><ul><li>因为底层是使用了CopyOnWriteArrayList，因此CopyOnWriteArraySet是并发安全的，而且是读写分离的。</li></ul><p>（4）CopyOnWriteArraySet以何种方式保证元素不重复？</p><ul><li>CopyOnWriteArrayList底层其实是一个数组，它是允许元素重复的。而CopyOnWriteArraySet通过调用其addIfAbsent来保证元素的不重复</li></ul><pre><code>    public class CopyOnWriteArraySet&lt;E&gt; extends AbstractSet&lt;E&gt;            implements java.io.Serializable &#123;        private static final long serialVersionUID = 5457747651344034263L;            // 内部使用CopyOnWriteArrayList存储元素        private final CopyOnWriteArrayList&lt;E&gt; al;            // 构造方法        public CopyOnWriteArraySet() &#123;            al = new CopyOnWriteArrayList&lt;E&gt;();        &#125;            // 将集合c中的元素初始化到CopyOnWriteArraySet中        public CopyOnWriteArraySet(Collection&lt;? extends E&gt; c) &#123;            if (c.getClass() == CopyOnWriteArraySet.class) &#123;                // 如果c是CopyOnWriteArraySet类型，说明没有重复元素，                // 直接调用CopyOnWriteArrayList的构造方法初始化                @SuppressWarnings(&quot;unchecked&quot;) CopyOnWriteArraySet&lt;E&gt; cc =                    (CopyOnWriteArraySet&lt;E&gt;)c;                al = new CopyOnWriteArrayList&lt;E&gt;(cc.al);            &#125;            else &#123;                // 如果c不是CopyOnWriteArraySet类型，说明有重复元素                // 调用CopyOnWriteArrayList的addAllAbsent()方法初始化                // 它会把重复元素排除掉                al = new CopyOnWriteArrayList&lt;E&gt;();                al.addAllAbsent(c);            &#125;        &#125;            // 获取元素个数        public int size() &#123;            return al.size();        &#125;            // 检查集合是否为空        public boolean isEmpty() &#123;            return al.isEmpty();        &#125;            // 检查是否包含某个元素        public boolean contains(Object o) &#123;            return al.contains(o);        &#125;            // 集合转数组        public Object[] toArray() &#123;            return al.toArray();        &#125;            // 集合转数组，这里是可能有bug的，详情见ArrayList中分析        public &lt;T&gt; T[] toArray(T[] a) &#123;            return al.toArray(a);        &#125;            // 清空所有元素        public void clear() &#123;            al.clear();        &#125;            // 删除元素        public boolean remove(Object o) &#123;            return al.remove(o);        &#125;            // 添加元素        // 这里是调用CopyOnWriteArrayList的addIfAbsent()方法        // 它会检测元素不存在的时候才添加        // 还记得这个方法吗？当时有分析过的，建议把CopyOnWriteArrayList拿出来再看看        public boolean add(E e) &#123;            return al.addIfAbsent(e);        &#125;            // 是否包含c中的所有元素        public boolean containsAll(Collection&lt;?&gt; c) &#123;            return al.containsAll(c);        &#125;            // 并集        public boolean addAll(Collection&lt;? extends E&gt; c) &#123;            return al.addAllAbsent(c) &gt; 0;        &#125;            // 单方向差集        public boolean removeAll(Collection&lt;?&gt; c) &#123;            return al.removeAll(c);        &#125;            // 交集        public boolean retainAll(Collection&lt;?&gt; c) &#123;            return al.retainAll(c);        &#125;            // 迭代器        public Iterator&lt;E&gt; iterator() &#123;            return al.iterator();        &#125;            // equals()方法        public boolean equals(Object o) &#123;            // 如果两者是同一个对象，返回true            if (o == this)                return true;            // 如果o不是Set对象，返回false            if (!(o instanceof Set))                return false;            Set&lt;?&gt; set = (Set&lt;?&gt;)(o);            Iterator&lt;?&gt; it = set.iterator();                // 集合元素数组的快照            Object[] elements = al.getArray();            int len = elements.length;                // 我觉得这里的设计不太好            // 首先，Set中的元素本来就是不重复的，所以不需要再用个matched[]数组记录有没有出现过            // 其次，两个集合的元素个数如果不相等，那肯定不相等了，这个是不是应该作为第一要素先检查            boolean[] matched = new boolean[len];            int k = 0;            // 从o这个集合开始遍历            outer: while (it.hasNext()) &#123;                // 如果k&gt;len了，说明o中元素多了                if (++k &gt; len)                    return false;                // 取值                Object x = it.next();                // 遍历检查是否在当前集合中                for (int i = 0; i &lt; len; ++i) &#123;                    if (!matched[i] &amp;&amp; eq(x, elements[i])) &#123;                        matched[i] = true;                        continue outer;                    &#125;                &#125;                // 如果不在当前集合中，返回false                return false;            &#125;            return k == len;        &#125;            // 移除满足过滤条件的元素        public boolean removeIf(Predicate&lt;? super E&gt; filter) &#123;            return al.removeIf(filter);        &#125;            // 遍历元素        public void forEach(Consumer&lt;? super E&gt; action) &#123;            al.forEach(action);        &#125;            // 分割的迭代器        public Spliterator&lt;E&gt; spliterator() &#123;            return Spliterators.spliterator                (al.getArray(), Spliterator.IMMUTABLE | Spliterator.DISTINCT);        &#125;            // 比较两个元素是否相等        private static boolean eq(Object o1, Object o2) &#123;            return (o1 == null) ? o2 == null : o1.equals(o2);        &#125;    &#125;    </code></pre><h2 id="ConcurrentSkipListSet"><a href="#ConcurrentSkipListSet" class="headerlink" title="ConcurrentSkipListSet"></a>ConcurrentSkipListSet</h2><p>（1）ConcurrentSkipListSet的底层是ConcurrentSkipListMap吗？</p><ul><li>ConcurrentSkipListSet底层是通过ConcurrentNavigableMap来实现的，</li></ul><p>（2）ConcurrentSkipListSet是线程安全的吗？</p><ul><li>它是一个有序的线程安全的集合。</li></ul><p>（3）ConcurrentSkipListSet是有序的吗？</p><ul><li>有序的</li></ul><p>（4）ConcurrentSkipListSet和之前讲的Set有何不同？</p><ul><li>ConcurrentSkipListSet基本上都是使用ConcurrentSkipListMap实现的，虽然取子set部分是使用ConcurrentSkipListMap中的内部类，但是这些内部类其实也是和ConcurrentSkipListMap相关的，它们返回ConcurrentSkipListMap的一部分数据。</li></ul><pre><code>   // 实现了NavigableSet接口，并没有所谓的ConcurrentNavigableSet接口    public class ConcurrentSkipListSet&lt;E&gt;        extends AbstractSet&lt;E&gt;        implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable &#123;            private static final long serialVersionUID = -2479143111061671589L;            // 存储使用的map        private final ConcurrentNavigableMap&lt;E,Object&gt; m;            // 初始化        public ConcurrentSkipListSet() &#123;            m = new ConcurrentSkipListMap&lt;E,Object&gt;();        &#125;            // 传入比较器        public ConcurrentSkipListSet(Comparator&lt;? super E&gt; comparator) &#123;            m = new ConcurrentSkipListMap&lt;E,Object&gt;(comparator);        &#125;            // 使用ConcurrentSkipListMap初始化map        // 并将集合c中所有元素放入到map中        public ConcurrentSkipListSet(Collection&lt;? extends E&gt; c) &#123;            m = new ConcurrentSkipListMap&lt;E,Object&gt;();            addAll(c);        &#125;            // 使用ConcurrentSkipListMap初始化map        // 并将有序Set中所有元素放入到map中        public ConcurrentSkipListSet(SortedSet&lt;E&gt; s) &#123;            m = new ConcurrentSkipListMap&lt;E,Object&gt;(s.comparator());            addAll(s);        &#125;            // ConcurrentSkipListSet类内部返回子set时使用的        ConcurrentSkipListSet(ConcurrentNavigableMap&lt;E,Object&gt; m) &#123;            this.m = m;        &#125;            // 克隆方法        public ConcurrentSkipListSet&lt;E&gt; clone() &#123;            try &#123;                @SuppressWarnings(&quot;unchecked&quot;)                ConcurrentSkipListSet&lt;E&gt; clone =                    (ConcurrentSkipListSet&lt;E&gt;) super.clone();                clone.setMap(new ConcurrentSkipListMap&lt;E,Object&gt;(m));                return clone;            &#125; catch (CloneNotSupportedException e) &#123;                throw new InternalError();            &#125;        &#125;            /* ---------------- Set operations -------------- */        // 返回元素个数        public int size() &#123;            return m.size();        &#125;            // 检查是否为空        public boolean isEmpty() &#123;            return m.isEmpty();        &#125;            // 检查是否包含某个元素        public boolean contains(Object o) &#123;            return m.containsKey(o);        &#125;            // 添加一个元素        // 调用map的putIfAbsent()方法        public boolean add(E e) &#123;            return m.putIfAbsent(e, Boolean.TRUE) == null;        &#125;            // 移除一个元素        public boolean remove(Object o) &#123;            return m.remove(o, Boolean.TRUE);        &#125;            // 清空所有元素        public void clear() &#123;            m.clear();        &#125;            // 迭代器        public Iterator&lt;E&gt; iterator() &#123;            return m.navigableKeySet().iterator();        &#125;            // 降序迭代器        public Iterator&lt;E&gt; descendingIterator() &#123;            return m.descendingKeySet().iterator();        &#125;                /* ---------------- AbstractSet Overrides -------------- */        // 比较相等方法        public boolean equals(Object o) &#123;            // Override AbstractSet version to avoid calling size()            if (o == this)                return true;            if (!(o instanceof Set))                return false;            Collection&lt;?&gt; c = (Collection&lt;?&gt;) o;            try &#123;                // 这里是通过两次两层for循环来比较                // 这里是有很大优化空间的，参考上篇文章CopyOnWriteArraySet中的彩蛋                return containsAll(c) &amp;&amp; c.containsAll(this);            &#125; catch (ClassCastException unused) &#123;                return false;            &#125; catch (NullPointerException unused) &#123;                return false;            &#125;        &#125;            // 移除集合c中所有元素        public boolean removeAll(Collection&lt;?&gt; c) &#123;            // Override AbstractSet version to avoid unnecessary call to size()            boolean modified = false;            for (Object e : c)                if (remove(e))                    modified = true;            return modified;        &#125;            /* ---------------- Relational operations -------------- */            // 小于e的最大元素        public E lower(E e) &#123;            return m.lowerKey(e);        &#125;            // 小于等于e的最大元素        public E floor(E e) &#123;            return m.floorKey(e);        &#125;            // 大于等于e的最小元素        public E ceiling(E e) &#123;            return m.ceilingKey(e);        &#125;            // 大于e的最小元素        public E higher(E e) &#123;            return m.higherKey(e);        &#125;            // 弹出最小的元素        public E pollFirst() &#123;            Map.Entry&lt;E,Object&gt; e = m.pollFirstEntry();            return (e == null) ? null : e.getKey();        &#125;            // 弹出最大的元素        public E pollLast() &#123;            Map.Entry&lt;E,Object&gt; e = m.pollLastEntry();            return (e == null) ? null : e.getKey();        &#125;                /* ---------------- SortedSet operations -------------- */            // 取比较器        public Comparator&lt;? super E&gt; comparator() &#123;            return m.comparator();        &#125;            // 最小的元素        public E first() &#123;            return m.firstKey();        &#125;            // 最大的元素        public E last() &#123;            return m.lastKey();        &#125;            // 取两个元素之间的子set        public NavigableSet&lt;E&gt; subSet(E fromElement,                                      boolean fromInclusive,                                      E toElement,                                      boolean toInclusive) &#123;            return new ConcurrentSkipListSet&lt;E&gt;                (m.subMap(fromElement, fromInclusive,                          toElement,   toInclusive));        &#125;            // 取头子set        public NavigableSet&lt;E&gt; headSet(E toElement, boolean inclusive) &#123;            return new ConcurrentSkipListSet&lt;E&gt;(m.headMap(toElement, inclusive));        &#125;            // 取尾子set        public NavigableSet&lt;E&gt; tailSet(E fromElement, boolean inclusive) &#123;            return new ConcurrentSkipListSet&lt;E&gt;(m.tailMap(fromElement, inclusive));        &#125;            // 取子set，包含from，不包含to        public NavigableSet&lt;E&gt; subSet(E fromElement, E toElement) &#123;            return subSet(fromElement, true, toElement, false);        &#125;            // 取头子set，不包含to        public NavigableSet&lt;E&gt; headSet(E toElement) &#123;            return headSet(toElement, false);        &#125;            // 取尾子set，包含from        public NavigableSet&lt;E&gt; tailSet(E fromElement) &#123;            return tailSet(fromElement, true);        &#125;            // 降序set        public NavigableSet&lt;E&gt; descendingSet() &#123;            return new ConcurrentSkipListSet&lt;E&gt;(m.descendingMap());        &#125;            // 可分割的迭代器        @SuppressWarnings(&quot;unchecked&quot;)        public Spliterator&lt;E&gt; spliterator() &#123;            if (m instanceof ConcurrentSkipListMap)                return ((ConcurrentSkipListMap&lt;E,?&gt;)m).keySpliterator();            else                return (Spliterator&lt;E&gt;)((ConcurrentSkipListMap.SubMap&lt;E,?&gt;)m).keyIterator();        &#125;            // 原子更新map，给clone方法使用        private void setMap(ConcurrentNavigableMap&lt;E,Object&gt; map) &#123;            UNSAFE.putObjectVolatile(this, mapOffset, map);        &#125;            // 原子操作相关内容        private static final sun.misc.Unsafe UNSAFE;        private static final long mapOffset;        static &#123;            try &#123;                UNSAFE = sun.misc.Unsafe.getUnsafe();                Class&lt;?&gt; k = ConcurrentSkipListSet.class;                mapOffset = UNSAFE.objectFieldOffset                    (k.getDeclaredField(&quot;m&quot;));            &#125; catch (Exception e) &#123;                throw new Error(e);            &#125;        &#125;    &#125;        </code></pre><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p> <img src="/images/pasted-174.png" alt="upload successful"></p><p>（1）除了HashSet其它Set都是有序的；</p><p>（2）实现了NavigableSet或者SortedSet接口的都是自然顺序的；</p><p>（3）使用并发安全的集合实现的Set也是并发安全的；</p><p>（4）TreeSet虽然不是全部都是使用的TreeMap实现的，但其实都是跟TreeMap相关的（TreeMap的子Map中组合了TreeMap）；</p><p>（5）ConcurrentSkipListSet虽然不是全部都是使用的ConcurrentSkipListMap实现的，但其实都是跟ConcurrentSkipListMap相关的（ConcurrentSkipListeMap的子Map中组合了ConcurrentSkipListMap）； </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;HashSet&quot;&gt;&lt;a href=&quot;#HashSet&quot; class=&quot;headerlink&quot; title=&quot;HashSet&quot;&gt;&lt;/a&gt;HashSet&lt;/h2&gt;&lt;p&gt;（1）HashSet内部使用HashMap的key存储元素，以此来保证元素不重复；&lt;/p&gt;
&lt;p&gt;（</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    <category term="集合" scheme="http://example.com/categories/Java/%E9%9B%86%E5%90%88/"/>
    
    
    <category term="集合" scheme="http://example.com/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>关于fail-safe</title>
    <link href="http://example.com/2022/04/01/%E5%85%B3%E4%BA%8Efail-safe/"/>
    <id>http://example.com/2022/04/01/%E5%85%B3%E4%BA%8Efail-safe/</id>
    <published>2022-04-01T14:00:00.000Z</published>
    <updated>2022-04-02T00:19:14.601Z</updated>
    
    <content type="html"><![CDATA[<p>Fail-Safe 迭代的出现，是为了解决fail-fast抛出异常处理不方便的情况。fail-safe是针对线程安全的集合类。</p><p>采⽤安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，⽽是先复制原有集合内容，在拷⻉的集合上进⾏遍历。所以，在遍历过程中对原集合所作的修改并不能被迭代器检测到，故不会抛ConcurrentModificationException 异常。</p><p>换句话说，并发容器的iterate方法返回的iterator对象，内部都是保存了该集合对象的一个快照副本，并且没有modCount等数值做检查。这也造成了并发容器的iterator读取的数据是某个时间点的快照版本。你可以并发读取，不会抛出异常，但是不保证你遍历读取的值和当前集合对象的状态是一致的！这就是安全失败的含义。</p><p>所以Fail-Safe 迭代的缺点是：首先是iterator不能保证返回集合更新后的数据，因为其工作在集合克隆上，而非集合本身。其次，创建集合拷贝需要相应的开销，包括时间和内存。</p><p>在java.util.concurrent 包中集合的迭代器，如 ConcurrentHashMap, CopyOnWriteArrayList等默认为都是Fail-Safe。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Fail-Safe 迭代的出现，是为了解决fail-fast抛出异常处理不方便的情况。fail-safe是针对线程安全的集合类。&lt;/p&gt;
&lt;p&gt;采⽤安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，⽽是先复制原有集合内容，在拷⻉的集合上进⾏遍历。所以，在遍历过程中</summary>
      
    
    
    
    <category term="集合" scheme="http://example.com/categories/%E9%9B%86%E5%90%88/"/>
    
    <category term="Java" scheme="http://example.com/categories/%E9%9B%86%E5%90%88/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="fail-safe" scheme="http://example.com/tags/fail-safe/"/>
    
  </entry>
  
  <entry>
    <title>Arrays.asList()避坑</title>
    <link href="http://example.com/2022/04/01/Arrays-asList-%E9%81%BF%E5%9D%91/"/>
    <id>http://example.com/2022/04/01/Arrays-asList-%E9%81%BF%E5%9D%91/</id>
    <published>2022-04-01T13:53:00.000Z</published>
    <updated>2022-04-01T13:59:09.226Z</updated>
    
    <content type="html"><![CDATA[<p>Arrays.asList() 我们可以使⽤它将⼀个数组转换为⼀个List集合。</p><p>jdk对这个方法的说明：返回由指定数组⽀持的固定⼤⼩的列表。此⽅法作为基于数组和基于集合的API之间的桥梁，与 Collection.toArray()结合使⽤。返回的List是可序列化并实现RandomAccess接⼝。</p><p>《阿⾥巴巴 Java 开发⼿册》对其的描述：Arrays.asList() 将数组转换为集合后,底层其实还是数组。强制使用add/remove/clear等方法会抛出异常。asList返回的对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList（）体现的是适配器模式，只是接口转换，后台的数据仍是数组。</p><p>传递的数组必须是对象数组，⽽不是基本类型。Arrays.asList() 是泛型⽅法，传⼊的对象必须是对象数组。</p><p> <img src="/images/pasted-173.png" alt="upload successful"></p><p>当传⼊⼀个原⽣数据类型数组时， Arrays.asList() 的真正得到的参数就不是数组中的元素，⽽是<br>数组对象本身！此时 List 的唯⼀元素就是这个数组，这也就解释了上⾯的代码。我们使用包装类可以解决该问题，但调用add/remove/clear等方法仍是会报错。</p><p>Arrays.asList() ⽅法返回的并不是 java.util.ArrayList ，⽽是 java.util.Arrays 的⼀个内部类,这个内部类并没有实现集合的修改⽅法或者说并没有重写这些⽅法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Arrays.asList() 我们可以使⽤它将⼀个数组转换为⼀个List集合。&lt;/p&gt;
&lt;p&gt;jdk对这个方法的说明：返回由指定数组⽀持的固定⼤⼩的列表。此⽅法作为基于数组和基于集合的API之间的桥梁，与 Collection.toArray()结合使⽤。返回的List是</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    <category term="集合" scheme="http://example.com/categories/Java/%E9%9B%86%E5%90%88/"/>
    
    
    <category term="集合" scheme="http://example.com/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>内存模型之伪共享(False Sharing)</title>
    <link href="http://example.com/2022/03/23/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BC%AA%E5%85%B1%E4%BA%AB-False-Sharing/"/>
    <id>http://example.com/2022/03/23/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B9%8B%E4%BC%AA%E5%85%B1%E4%BA%AB-False-Sharing/</id>
    <published>2022-03-23T13:09:00.000Z</published>
    <updated>2022-03-23T13:15:05.799Z</updated>
    
    <content type="html"><![CDATA[<p>在对称多处理器(SMP)系统中，每个处理器均有一个本地高速缓存。内存系统必须保证高速缓存的一致性。当不同处理器上的线程修改驻留在同一高速缓存行中的变量时就会发生假共享，结果导致高速缓存行无效，并强制执行更新，进而影响系统性能。</p><p> <img src="/images/pasted-172.png" alt="upload successful"><br>线程0和线程1会用到不同变量，它们在内存中彼此相邻，并驻留在同一高速缓存行。高速缓存行被加载到CPU0和CPU1的高速缓存中（灰色箭头）。<br>尽管这些线程修改的是不同变量（红色和蓝色箭头），高速缓存行仍会无效，并强制内存更新以维持高速缓存的一致性。</p><p>缓存系统中是以缓存行（cacheline）为单位存储的。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。一个Java的long类型是8字节，因此在一个缓存行中可以存8个long类型的变量。所以，如果你访问一个long数组，当数组中的一个值被加载到缓存中，它会额外加载另外7个，这会带来一些优势。但是也有伪共享问题，比如两个线程，修改long数组的第一个与第七个，会频发发生缓存失效，影响性能。解决办法就是填充，在JDK8中提供了@sun.misc.Contended注解来避免伪共享，即通过padding填充，让数据占据不同的缓存行。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在对称多处理器(SMP)系统中，每个处理器均有一个本地高速缓存。内存系统必须保证高速缓存的一致性。当不同处理器上的线程修改驻留在同一高速缓存行中的变量时就会发生假共享，结果导致高速缓存行无效，并强制执行更新，进而影响系统性能。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/imag</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    <category term="JMM" scheme="http://example.com/categories/Java/JMM/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="JMM" scheme="http://example.com/tags/JMM/"/>
    
  </entry>
  
  <entry>
    <title>MySQL其他一下查询优化策略</title>
    <link href="http://example.com/2022/03/23/MySQL%E5%85%B6%E4%BB%96%E4%B8%80%E4%B8%8B%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/"/>
    <id>http://example.com/2022/03/23/MySQL%E5%85%B6%E4%BB%96%E4%B8%80%E4%B8%8B%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/</id>
    <published>2022-03-23T04:01:00.000Z</published>
    <updated>2022-03-23T04:09:30.098Z</updated>
    
    <content type="html"><![CDATA[<p>1、 in 和 exists的区别: 如果子查询得出的结果集记录较少，主查询中的表较大且又有索引时应该用in, 反之如果外层的主查询记录较少，子查询中的表大，又有索引时使用exists。其实我们区分in和exists主要是造成了驱动顺序的改变(这是性能变化的关键)，如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询，所以我们会以驱动表的快速返回为目标，那么就会考虑到索引及结果集的关系了 ，另外IN时不对NULL进行处理。</p><ul><li><p>in 是把外表和内表作hash 连接，而exists是对外表作loop循环，每次loop循环再对内表进行查询。一直以来认为exists比in效率高的说法是不准确的。</p></li><li><p>not in 和not exists：如果查询语句使用了not in 那么内外表都进行全表扫描，没有用到索引；而not extsts 的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</p></li></ul><p>2、COUNT(*)与COUNT(具体字段)效率</p><ul><li>在表查询中，建议明确字段，不要使用 * 作为查询的字段列表，推荐使用SELECT &lt;字段列表&gt; 查询。原因：① MySQL 在解析的过程中，会通过 查询数据字典 将”*”按序转换成所有列名，这会大大的耗费资源和时间。② 无法使用 覆盖索引</li></ul><p>3、 LIMIT 1 对优化的影响</p><ul><li>针对的是会扫描全表的 SQL 语句，如果你可以确定结果集只有一条，那么加上 LIMIT 1 的时候，当找到一条结果的时候就不会继续扫描了，这样会加快查询速度。如果数据表已经对字段建立了唯一索引，那么可以通过索引进行查询，不会全表扫描的话，就不需要加上 LIMIT 1 了。</li></ul><p>4、多使用COMMIT</p><ul><li>只要有可能，在程序中尽量多使用 COMMIT，这样程序的性能得到提高，需求也会因为 COMMIT 所释放的资源而减少。COMMIT 所释放的资源：1、回滚段上用于恢复数据的信息2、被程序语句获得的锁 3、redo / undo log buffer 中的空间 4、管理上述 3 种资源中的内部花费</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1、 in 和 exists的区别: 如果子查询得出的结果集记录较少，主查询中的表较大且又有索引时应该用in, 反之如果外层的主查询记录较少，子查询中的表大，又有索引时使用exists。其实我们区分in和exists主要是造成了驱动顺序的改变(这是性能变化的关键)，如果是e</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="其它" scheme="http://example.com/tags/%E5%85%B6%E5%AE%83/"/>
    
    <category term="SQL优化" scheme="http://example.com/tags/SQL%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>change buffer的使用场景</title>
    <link href="http://example.com/2022/03/23/change-buffer%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <id>http://example.com/2022/03/23/change-buffer%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</id>
    <published>2022-03-23T03:58:00.000Z</published>
    <updated>2022-03-23T03:59:55.566Z</updated>
    
    <content type="html"><![CDATA[<ol><li>普通索引和唯一索引应该怎么选择？其实，这两类索引在查询能力上是没差别的，主要考虑的是对 更新性能 的影响。所以，建议你 尽量选择普通索引 。 2. 在实际使用中会发现， 普通索引 和 change buffer 的配合使用，对于 数据量大 的表的更新优化还是很明显的。</li><li>如果所有的更新后面，都马上 伴随着对这个记录的查询 ，那么你应该 关闭change buffer 。而在其他情况下，change buffer都能提升更新性能。</li><li>由于唯一索引用不changebuffer的优化机制，因此如果 业务可以接受 ，从性能角度出发建议优先考虑非唯一索引。但是如果”业务可能无法确保”的情况下，怎么处理呢？</li></ol><p>首先， 业务正确性优先 。我们的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。这种情况下，本节的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，给你多提供一个排查思路。</p><p>然后，在一些“ 归档库 ”的场景，你是可以考虑使用唯一索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;普通索引和唯一索引应该怎么选择？其实，这两类索引在查询能力上是没差别的，主要考虑的是对 更新性能 的影响。所以，建议你 尽量选择普通索引 。 2. 在实际使用中会发现， 普通索引 和 change buffer 的配合使用，对于 数据量大 的表的更新优化还是很明</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="change buffer" scheme="http://example.com/tags/change-buffer/"/>
    
  </entry>
  
  <entry>
    <title>索引下推</title>
    <link href="http://example.com/2022/03/23/%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/"/>
    <id>http://example.com/2022/03/23/%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/</id>
    <published>2022-03-23T03:50:00.000Z</published>
    <updated>2022-03-23T03:55:43.730Z</updated>
    
    <content type="html"><![CDATA[<p>Index Condition Pushdown(ICP)是MySQL 5.6中新特性，是一种在存储引擎层使用索引过滤数据的一种优化方式。ICP可以减少存储引擎访问基表的次数以及MySQL服务器访问存储引擎的次数。</p><p>在不使用ICP索引扫描的过程：</p><ul><li>storage层：只将满足index key条件的索引记录对应的整行记录取出，返回给server层 </li><li>server 层：对返回的数据，使用后面的where条件过滤，直至返回最后一行。</li></ul><p> <img src="/images/pasted-171.png" alt="upload successful"></p><p> 使用ICP扫描的过程：</p><ul><li>storage层：首先将index key条件满足的索引记录区间确定，然后在索引上使用index filter进行过滤。将满足的index filter条件的索引记录才去回表取出整行记录返回server层。不满足index filter条件的索引记录丢弃，不回表、也不会返回server层。</li><li>server 层：对返回的数据，使用table filter条件做最后的过滤。</li></ul><p>使用前后的成本差别：使用前，存储层多返回了需要被index filter过滤掉的整行记录使用ICP后，直接就去掉了不满足index filter条件的记录，省去了他们回表和传递到server层的成本。ICP的 加速效果 取决于在存储引擎内通过 ICP筛选 掉的数据的比例。</p><p>ICP的使用条件：</p><p>① 只能用于二级索引(secondary index) </p><p>②explain显示的执行计划中type值（join 类型）为 range 、 ref 、 eq_ref 或者 ref_or_null 。 </p><p>③ 并非全部where条件都可以用ICP筛选，如果where条件的字段不在索引列中，还是要读取整表的记录<br>到server端做where过滤。</p><p>④ ICP可以用于MyISAM和InnnoDB存储引擎</p><p>⑤ MySQL 5.6版本的不支持分区表的ICP功能，5.7版本的开始支持。</p><p>⑥ 当SQL使用覆盖索引时，不支持ICP优化方法。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Index Condition Pushdown(ICP)是MySQL 5.6中新特性，是一种在存储引擎层使用索引过滤数据的一种优化方式。ICP可以减少存储引擎访问基表的次数以及MySQL服务器访问存储引擎的次数。&lt;/p&gt;
&lt;p&gt;在不使用ICP索引扫描的过程：&lt;/p&gt;
&lt;u</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="索引下推" scheme="http://example.com/tags/%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8/"/>
    
  </entry>
  
  <entry>
    <title>优化分页查询</title>
    <link href="http://example.com/2022/03/23/%E4%BC%98%E5%8C%96%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/"/>
    <id>http://example.com/2022/03/23/%E4%BC%98%E5%8C%96%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/</id>
    <published>2022-03-23T02:56:00.000Z</published>
    <updated>2022-03-23T02:58:13.556Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>在索引上完成排序分页操作，最后根据主键关联回原表查询所需要的其他列内容。</p></li><li><p>该方案适用于主键自增的表，可以把Limit 查询转换成某个位置的查询 。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在索引上完成排序分页操作，最后根据主键关联回原表查询所需要的其他列内容。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;该方案适用于主键自增的表，可以把Limit 查询转换成某个位置的查询 。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="分页查询" scheme="http://example.com/tags/%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/"/>
    
  </entry>
  
  <entry>
    <title>GROUP BY优化</title>
    <link href="http://example.com/2022/03/23/GROUP-BY%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/03/23/GROUP-BY%E4%BC%98%E5%8C%96/</id>
    <published>2022-03-23T02:55:00.000Z</published>
    <updated>2022-03-23T02:56:43.112Z</updated>
    
    <content type="html"><![CDATA[<ul><li>group by 使用索引的原则几乎跟order by一致 ，group by 即使没有过滤条件用到索引，也可以直接使用索引。</li><li>group by 先排序再分组，遵照索引建的最佳左前缀法则</li><li>当无法使用索引列，增大 max_length_for_sort_data 和 sort_buffer_size 参数的设置</li><li>where效率高于having，能写在where限定的条件就不要写在having中了</li><li>减少使用order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。Order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是极其宝贵的。</li><li>包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;group by 使用索引的原则几乎跟order by一致 ，group by 即使没有过滤条件用到索引，也可以直接使用索引。&lt;/li&gt;
&lt;li&gt;group by 先排序再分组，遵照索引建的最佳左前缀法则&lt;/li&gt;
&lt;li&gt;当无法使用索引列，增大 max_len</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="GROUP BY优化" scheme="http://example.com/tags/GROUP-BY%E4%BC%98%E5%8C%96/"/>
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>排序优化</title>
    <link href="http://example.com/2022/03/23/%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/03/23/%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/</id>
    <published>2022-03-23T02:47:00.000Z</published>
    <updated>2022-03-23T02:54:53.268Z</updated>
    
    <content type="html"><![CDATA[<p>在 WHERE 条件字段上加索引，但是为什么在 ORDER BY 字段上还要加索引呢？</p><p>优化建议：</p><ol><li>SQL 中，可以在 WHERE 子句和 ORDER BY 子句中使用索引，目的是在 WHERE 子句中 避免全表扫 描 ，在 ORDER BY 子句 避免使用 FileSort 排序 。当然，某些情况下全表扫描，或者 FileSort 排序不一定比索引慢。但总的来说，我们还是要避免，以提高查询效率。</li><li>尽量使用 Index 完成 ORDER BY 排序。如果 WHERE 和 ORDER BY 后面是相同的列就使用单索引列；如果不同就使用联合索引。</li><li>无法使用 Index 时，需要对 FileSort 方式进行调优。</li></ol><p> <img src="/images/pasted-169.png" alt="upload successful"></p><p> <img src="/images/pasted-170.png" alt="upload successful"></p><ol><li>两个索引同时存在，mysql自动选择最优的方案。（对于这个例子，mysql选idx_age_stuno_name）。但是， 随着数据量的变化，选择的索引也会随之变化的 。 </li><li>当【范围条件】和【group by 或者 order by】的字段出现二选一时，优先观察条件字段的过滤数量，如果过滤的数据足够多，而需要排序的数据并不多时，优先把索引放在范围字段上。反之，亦然。</li></ol><p>filesort：双路排序和单路排序</p><p>双路排序 （慢）<br>MySQL 4.1之前是使用双路排序 ，字面意思就是两次扫描磁盘，最终得到数据， 读取行指针和<br>order by列 ，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取<br>对应的数据输出<br>从磁盘取排序字段，在buffer进行排序，再从 磁盘取其他字段 。<br>取一批数据，要对磁盘进行两次扫描，众所周知，IO是很耗时的，所以在mysql4.1之后，出现了第二种<br>改进的算法，就是单路排序。</p><p>单路排序 （快）<br>从磁盘读取查询需要的 所有列 ，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输<br>出， 它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空<br>间， 因为它把每一行都保存在内存中了。</p><p>优化策略</p><ol><li>尝试提高 sort_buffer_size 2. 尝试提高 max_length_for_sort_data </li><li>Order by 时select * 是一个大忌。最好只Query需要的字段。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 WHERE 条件字段上加索引，但是为什么在 ORDER BY 字段上还要加索引呢？&lt;/p&gt;
&lt;p&gt;优化建议：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SQL 中，可以在 WHERE 子句和 ORDER BY 子句中使用索引，目的是在 WHERE 子句中 避免全表扫 描 ，在 ORDE</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="排序优化" scheme="http://example.com/tags/%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>子查询优化</title>
    <link href="http://example.com/2022/03/23/%E5%AD%90%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/03/23/%E5%AD%90%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</id>
    <published>2022-03-23T02:43:00.000Z</published>
    <updated>2022-03-23T02:47:07.393Z</updated>
    
    <content type="html"><![CDATA[<p>使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。 子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。</p><pre><code>但值得注意的是：子查询虽然可以帮助我们通过一个 SQL 语句实现比较复杂的查询。但是，子查询的执行效率不高。原因：① 执行子查询时，MySQL需要为内层查询语句的查询结果 建立一个临时表 ，然后外层查询语句从临时表中查询记录。查询完毕后，再撤销这些临时表 。这样会消耗过多的CPU和IO资源，产生大量的慢查询。② 子查询的结果集存储的临时表，不论是内存临时表还是磁盘临时表都 不会存在索引 ，所以查询性能会受到一定的影响。③ 对于返回结果集比较大的子查询，其对查询性能的影响也就越大。</code></pre><p>在MySQL中，可以使用连接（JOIN）查询来替代子查询。连接查询 不需要建立临时表 ，其速度比子查询要快 ，如果查询中使用索引的话，性能会更好。</p><p>因此：尽量不要使用NOT IN 或者 NOT EXISTS，用LEFT JOIN xxx ON xx WHERE xx IS NULL替代</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。 子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;但值得注意的是：子查询虽然可以帮助我们通过一个 SQL 语句实现比较</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="子查询优化" scheme="http://example.com/tags/%E5%AD%90%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>关联查询优化</title>
    <link href="http://example.com/2022/03/23/%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/"/>
    <id>http://example.com/2022/03/23/%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/</id>
    <published>2022-03-23T02:24:00.000Z</published>
    <updated>2022-03-23T02:41:22.043Z</updated>
    
    <content type="html"><![CDATA[<p>采用左外连接</p><ul><li>被驱动的表简历索引，可以避免全表扫描（LEFT JOIN条件用于确定如何从右表搜索行，左边一定都有，所以 右边是我们的关键点,一定需要建立索引 。）</li></ul><p>采用内连接</p><ul><li>MySQL自动选择驱动表（小结果集），保证被驱动的表的JOIN字段已经建立了索引。</li></ul><p>小结：</p><ul><li>保证被驱动表的JOIN字段已经创建了索引</li><li>需要JOIN 的字段，数据类型保持绝对一致。</li><li>LEFT JOIN 时，选择小表作为驱动表， 大表作为被驱动表 。减少外层循环的次数。</li><li>INNER JOIN 时，MySQL会自动将 小结果集的表选为驱动表 。选择相信MySQL优化策略。</li><li>能够直接多表关联的尽量直接关联，不用子查询。(减少查询的趟数)</li><li>不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用 JOIN 来代替子查询。</li><li>衍生表建不了索引</li></ul><p>补充：</p><ul><li>什么叫作“小表”？在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。</li></ul><p> <img src="/images/pasted-168.png" alt="upload successful"></p><p>在这个流程里：</p><ol><li>对驱动表t1做了全表扫描，这个过程需要扫描100行；</li><li>而对于每一行R，根据a字段去表t2查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描100行；</li><li>所以，整个执行流程，总扫描行数是200。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;采用左外连接&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;被驱动的表简历索引，可以避免全表扫描（LEFT JOIN条件用于确定如何从右表搜索行，左边一定都有，所以 右边是我们的关键点,一定需要建立索引 。）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;采用内连接&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL自动选择</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="关联查询" scheme="http://example.com/tags/%E5%85%B3%E8%81%94%E6%9F%A5%E8%AF%A2/"/>
    
  </entry>
  
  <entry>
    <title>索引失效案例</title>
    <link href="http://example.com/2022/03/23/%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E6%A1%88%E4%BE%8B/"/>
    <id>http://example.com/2022/03/23/%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E6%A1%88%E4%BE%8B/</id>
    <published>2022-03-23T02:15:00.000Z</published>
    <updated>2022-03-23T02:22:42.930Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>没有遵守最左前缀法则（联合索引中，左边的值未确认，无法使用此索引）</p></li><li><p>SQL语句中使用计算、函数、类型转换等</p></li><li><p>SQL语句中索引条件在范围查询右边</p></li><li><p>使用！=或者&lt;&gt;也会令索引失效</p></li><li><p>is null 可以使用索引，而is not null无法使用索引</p></li><li><p>like以%开头，索引会失效（页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。）</p></li><li><p> OR 前后存在非索引的列，索引失效</p></li><li><p>数据库和表的字符集统一使用utf8mb4（统一使用utf8mb4( 5.5.3版本以上支持)兼容性更好，统一字符集可以避免由于字符集转换产生的乱码。不同的 字符集 进行比较前需要进行 转换 会造成索引失效。）</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;没有遵守最左前缀法则（联合索引中，左边的值未确认，无法使用此索引）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;SQL语句中使用计算、函数、类型转换等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;SQL语句中索引条件在范围查询右边&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用！=或</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="索引失效" scheme="http://example.com/tags/%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88/"/>
    
  </entry>
  
  <entry>
    <title>哪些情况下不适合建立索引？</title>
    <link href="http://example.com/2022/03/23/%E5%93%AA%E4%BA%9B%E6%83%85%E5%86%B5%E4%B8%8B%E4%B8%8D%E9%80%82%E5%90%88%E5%BB%BA%E7%AB%8B%E7%B4%A2%E5%BC%95%EF%BC%9F/"/>
    <id>http://example.com/2022/03/23/%E5%93%AA%E4%BA%9B%E6%83%85%E5%86%B5%E4%B8%8B%E4%B8%8D%E9%80%82%E5%90%88%E5%BB%BA%E7%AB%8B%E7%B4%A2%E5%BC%95%EF%BC%9F/</id>
    <published>2022-03-23T01:29:00.000Z</published>
    <updated>2022-03-23T01:30:24.048Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>在where中使用不到的字段，不要设置索引</p></li><li><p> 数据量小的表最好不要使用索引</p></li><li><p>有大量重复数据的列上不要建立索引</p></li><li><p>避免对经常更新的表创建过多的索引</p></li><li><p>不建议用无序的值作为索引</p></li><li><p> 删除不再使用或者很少使用的索引</p></li><li><p> 不要定义冗余或重复的索引</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在where中使用不到的字段，不要设置索引&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt; 数据量小的表最好不要使用索引&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;有大量重复数据的列上不要建立索引&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;避免对经常更新的表创建过多的索引&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="索引" scheme="http://example.com/tags/%E7%B4%A2%E5%BC%95/"/>
    
    <category term="设计原则" scheme="http://example.com/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"/>
    
  </entry>
  
  <entry>
    <title>哪些情况下适合建立索引？</title>
    <link href="http://example.com/2022/03/23/%E5%93%AA%E4%BA%9B%E6%83%85%E5%86%B5%E4%B8%8B%E9%80%82%E5%90%88%E5%BB%BA%E7%AB%8B%E7%B4%A2%E5%BC%95%EF%BC%9F/"/>
    <id>http://example.com/2022/03/23/%E5%93%AA%E4%BA%9B%E6%83%85%E5%86%B5%E4%B8%8B%E9%80%82%E5%90%88%E5%BB%BA%E7%AB%8B%E7%B4%A2%E5%BC%95%EF%BC%9F/</id>
    <published>2022-03-23T01:18:00.000Z</published>
    <updated>2022-03-23T01:28:05.806Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>字段的数值有唯一性约束<br>（业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。（来源：Alibaba））</p></li><li><p>频繁作为where查询条件的字段<br>（某个字段在SELECT语句的 WHERE 条件中经常被使用到，那么就需要给这个字段创建索引了。尤其是在<br>数据量大的情况下，创建普通索引就可以大幅提升数据查询的效率。）</p></li><li><p>经常 GROUP BY 和 ORDER BY 的列<br>（索引就是让数据按照某种顺序进行存储或检索，因此当我们使用 GROUP BY 对数据进行分组查询，或者<br>使用 ORDER BY 对数据进行排序的时候，就需要 对分组或者排序的字段进行索引 。如果待排序的列有多<br>个，那么可以在这些列上建立 组合索引 。）</p></li><li><p> UPDATE、DELETE 的 WHERE 条件列<br>（对数据按照某个条件进行查询后再进行 UPDATE 或 DELETE 的操作，如果对 WHERE 字段创建了索引，就<br>能大幅提升效率。原理是因为我们需要先根据 WHERE 条件列检索出来这条记录，然后再对它进行更新或<br>删除。如果进行更新的时候，更新的字段是非索引字段，提升的效率会更明显，这是因为非索引字段更<br>新不需要对索引进行维护。）</p></li><li><p>DISTINCT 字段需要创建索引<br>（有时候我们需要对某个字段进行去重，使用 DISTINCT，那么对这个字段创建索引，也会提升查询效率。）</p></li><li><p>多表 JOIN 连接操作时，创建索引注意事项<br>（首先， 连接表的数量尽量不要超过 3 张 ，因为每增加一张表就相当于增加了一次嵌套的循环，数量级增<br>长会非常快，严重影响查询的效率。<br>其次， 对 WHERE 条件创建索引 ，因为 WHERE 才是对数据条件的过滤。如果在数据量非常大的情况下，<br>没有 WHERE 条件过滤是非常可怕的。<br>最后， 对用于连接的字段创建索引 ，并且该字段在多张表中的 类型必须一致 。比如 course_id 在 student_info 表和 course 表中都为 int(11) 类型，而不能一个为 int 另一个为 varchar 类型。）</p></li><li><p> 使用列的类型小的创建索引</p></li><li><p>使用字符串前缀创建索引<br>（例如创建一张商户表，因为地址字段比较长，可以在地址字段上建立前缀索引）</p><p>  注意：</p><p>  【 强制 】在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度。</p><p>  说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会 高达 90% 以上 ，可以使用 count(distinct left(列名, 索引长度))/count(*)的区分度来确定。</p></li><li><p> 区分度高(散列性高)的列适合作为索引</p></li><li><p> 使用最频繁的列放到联合索引的左侧</p></li><li><p>在多个字段都要创建索引的情况下，联合索引优于单值索引</p></li><li><p>限制索引的数目</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;ul&gt;
&lt;li&gt;&lt;p&gt;字段的数值有唯一性约束&lt;br&gt;（业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。（来源：Alibaba））&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;频繁作为where查询条件的字段&lt;br&gt;（某个字段在SELECT语句的 WHERE 条件中经常被使用</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="索引" scheme="http://example.com/tags/%E7%B4%A2%E5%BC%95/"/>
    
    <category term="原则" scheme="http://example.com/tags/%E5%8E%9F%E5%88%99/"/>
    
  </entry>
  
  <entry>
    <title>MySQL8.0索引新特性</title>
    <link href="http://example.com/2022/03/23/MySQL8-0%E7%B4%A2%E5%BC%95%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    <id>http://example.com/2022/03/23/MySQL8-0%E7%B4%A2%E5%BC%95%E6%96%B0%E7%89%B9%E6%80%A7/</id>
    <published>2022-03-23T01:12:00.000Z</published>
    <updated>2022-03-23T01:18:15.471Z</updated>
    
    <content type="html"><![CDATA[<h1 id="支持降序索引"><a href="#支持降序索引" class="headerlink" title="支持降序索引"></a>支持降序索引</h1><p>分别在MySQL 5.7版本和MySQL 8.0版本中创建数据表ts1，结果如下：</p><pre><code>CREATE TABLE ts1(a int,b int,index idx_a_b(a,b desc));</code></pre><ul><li>5.7</li></ul><p> <img src="/images/pasted-166.png" alt="upload successful"></p><ul><li>8.0</li></ul><p> <img src="/images/pasted-167.png" alt="upload successful"></p><p>降序索引在特性降序查询效率比升序自然要好，具体根据情况而进行设定。</p><h1 id="隐藏索引"><a href="#隐藏索引" class="headerlink" title="隐藏索引"></a>隐藏索引</h1><ul><li><p>在MySQL 5.7版本及之前，只能通过显式的方式删除索引。此时，如果发现删除索引后出现错误，又只能通过显式创建索引的方式将删除的索引创建回来。如果数据表中的数据量非常大，或者数据表本身比较大，这种操作就会消耗系统过多的资源，操作成本非常高。</p></li><li><p>从MySQL 8.x开始支持 隐藏索引（invisible indexes） ，只需要将待删除的索引设置为隐藏索引，使查询优化器不再使用这个索引（即使使用force index（强制使用索引），优化器也不会使用该索引），确认将索引设置为隐藏索引后系统不受任何响应，就可以彻底删除索引。 这种通过先将索引设置为隐藏索引，再删除索引的方式就是软删除 。</p></li></ul><p>注意：注意 当索引被隐藏时，它的内容仍然是和正常索引一样实时更新的。如果一个索引需要长期被隐藏，那么可以将其删除，因为索引的存在会影响插入、更新和删除的性能。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;支持降序索引&quot;&gt;&lt;a href=&quot;#支持降序索引&quot; class=&quot;headerlink&quot; title=&quot;支持降序索引&quot;&gt;&lt;/a&gt;支持降序索引&lt;/h1&gt;&lt;p&gt;分别在MySQL 5.7版本和MySQL 8.0版本中创建数据表ts1，结果如下：&lt;/p&gt;
&lt;pre&gt;&lt;co</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="新特性" scheme="http://example.com/tags/%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    
    <category term="MySQL8.0" scheme="http://example.com/tags/MySQL8-0/"/>
    
  </entry>
  
  <entry>
    <title>MySQL中大多数情况查询缓存就是个鸡肋，为什么呢？</title>
    <link href="http://example.com/2022/03/22/MySQL%E4%B8%AD%E5%A4%A7%E5%A4%9A%E6%95%B0%E6%83%85%E5%86%B5%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98%E5%B0%B1%E6%98%AF%E4%B8%AA%E9%B8%A1%E8%82%8B%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E5%91%A2%EF%BC%9F/"/>
    <id>http://example.com/2022/03/22/MySQL%E4%B8%AD%E5%A4%A7%E5%A4%9A%E6%95%B0%E6%83%85%E5%86%B5%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98%E5%B0%B1%E6%98%AF%E4%B8%AA%E9%B8%A1%E8%82%8B%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E5%91%A2%EF%BC%9F/</id>
    <published>2022-03-22T12:34:00.000Z</published>
    <updated>2022-03-22T12:37:08.225Z</updated>
    
    <content type="html"><![CDATA[<p>查询缓存是提前把查询结果缓存起来，这样下次不需要执行就可以直接拿到结果。需要说明的是，在MySQL 中的查询缓存，不是缓存查询计划，而是查询对应的结果。这就意味着查询匹配的鲁棒性大大降低 ，只有相同的查询操作才会命中查询缓存。两个查询请求在任何字符上的不同（例如：空格、注释、大小写），都会导致缓存不会命中。因此 MySQL的查询缓存命中率不高 。同时，如果查询请求中包含某些系统函数、用户自定义变量和函数、一些系统表，如 mysql 、 information_schema、 performance_schema 数据库中的表，那这个请求就不会被缓存。以某些系统函数举例，可能同样的函数的两次调用会产生不一样的结果，比如函数NOW ，每次调用都会产生最新的当前时间，如果在一个查询请求中调用了这个函数，那即使查询请求的文本信息都一样，那不同时间的两次查询也应该得到不同的结果，如果在第一次查询时就缓存了，那第二次查询的时候直接使用第一次查询的结果就是错误的！</p><p>此外，既然是缓存，那就有它缓存失效的时候 。MySQL的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，如对该表使用了INSERT 、 UPDATE 、 DELETE 、 TRUNCATE TABLE 、 ALTER TABLE 、 DROP TABLE 或 DROP DATABASE 语句，那使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除！对于更新压力大的数据库 来说，查询缓存的命中率会非常低。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;查询缓存是提前把查询结果缓存起来，这样下次不需要执行就可以直接拿到结果。需要说明的是，在MySQL 中的查询缓存，不是缓存查询计划，而是查询对应的结果。这就意味着查询匹配的鲁棒性大大降低 ，只有相同的查询操作才会命中查询缓存。两个查询请求在任何字符上的不同（例如：空格、注释</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="缓存" scheme="http://example.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>MySQL两阶段提交</title>
    <link href="http://example.com/2022/03/21/MySQL%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/"/>
    <id>http://example.com/2022/03/21/MySQL%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/</id>
    <published>2022-03-21T08:12:00.000Z</published>
    <updated>2022-03-21T08:19:53.324Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL中经常说的WAL技术，WAL的全称是Write Ahead Logging，它的关键点就是先写日志，再写磁盘。即当有一条记录需要更新时，InnoDB引擎就会先把记录写到redo log里，并更新内存，这个时候更新就完成了。因为如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。</p><p>在执行一条update语句时候，通过连接器、分析器、优化器之后，调用操作引擎，将新行写入内存，写入redo log，状态为prepare-&gt;写binlog-&gt;redo log状态修改为commit。写入redo的过程分为了prepare和commit称为二阶段提交。</p><ul><li><p>采用二阶段提交的原因：</p></li><li><p>先写redolog再写binlog：如果在一条语句redolog之后崩溃了，binlog则没有记录这条语句。系统在crash recovery时重新执行了一遍binlog便会少了这一次的修改。恢复的数据库少了这条更新。</p></li><li><p>先写binlog再写redolog：如果在一条语句binlog之后崩溃了，redolog则没有记录这条语句（数据库物理层面并没有执行这条语句）。系统在crash recovery时重新执行了一遍binlog便会多了这一次的修改。恢复的数据库便多了这条更新。</p></li></ul><h2 id="Crash-recovery"><a href="#Crash-recovery" class="headerlink" title="Crash recovery"></a>Crash recovery</h2><p>在做Crash recovery时，分为以下3种情况：</p><ul><li><p>binlog有记录，redolog状态commit：正常完成的事务，不需要恢复；</p></li><li><p>binlog有记录，redolog状态prepare：在binlog写完提交事务之前的crash，恢复操作：提交事务。（因为之前没有提交）</p></li><li><p>binlog无记录，redolog状态prepare：在binlog写完之前的crash，恢复操作：回滚事务（因为crash时并没有成功写入数据库）</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;MySQL中经常说的WAL技术，WAL的全称是Write Ahead Logging，它的关键点就是先写日志，再写磁盘。即当有一条记录需要更新时，InnoDB引擎就会先把记录写到redo log里，并更新内存，这个时候更新就完成了。因为如果每一次的更新操作都需要写进磁盘，然</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="两阶段提交" scheme="http://example.com/tags/%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4/"/>
    
    <category term="Binlog" scheme="http://example.com/tags/Binlog/"/>
    
  </entry>
  
  <entry>
    <title>如何判断一个数据库是否出现了问题？</title>
    <link href="http://example.com/2022/03/21/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E5%87%BA%E7%8E%B0%E4%BA%86%E9%97%AE%E9%A2%98%EF%BC%9F/"/>
    <id>http://example.com/2022/03/21/%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E5%90%A6%E5%87%BA%E7%8E%B0%E4%BA%86%E9%97%AE%E9%A2%98%EF%BC%9F/</id>
    <published>2022-03-21T07:30:00.000Z</published>
    <updated>2022-03-21T07:50:00.480Z</updated>
    
    <content type="html"><![CDATA[<p>在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。</p><p>主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出问题了，由 HA 系统发起的。</p><p>而怎么判断主库出现了问题则是一个重点。</p><h2 id="select-1判断"><a href="#select-1判断" class="headerlink" title="select 1判断"></a>select 1判断</h2><p>select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。</p><p>我们设置 innodb_thread_concurrency 参数为3控制InnoDB 的并发线程上限。也就是说，一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。</p><p>此时执行三个select sleep(100) from t，然后执行 select 1会返回成功，但执行select * from t会阻塞。这select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。</p><p>在 InnoDB 中，innodb_thread_concurrency 这个参数的默认值是 0，表示不限制并发线程数量。但是，不限制并发线程数肯定是不行的。因为，一个机器的 CPU 核数有限，线程全冲进来，上下文切换的成本就会太高。</p><p>所以，通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值。这时，你一定会有疑问，并发线程上限数设置为 128 够干啥，线上的并发连接数动不动就上千了。</p><p>并发连接和并发查询，并不是同一个概念。你在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。</p><p>并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。这也是为什么我们需要设置innodb_thread_concurrency 参数的原因。</p><h2 id="查表判断"><a href="#查表判断" class="headerlink" title="查表判断"></a>查表判断</h2><p>为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行。</p><p>使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。</p><p>但是，我们马上还会碰到下一个问题，即：空间满了以后，这种方法又会变得不好使。</p><p>我们知道，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。</p><h2 id="更新判断"><a href="#更新判断" class="headerlink" title="更新判断"></a>更新判断</h2><p>既然要更新，就要放个有意义的字段，常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。</p><p>节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。</p><p>但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。</p><p>但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。所以，现在看来 mysql.health_check 这个表就不能只有一行数据了。</p><p>为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。</p><p>由于 MySQL 规定了主库和备库的 server_id 必须不同（否则创建主备关系的时候就会报错），这样就可以保证主、备库各自的检测命令不会发生冲突。</p><p>更新判断是一个相对比较常用的方案了，不过依然存在一些问题。其中，“判定慢”一直是让 DBA 头疼的问题。</p><p>其实，这里涉及到的是服务器 IO 资源分配的问题。</p><p>首先，所有的检测逻辑都需要一个超时时间 N。执行一条 update 语句，超过 N 秒后还不返回，就认为系统不可用。</p><p>你可以设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。</p><p>但是你要知道，IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在</p><p>拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。</p><p>检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。</p><p>也就是说，这时候在业务系统上正常的 SQL 语句已经执行得很慢了，但是 DBA 上去一看，HA 系统还在正常工作，并且认为主库现在处于可用状态。</p><p>之所以会出现这个现象，根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。</p><p>因为，外部检测都需要定时轮询，所以系统可能已经出问题了，但是却需要等到下一个检测发起执行语句的时候，我们才有可能发现问题。而且，如果你的运气不够好的话，可能第一次轮询还不能发现，这就会导致切换慢的问题。</p><h2 id="内部统计"><a href="#内部统计" class="headerlink" title="内部统计"></a>内部统计</h2><p>针对磁盘利用率这个问题，如果 MySQL 可以告诉我们，内部每一次 IO 请求的时间，那我们判断数据库是否出问题的方法就可靠得多了。</p><p>其实，MySQL 5.6 版本以后提供的 performance_schema 库，就在file_summary_by_event_name 表里统计了每次 IO 请求的时间。</p><p>因为我们每一次操作数据库，performance_schema 都需要额外地统计这些信息，所以我们打开这个统计功能是有性能损耗的。</p><p>假设，现在你已经开启了 redo log 和 binlog 这两个统计信息，那要怎么把这个信息用在实例状态诊断上呢？</p><p>很简单，你可以通过 MAX_TIMER 的值来判断数据库是否出问题了。比如，你可以设定阈值，单次 IO 请求时间超过 200 毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。</p><pre><code>mysql&gt; select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_n</code></pre><p>发现异常后，取到你需要的信息，再通过下面这条语句：</p><pre><code>mysql&gt; truncate table performance_schema.file_summary_by_event_name;</code></pre><p>把之前的统计信息清空。这样如果后面的监控中，再次出现这个异常，就可以加入监控累积值了。</p><pre><code>转载：https://www.jianshu.com/p/a95064c25e45</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。&lt;/p&gt;
&lt;p&gt;主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出问题了，由 HA 系统发起</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    <category term="主从复制" scheme="http://example.com/categories/MySQL/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
    <category term="主从复制" scheme="http://example.com/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    
    <category term="故障" scheme="http://example.com/tags/%E6%95%85%E9%9A%9C/"/>
    
  </entry>
  
</feed>
