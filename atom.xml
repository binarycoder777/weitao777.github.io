<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-09-18T12:27:13.615Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>重温Mybatis---Mybatis整体架构</title>
    <link href="http://example.com/2022/09/18/%E9%87%8D%E6%B8%A9Mybatis-Mybatis%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/"/>
    <id>http://example.com/2022/09/18/%E9%87%8D%E6%B8%A9Mybatis-Mybatis%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/</id>
    <published>2022-09-18T12:10:00.000Z</published>
    <updated>2022-09-18T12:27:13.615Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatis整体架构分为三层，分别是基础层、核心层和接口层<br><img src="/images/pasted-250.png" alt="upload successful"></p><ol><li>基础层：“包含整个MyBatis的基础模块，这些模块为核心处理层的功能提供了良好的支撑。”</li></ol><ul><li>反射模块：“对Java原生的反射进行了良好的封装，提供了更加简洁易用的API，方便上层使调用，并且对反射操作进行了一系列优化，例如缓存了类的元数据，提高了反射操作的性能。”</li><li>类型转换模块：“MyBatis为简化配置文件提供了别名机制，该机制是类型转换模块的主要功能之一。类型转换模块的另一个功能是实现JDBC类型与Java类型之间的转换，该功能在为SQL语句绑定实参以及映射查询结果集时都会涉及。在为SQL语句绑定实参时，会将数据由Java类型转换成JDBC类型；而在映射结果集时，会将数据由JDBC类型转换成Java类型。”</li><li>日志模块：”Mybatis集成了多种日志框架“</li><li>资源加载模块：”MyBatis为简化配置文件提供了别名机制，该机制是类型转换模块的主要功能之一。类型转换模块的另一个功能是实现JDBC类型与Java类型之间的转换，该功能在为SQL语句绑定实参以及映射查询结果集时都会涉及。在为SQL语句绑定实参时，会将数据由Java类型转换成JDBC类型；而在映射结果集时，会将数据由JDBC类型转换成Java类型。”</li><li>解析器模块：“解析器模块的主要提供了两个功能：一个功能是对XPath进行封装，为MyBatis初始化时解析mybatis-config.xml配置文件以及映射配置文件提供支持；另一个功能是为处理动态SQL语句中的占位符提供支持。”</li><li>数据源模块：”Mybatis提供的自身数据源实现和与第三方数据源集成的接口“</li><li>事务模块：“MyBatis对数据库中的事务进行了抽象，其自身提供了相应的事务接口和简单实现。在很多场景中，MyBatis会与Spring框架集成，并由Spring框架管理事务”</li><li>缓存模块：“MyBatis中提供了一级缓存和二级缓存，而这两级缓存都是依赖于基础支持层中的缓存模块实现的。”</li><li>Binging模块：“在调用SqlSession相应方法执行数据库操作时，需要指定映射文件中定义的SQL节点，如果出现拼写错误，我们只能在运行时才能发现相应的异常。为了尽早发现这种错误，MyBatis通过Binding模块将用户自定义的Mapper接口与映射配置文件关联起来，系统可以通过调用自定义Mapper接口中的方法执行相应的SQL语句完成数据库操作，从而避免上述问题。”</li></ul><ol start="2"><li>核心处理层：“在核心处理层中实现了MyBatis的核心处理流程，其中包括MyBatis的初始化以及完成一次数据库操作的涉及的全部流程。”</li></ol><ul><li>配置解析：“在MyBatis初始化过程中，会加载mybatis-config.xml配置文件、映射配置文件以及Mapper接口中的注解信息，解析后的配置信息会形成相应的对象并保存到Configuration对象中。之后利用configuration创建sqlsessionFactory对象，待MyBatis初始化之后，开发人员可以通过初始化得到SqlSessionFactory创建SqlSession对象并完成数据库操作。”</li><li>SQL解析与scripting模块：“MyBatis实现动态SQL语句的功能，提供了多种动态SQL语句对应的节点，例如，＜where＞节点、＜if＞节点、＜foreach＞节点等。通过这些节点的组合使用，开发人员可以写出几乎满足所有需求的动态SQL语句。”</li><li>SQL执行：“SQL语句的执行涉及多个组件，其中比较重要的是Executor、StatementHandler、ParameterHandler和ResultSetHandler。Executor主要负责维护一级缓存和二级缓存，并提供事务管理的相关操作，它会将数据库相关操作委托给StatementHandler完成。StatementHandler首先通过ParameterHandler完成SQL语句的实参绑定，然后通过java.sql.Statement对象执行SQL语句并得到结果集，最后通过ResultSetHandler完成结果集的映射，得到结果对象并返回。”</li></ul><p> <img src="/images/pasted-251.png" alt="upload successful"></p><ul><li>插件：“MyBatis提供了插件接口，我们可以通过添加用户自定义插件的方式对MyBatis进行扩展。用户自定义插件也可以改变Mybatis的默认行为”</li></ul><ol start="3"><li>接口层：“接口层相对简单，其核心是SqlSession接口，该接口中定义了MyBatis暴露给应用程序调用的API，也就是上层应用与MyBatis交互的桥梁。接口层在接收到调用请求时，会调用核心处理层的相应模块来完成具体的数据库操作。”</li></ol><p>摘录来自<br>MyBatis技术内幕<br>徐郡明</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Mybatis整体架构分为三层，分别是基础层、核心层和接口层&lt;br&gt;&lt;img src=&quot;/images/pasted-250.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基础层：“包含整个MyBatis的基础模块，这些模块为核心处理</summary>
      
    
    
    
    <category term="Mybatis" scheme="http://example.com/categories/Mybatis/"/>
    
    
    <category term="Mybatis" scheme="http://example.com/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>关于线上CPU飙升如何排查问题</title>
    <link href="http://example.com/2022/09/10/%E5%85%B3%E4%BA%8E%E7%BA%BF%E4%B8%8ACPU%E9%A3%99%E5%8D%87%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2022/09/10/%E5%85%B3%E4%BA%8E%E7%BA%BF%E4%B8%8ACPU%E9%A3%99%E5%8D%87%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5%E9%97%AE%E9%A2%98/</id>
    <published>2022-09-10T02:42:00.000Z</published>
    <updated>2022-09-10T03:44:02.090Z</updated>
    
    <content type="html"><![CDATA[<p>在学校的时候做的项目并没有遇到CPU飙升等相关的问题，以至于针对于线上CPU飙升等问题的排查得不到锻炼，特此记录一下，关于CPU飙升问题的排查。</p><h3 id="一、定位问题"><a href="#一、定位问题" class="headerlink" title="一、定位问题"></a>一、定位问题</h3><p>一般情况下，在线上遇到了CPU飙升等问题，可以开启弹性扩容或重启服务来暂时性的避免问题，但终究是治标不治本。只有找到问题发生的原因才能从根本上解决问题。而一般来说导致Java程序CPU与内存冲高的原因有如下：</p><ul><li>代码中某个位置读取数据量较大，导致系统内存耗尽，从而导致Full GC次数过多，系统缓慢。</li><li>代码中有比较耗CPU的操作，导致CPU过高，系统运行缓慢。</li><li>代码某个位置有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的；</li><li>某个线程由于某种原因而进入WAITING状态，此时该功能整体不可用，但是无法复现；</li><li>由于锁使用不当，导致多个线程进入死锁状态，从而导致系统整体比较缓慢</li></ul><p>前两种情况出现的频率较高，可能会导致系统不可用，后三种会导致某个功能运行缓慢，但是不至于导致系统不可用。因此针对于这些情况，需要进行依依排查。</p><ol><li>通过top命令查看所有进程的资源占用情况，找到资源占用较高的进程</li><li>然后通过top -Hp 查看对应进程下的线程资源使用情况</li><li>将线程id转化为16进制，然后jstack pid | grep tip 查看进程下对应线程的栈信息</li><li>通过jstat -gcutil 进程号 统计间隔毫秒 统计次数（缺省代表一直统计）查看对应的full gc等情况</li><li>也可以通过jconsole，MAT等可视化工具查看</li></ol><h3 id="二、排查问题"><a href="#二、排查问题" class="headerlink" title="二、排查问题"></a>二、排查问题</h3><ol><li>Full GC次数过多：走上述1-4步，查看是因为生成量大对象导致，还是生成大对象导致等</li></ol><ul><li>线上多个线程的CPU都超过了100%，通过jstack命令可以看到这些线程主要是垃圾回收线程</li><li>通过jstat命令监控GC情况，可以看到Full GC次数非常多，并且次数在不断增加。</li></ul><ol start="2"><li><p>某个业务逻辑执行时间过长：走上述1-4步，查看具体的堆栈信息定位代码进一步排查</p></li><li><p>如果有死锁，会直接提示。关键字：deadlock。使用jstack打印线程信息会打印出业务死锁的位置。</p></li></ol><ol start="4"><li>随机出现大量线程访问接口缓慢：首先找到该接口，通过压测工具不断加大访问力度，如果说该接口中有某个位置是比较耗时的，由于我们的访问的频率非常高，那么大多数的线程最终都将阻塞于该阻塞点这样通过多个线程具有相同的堆栈日志，我们基本上就可以定位到该接口中比较耗时的代码的位置。</li></ol><p>因此对于线上CPU的排查步骤大致便是如此，到了具体场景需要具体场景具体分析。以上只是一个大致的排查思路记录。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在学校的时候做的项目并没有遇到CPU飙升等相关的问题，以至于针对于线上CPU飙升等问题的排查得不到锻炼，特此记录一下，关于CPU飙升问题的排查。&lt;/p&gt;
&lt;h3 id=&quot;一、定位问题&quot;&gt;&lt;a href=&quot;#一、定位问题&quot; class=&quot;headerlink&quot; title=&quot;</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
  </entry>
  
  <entry>
    <title>Redis如何处理内存碎片？</title>
    <link href="http://example.com/2022/08/23/Redis%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%EF%BC%9F/"/>
    <id>http://example.com/2022/08/23/Redis%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%EF%BC%9F/</id>
    <published>2022-08-23T08:09:00.000Z</published>
    <updated>2022-08-23T08:19:29.181Z</updated>
    
    <content type="html"><![CDATA[<p>redis服务器的内存碎片过大</p><ul><li><p>在4.0版本以下只能重启恢复，因为重启之后redis重新从日志文件读取数据，在内存进行排序，为每个数据重新选择合适的内存单元，减小内存碎片</p></li><li><p>在4.0以后，redis提供了自动和手动的碎片整理功能：原理就是复制算法，把数据拷贝到新的内存空间，然后把佬的空间释放掉，这期间会阻塞主进程。</p></li></ul><p>手动：memory purge命令</p><p>自动：使用config set activedefrag指令或在redis.config中配置activedefrag为yes</p><p>自动清理时机：设置200m开始情况，或设置内存碎片占分配的内存多少占比开始，除此之外，可以设置清理期间清理线程所占cpu时间比，以保证有效清理以及不会影响当前任务</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;redis服务器的内存碎片过大&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在4.0版本以下只能重启恢复，因为重启之后redis重新从日志文件读取数据，在内存进行排序，为每个数据重新选择合适的内存单元，减小内存碎片&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在4.0以后，redis提供了自动和</summary>
      
    
    
    
    <category term="内存碎片" scheme="http://example.com/categories/%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/"/>
    
    
    <category term="Redis" scheme="http://example.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>redis共享对象失效的场景</title>
    <link href="http://example.com/2022/08/23/redis%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/"/>
    <id>http://example.com/2022/08/23/redis%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/</id>
    <published>2022-08-23T08:05:00.000Z</published>
    <updated>2022-08-23T08:09:10.420Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>redis中设置了maxmemory现在最大内存占用大小，且启用了LRU策略：LRU策略需要记录每个键值对的访问时间，如果共享同一个整数对象，会导致更新与LRU不匹配</p></li><li><p>集合类型的编码采用ziplist编码，并且集合内容是整数，也不能共享一个整数对象：因为使用了ziplist紧凑内存结构存储数据，可以不用去判断整数是否共享</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;redis中设置了maxmemory现在最大内存占用大小，且启用了LRU策略：LRU策略需要记录每个键值对的访问时间，如果共享同一个整数对象，会导致更新与LRU不匹配&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;集合类型的编码采用ziplist编码，并且集合内容是整</summary>
      
    
    
    
    <category term="共享对象" scheme="http://example.com/categories/%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1/"/>
    
    <category term="Redis" scheme="http://example.com/categories/%E5%85%B1%E4%BA%AB%E5%AF%B9%E8%B1%A1/Redis/"/>
    
    
    <category term="Redis" scheme="http://example.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>为什么要记录呢？</title>
    <link href="http://example.com/2022/08/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%B0%E5%BD%95%E5%91%A2%EF%BC%9F/"/>
    <id>http://example.com/2022/08/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%AE%B0%E5%BD%95%E5%91%A2%EF%BC%9F/</id>
    <published>2022-08-15T12:38:11.000Z</published>
    <updated>2022-08-15T12:41:57.727Z</updated>
    
    <content type="html"><![CDATA[<p>我时常会有这样的感觉：自己心里觉得对一个技术点已经掌握了，但是当我试图给别<br>人讲述的时候，发现并不能轻松自如 、深入浅出地讲出来这就说明了一个问题：自认为掌握了，真实并没有真正掌握，大脑只是对这个技术点建立了一个整体的概念，在一些细节处做了想当然的假设 等到你用语言再来表达的时候就会发现，原来这个假设并不完全成立，是辛辛问题的。估计大家都有这样的经验：如果你能把一门技术通俗易懂地给别人讲明白，那就说明你已经掌握了 这种“转教别人（ Teach others ）” 的办法属于主动学习，效率是最高的。但是在平日生活当中，很少有机会去给别人讲授的。那怎么办？总不能拉着别人说：“哥们儿，来，我刚学了 Java CAS ，我给你讲讲吧。”别人很有礼貌，耐着性子昕你磕磕绊绊地讲完了 ，然后不知所云前几次还行，次数多了，就对你敬而远之了。既然没法给别人讲，那就退而求真；写吧，把自己的理解写出来。当然不是泛泛地记流水账，或者把几个孤立的点罗列在那里，而是要把思路厘清楚，尤真要写出为什么要有这门技术、这门技术解决了什么问题， 后才是这门技术是怎么使用当你逼着自己去回答这些问题的时候很快就会发现 ，自 己的理解还不够，还需要查找更多的资料。在你从网上查找资料的时候，你会发现，网上的这些文章怎么这么差劲，重复的内容这么多，大部分都是复制、粘贴的大部分都在讲述怎么使用 ，对为什么”从来都是只字不握，或者犹抱琵琶半遮面，羞羞答答地不说出来这个整理资料和思考的过程是很珍贵的，只离这样才能把信息变成仰自身的知识。如果实在搞不定，就带着问题去论坛提问，去QQ群发言，找大牛请教，总是可以解决的。举个例子，你接触到一个新的知识点： Java 动态代理，你也看了书或视频中的代码 知道了这个技术点是怎么使用的，接下来想要写一篇文章，首先要努力阎明的问题就是“为什么要用 Java 动态代理”。这玩意儿到底要干吗？我已经知<br>道了 能够对一个类进行增强，还是在运行时进行增强的，但是增强一个类有什么用处？我完全可以新写一个类对原有的类进行增强啊？为什么要在运行时进行增强呢？<br>如果你顺着这个思路挖掘下去，则会在通道的尽头找到一个宝贝： AOP具体到技术层面，还有一个问题，就是为什么 Java 动态代理只能对 interface 进行操作，而不能对 class 进行操作？这个问题如果也深挖下去，那么你会发现另一个宝贝：动态字节码的生成，继续深挖就能看到 ASM CGLib 这样的东西，看到它们怎么在内存中操作 .class 文件的字节码。至于字节码的格式是什么样子的，只好去看看 Java 虚拟机了。到了最后，你也许会体会到，原来 Java 是一门静态语言，在运行时不能对现有的方法逻辑进行修改，不能添加方法，所以必须用别的手段，如 ASM 、动态代理等创建一个新类来做一点“额外”的事情。赶紧写一篇文章吧，把挖掘的结果记录下来，别人只学会了什么是 Java 动态代理，这只是冰山一角，而你则看到了整座冰山。人可能要问了：我也可以按照这个思路去学习，为什么要写下来呢？原因很简不写出来，很容易肢弃深度思考 你会觉得，我已经知道是怎么回事儿了一一真实一些关键的细节被大脑给忽略了</p><p>我们已经进入了一个碎片化的时代，我们的大脑已经养成了碎片化的习惯，一天不看<br>碎片化的信息就觉得不舒服，这样下去会慢慢地丧失深度思考的能力写作会逼着你去思考，梳理知识体系，防止自己被碎片所填满真实很多人都知道写作是一件很好的事情，就是犯懒，执行不下去。还是行动起来吧！逼自己，对自己狠一点！有自制力的人、能够坚持的人才更高可能成功！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我时常会有这样的感觉：自己心里觉得对一个技术点已经掌握了，但是当我试图给别&lt;br&gt;人讲述的时候，发现并不能轻松自如 、深入浅出地讲出来这就说明了一个问题：自认为掌握了，真实并没有真正掌握，大脑只是对这个技术点建立了一个整体的概念，在一些细节处做了想当然的假设 等到你用语言再</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>分布式调度xxl-job</title>
    <link href="http://example.com/2022/08/01/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6xxl-job/"/>
    <id>http://example.com/2022/08/01/%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6xxl-job/</id>
    <published>2022-08-01T11:40:00.000Z</published>
    <updated>2022-08-01T12:47:18.805Z</updated>
    
    <content type="html"><![CDATA[<p>xxl-job就是一个中心化管理系统，系统主要通过MySQL管理各种定时任务信息，当到了定时任务的触发时间，就把任务信息从db中拉进内存，对任务执行器发起触发请求。这个任务执行器，既可以是bean、groovy脚本、python脚本等，也可以是外部的http接口。相比起当当网开源的elastic-job-lite（基于zookeeper作为协调器的“无中心”架构），这种中心化管理的系统其实更简单、易于维护。</p><h3 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h3><p>将调度行为抽象形成“调度中心”公共平台，而平台自身并不承担业务逻辑，“调度中心”负责发起调度请求。将任务抽象成分散的JobHandler，交由“执行器”统一管理，“执行器”负责接收调度请求并执行对应的JobHandler中业务逻辑。因此，“调度”和“任务”两部分可以相互解耦，提高系统整体稳定性和扩展性；</p><h3 id="系统组成"><a href="#系统组成" class="headerlink" title="系统组成"></a>系统组成</h3><p>调度模块（调度中心）：负责管理调度信息，按照调度配置发出调度请求，自身不承担业务代码。调度系统与任务解耦，提高了系统可用性和稳定性，同时调度系统性能不再受限于任务模块；支持可视化、简单且动态的管理调度信息，包括任务新建，更新，删除，GLUE开发和任务报警等，所有上述操作都会实时生效，同时支持监控调度结果以及执行日志，支持执行器Failover。</p><p>执行模块（执行器）：负责接收调度请求并执行任务逻辑。任务模块专注于任务的执行等操作，开发和维护更加简单和高效；接收“调度中心”的执行请求、终止请求和日志请求等。</p><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p> <img src="/images/pasted-249.png" alt="upload successful"></p><h3 id="quartz的不足"><a href="#quartz的不足" class="headerlink" title="quartz的不足"></a>quartz的不足</h3><p> Quartz作为开源作业调度中的佼佼者，是作业调度的首选。但是集群环境中Quartz采用API的方式对任务进行管理，从而可以避免上述问题，但是同样存在以下问题：</p><ul><li>问题一：调用API的的方式操作任务，不人性化；</li><li>问题二：需要持久化业务QuartzJobBean到底层数据表中，系统侵入性相当严重。</li><li>问题三：调度逻辑和QuartzJobBean耦合在同一个项目中，这将导致一个问题，在调度任务数量逐渐增多，同时调度任务逻辑逐渐加重的情况下，此时调度系统的性能将大大受限于业务；</li><li>问题四：quartz底层以“抢占式”获取DB锁并由抢占成功节点负责运行任务，会导致节点负载悬殊非常大；而XXL-JOB通过执行器实现“协同分配式”运行任务，充分发挥集群优势，负载各节点均衡。</li></ul><p>XXL-JOB弥补了quartz的上述不足之处。</p><h3 id="调度模块剖析"><a href="#调度模块剖析" class="headerlink" title="调度模块剖析"></a>调度模块剖析</h3><ul><li>XXL-JOB最终选择自研调度组件（早期调度组件基于Quartz）；一方面是为了精简系统降低冗余依赖，另一方面是为了提供系统的可控度与稳定性；XXL-JOB中“调度模块”和“任务模块”完全解耦，调度模块进行任务调度时，将会解析不同的任务参数发起远程调用，调用各自的远程执行器服务。这种调用模型类似RPC调用，调度中心提供调用代理的功能，而执行器提供远程服务的功能。</li><li>基于数据库的集群方案，数据库选用Mysql；集群分布式并发环境中进行定时任务调度时，会在各个节点会上报任务，存到数据库中，执行时会从数据库中取出触发器来执行，如果触发器的名称和执行时间相同，则只有一个节点去执行此任务。</li><li>调度采用线程池方式实现，避免单线程因阻塞而引起任务调度延迟。</li><li>XXL-JOB调度模块默认采用并行机制，在多线程调度的情况下，调度模块被阻塞的几率很低，大大提高了调度系统的承载量。XXL-JOB的不同任务之间并行调度、并行执行。XXL-JOB的单个任务，针对多个执行器是并行运行的，针对单个执行器是串行执行的。同时支持任务终止。</li></ul><p>任务调度错过触发时间时的处理策略：</p><ul><li>过期超5s：本次忽略，当前时间开始计算下次触发时间</li><li>过期5s内：立即触发一次，当前时间开始计算下次触发时间</li></ul><h3 id="调度日志"><a href="#调度日志" class="headerlink" title="调度日志"></a>调度日志</h3><p>调度中心每次进行任务调度，都会记录一条任务日志，任务日志主要包括以下三部分内容：</p><ul><li>任务信息：包括“执行器地址”、“JobHandler”和“执行参数”等属性，点击任务ID按钮可查看，根据这些参数，可以精确的定位任务执行的具体机器和任务代码；</li><li>调度信息：包括“调度时间”、“调度结果”和“调度日志”等，根据这些参数，可以了解“调度中心”发起调度请求时具体情况。</li><li>执行信息：包括“执行时间”、“执行结果”和“执行日志”等，根据这些参数，可以了解在“执行器”端任务执行的具体情况；</li></ul><p>调度日志，针对单次调度，属性说明如下：</p><pre><code>执行器地址：任务执行的机器地址；JobHandler：Bean模式表示任务执行的JobHandler名称；任务参数：任务执行的入参；调度时间：调度中心，发起调度的时间；调度结果：调度中心，发起调度的结果，SUCCESS或FAIL；调度备注：调度中心，发起调度的备注信息，如地址心跳检测日志等；执行时间：执行器，任务执行结束后回调的时间；执行结果：执行器，任务执行的结果，SUCCESS或FAIL；执行备注：执行器，任务执行的备注信息，如异常日志等；执行日志：任务执行过程中，业务代码中打印的完整执行日志，见“4.8 查看执行日志”；</code></pre><h3 id="任务依赖"><a href="#任务依赖" class="headerlink" title="任务依赖"></a>任务依赖</h3><p>原理：XXL-JOB中每个任务都对应有一个任务ID，同时，每个任务支持设置属性“子任务ID”，因此，通过“任务ID”可以匹配任务依赖关系。</p><p>当父任务执行结束并且执行成功时，将会根据“子任务ID”匹配子任务依赖，如果匹配到子任务，将会主动触发一次子任务的执行。</p><h3 id="全异步化-amp-轻量级"><a href="#全异步化-amp-轻量级" class="headerlink" title="全异步化&amp;轻量级"></a>全异步化&amp;轻量级</h3><p>全异步化设计：XXL-JOB系统中业务逻辑在远程执行器执行，触发流程全异步化设计。相比直接在调度中心内部执行业务逻辑，极大的降低了调度线程占用时间；</p><ul><li><p>异步调度：调度中心每次任务触发时仅发送一次调度请求，该调度请求首先推送“异步调度队列”，然后异步推送给远程执行器</p></li><li><p>异步执行：执行器会将请求存入“异步执行队列”并且立即响应调度中心，异步运行。</p></li></ul><p>轻量级设计：XXL-JOB调度中心中每个JOB逻辑非常 “轻”，在全异步化的基础上，单个JOB一次运行平均耗时基本在 “10ms” 之内（基本为一次请求的网络开销）；因此，可以保证使用有限的线程支撑大量的JOB并发运行；</p><p>得益于上述两点优化，理论上默认配置下的调度中心，单机能够支撑 5000 任务并发运行稳定运行；</p><p>实际场景中，由于调度中心与执行器网络ping延迟不同、DB读写耗时不同、任务调度密集程度不同，会导致任务量上限会上下波动。</p><p>如若需要支撑更多的任务量，可以通过 “调大调度线程数” 、”降低调度中心与执行器ping延迟” 和 “提升机器配置” 几种方式优化。</p><h3 id="均衡调度"><a href="#均衡调度" class="headerlink" title="均衡调度"></a>均衡调度</h3><p>调度中心在集群部署时会自动进行任务平均分配，触发组件每次获取与线程池数量（调度中心支持自定义调度线程池大小）相关数量的任务，避免大量任务集中在单个调度中心集群节点；</p><h3 id="任务-“运行模式”-剖析"><a href="#任务-“运行模式”-剖析" class="headerlink" title="任务 “运行模式” 剖析"></a>任务 “运行模式” 剖析</h3><p>原理：每个Bean模式任务都是一个Spring的Bean类实例，它被维护在“执行器”项目的Spring容器中。任务类需要加“@JobHandler(value=”名称”)”注解，因为“执行器”会根据该注解识别Spring容器中的任务。任务类需要继承统一接口“IJobHandler”，任务逻辑在execute方法中开发，因为“执行器”在接收到调度中心的调度请求时，将会调用“IJobHandler”的execute方法，执行任务逻辑。</p><h3 id="“GLUE模式-Java-”-任务"><a href="#“GLUE模式-Java-”-任务" class="headerlink" title="“GLUE模式(Java)” 任务"></a>“GLUE模式(Java)” 任务</h3><p>原理：每个 “GLUE模式(Java)” 任务的代码，实际上是“一个继承自“IJobHandler”的实现类的类代码”，“执行器”接收到“调度中心”的调度请求时，会通过Groovy类加载器加载此代码，实例化成Java对象，同时注入此代码中声明的Spring服务（请确保Glue代码中的服务和类引用在“执行器”项目中存在），然后调用该对象的execute方法，执行任务逻辑。</p><h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>执行器实际上是一个内嵌的Server，默认端口9999（配置项：xxl.job.executor.port）。</p><p>在项目启动时，执行器会通过“@JobHandler”识别Spring容器中“Bean模式任务”，以注解的value属性为key管理起来。</p><p>“执行器”接收到“调度中心”的调度请求时，如果任务类型为“Bean模式”，将会匹配Spring容器中的“Bean模式任务”，然后调用其execute方法，执行任务逻辑。如果任务类型为“GLUE模式”，将会加载GLue代码，实例化Java对象，注入依赖的Spring服务（注意：Glue代码中注入的Spring服务，必须存在与该“执行器”项目的Spring容器中），然后调用execute方法，执行任务逻辑。</p><h3 id="通讯模块剖析"><a href="#通讯模块剖析" class="headerlink" title="通讯模块剖析"></a>通讯模块剖析</h3><p>一次完整的任务调度通讯流程</p><ul><li>1、“调度中心”向“执行器”发送http调度请求: “执行器”中接收请求的服务，实际上是一台内嵌Server，默认端口9999;</li><li>2、“执行器”执行任务逻辑；</li><li>3、“执行器”http回调“调度中心”调度结果: “调度中心”中接收回调的服务，是针对执行器开放一套API服务;</li></ul><p>调度中心向执行器发送的调度请求时使用RequestModel和ResponseModel两个对象封装调度请求参数和响应数据, 在进行通讯之前底层会将上述两个对象对象序列化，并进行数据协议以及时间戳检验,从而达到数据加密的功能;</p><p>自v1.5版本之后, 任务取消了”任务执行机器”属性, 改为通过任务注册和自动发现的方式, 动态获取远程执行器地址并执行。</p><p>为保证系统”轻量级”并且降低学习部署成本，没有采用Zookeeper作为注册中心，采用DB方式进行任务注册发现；</p><h3 id="分片广播-amp-动态分片"><a href="#分片广播-amp-动态分片" class="headerlink" title="分片广播&amp;动态分片"></a>分片广播&amp;动态分片</h3><p>执行器集群部署时，任务路由策略选择”分片广播”情况下，一次任务调度将会广播触发对应集群中所有执行器执行一次任务，同时系统自动传递分片参数；可根据分片参数开发分片任务；</p><p>“分片广播” 以执行器为维度进行分片，支持动态扩容执行器集群从而动态增加分片数量，协同进行业务处理；在进行大数据量业务操作时可显著提升任务处理能力和速度。</p><p>“分片广播” 和普通任务开发流程一致，不同之处在于可以获取分片参数，获取分片参数进行分片业务处理。</p><p>1、分片任务场景：10个执行器的集群来处理10w条数据，每台机器只需要处理1w条数据，耗时降低10倍；<br>2、广播任务场景：广播执行器机器运行shell脚本、广播集群节点进行缓存更新等</p><h3 id="访问令牌（AccessToken）"><a href="#访问令牌（AccessToken）" class="headerlink" title="访问令牌（AccessToken）"></a>访问令牌（AccessToken）</h3><p>为提升系统安全性，调度中心和执行器进行安全性校验，双方AccessToken匹配才允许通讯；</p><p>调度中心和执行器，可通过配置项 “xxl.job.accessToken” 进行AccessToken的设置。</p><p>调度中心和执行器，如果需要正常通讯，只有两种设置；</p><p>设置一：调度中心和执行器，均不设置AccessToken；关闭安全性校验；<br>设置二：调度中心和执行器，设置了相同的AccessToken；</p><p>一次完整任务流程包括”调度（调度中心） + 执行（执行器）”两个阶段。</p><p>“故障转移”发生在调度阶段，在执行器集群部署时，如果某一台执行器发生故障，该策略支持自动进行Failover切换到一台正常的执行器机器并且完成调度请求流程。<br>“失败重试”发生在”调度 + 执行”两个阶段，支持通过自定义任务失败重试次数，当任务失败时将会按照预设的失败重试次数主动进行重试；</p><h3 id="执行器灰度上线"><a href="#执行器灰度上线" class="headerlink" title="执行器灰度上线"></a>执行器灰度上线</h3><p>调度中心与业务解耦，只需部署一次后常年不需要维护。但是，执行器中托管运行着业务作业，作业上线和变更需要重启执行器，尤其是Bean模式任务。<br>执行器重启可能会中断运行中的任务。但是，XXL-JOB得益于自建执行器与自建注册中心，可以通过灰度上线的方式，避免因重启导致的任务中断的问题。</p><p>步骤如下：</p><p>1、执行器改为手动注册，下线一半机器列表（A组），线上运行另一半机器列表（B组）；<br>2、等待A组机器任务运行结束并编译上线；执行器注册地址替换为A组；<br>3、等待B组机器任务运行结束并编译上线；执行器注册地址替换为A组+B组；<br>操作结束；</p><h3 id="任务失败警告"><a href="#任务失败警告" class="headerlink" title="任务失败警告"></a>任务失败警告</h3><p>默认提供邮件失败告警，可扩展短信、钉钉等方式。如果需要新增一种告警方式，只需要新增一个实现 “com.xxl.job.admin.core.alarm.JobAlarm” 接口的告警实现即可。可以参考默认提供邮箱告警实现 “EmailJobAlarm”。</p><h3 id="避免任务重复执行"><a href="#避免任务重复执行" class="headerlink" title="避免任务重复执行"></a>避免任务重复执行</h3><p>调度密集或者耗时任务可能会导致任务阻塞，集群情况下调度组件小概率情况下会重复触发；<br>针对上述情况，可以通过结合 “单机路由策略（如：第一台、一致性哈希）” + “阻塞策略（如：单机串行、丢弃后续调度）” 来规避，最终避免任务重复执行。</p><h3 id="调度结果丢失处理"><a href="#调度结果丢失处理" class="headerlink" title="调度结果丢失处理"></a>调度结果丢失处理</h3><p>执行器因网络抖动回调失败或宕机等异常情况，会导致任务调度结果丢失。由于调度中心依赖执行器回调来感知调度结果，因此会导致调度日志永远处于 “运行中” 状态。</p><p>针对该问题，调度中心提供内置组件进行处理，逻辑为：调度记录停留在 “运行中” 状态超过10min，且对应执行器心跳注册失败不在线，则将本地调度主动标记失败；</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;xxl-job就是一个中心化管理系统，系统主要通过MySQL管理各种定时任务信息，当到了定时任务的触发时间，就把任务信息从db中拉进内存，对任务执行器发起触发请求。这个任务执行器，既可以是bean、groovy脚本、python脚本等，也可以是外部的http接口。相比起当当</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="xxl-job" scheme="http://example.com/tags/xxl-job/"/>
    
    <category term="任务调度" scheme="http://example.com/tags/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>事件日志</title>
    <link href="http://example.com/2022/07/29/%E4%BA%8B%E4%BB%B6%E6%97%A5%E5%BF%97/"/>
    <id>http://example.com/2022/07/29/%E4%BA%8B%E4%BB%B6%E6%97%A5%E5%BF%97/</id>
    <published>2022-07-29T07:52:00.000Z</published>
    <updated>2022-07-29T08:12:05.044Z</updated>
    
    <content type="html"><![CDATA[<p>“日志用于记录系统运行期间发生过的离散事件。”</p><p> <img src="/images/pasted-248.png" alt="upload successful"></p><p> 从打印日志到分析查询之间，隔着收集、缓冲、聚合、加工、索引、存储等若干个步骤，这一整个链条中涉及大量值得注意的细节，复杂性并不亚于任何一项技术或业务功能的实现。</p><h3 id="日志输出"><a href="#日志输出" class="headerlink" title="日志输出"></a>日志输出</h3><p>从日志输出值得注意的事项开始，日志的输出应避免以下情况：</p><ul><li>避免打印敏感信息。</li><li>避免引用慢操作。</li><li>避免打印追踪诊断信息：日志中不要打印方法输入参数、输出结果、方法执行时长之类的调试信息。日志的职责是记录时间，追踪诊断应由链路系统去做。</li><li>避免误导他人：日志中给日后调试除错的人挖坑是十分恶劣却又常见的行为。</li><li>处理请求时的TraceID：服务收到请求时，如果该请求没有附带TraceID，就应该自动生成唯一的TraceID来对请求进行标记，并使用MDC自动输出到日志。“TraceID会贯穿整条调用链，目的是通过它把请求在分布式系统各个服务中的执行过程串联起来。TraceID通常也会随着请求的响应返回到客户端，如果响应内容出现了异常，用户便能通过此ID快速找到与问题相关的日志。”</li><li>系统运行过程中的关键事件</li><li>启动时输出配置信息。</li></ul><h3 id="收集与缓存"><a href="#收集与缓存" class="headerlink" title="收集与缓存"></a>收集与缓存</h3><p>“为了能看到跨节点的全部日志，就要有能覆盖整个链路的全局日志系统。这个需求决定了每个节点输出日志到文件后，必须将日志文件统一收集起来集中存储、索引，由此便催生了专门的日志收集器。”</p><p>“日志收集器不仅要保证能覆盖全部数据来源，还要尽力保证日志数据的连续性，这其实并不容易做到。譬如淘宝这类大型的互联网系统，每天的日志量超过了10 000TB（10PB）量级，日志收集器的部署实例数能到达百万量级[1]，此时归集到系统中的日志要与实际产生的日志保持绝对的一致性是非常困难的，也不应该为此付出过高成本。换言之，日志不追求绝对的完整精确，只追求在代价可承受的范围内尽可能地保证较高的数据质量。一种最常用的缓解压力的做法是将日志接收者从Logstash和Elasticsearch转移至抗压能力更强的队列缓存，譬如在Logstash之前架设一个Kafka或者Redis作为缓冲层，面对突发流量，Logstash或Elasticsearch处理能力出现瓶颈时自动削峰填谷，甚至当它们短时间停顿时，也不会丢失日志数据。”</p><h3 id="加工与聚合"><a href="#加工与聚合" class="headerlink" title="加工与聚合"></a>加工与聚合</h3><p>“在将日志集中收集之后，存入Elasticsearch之前，一般还要对它们进行加工转换和聚合处理。这是因为日志是非结构化数据，一行日志中通常会包含多项信息，如果不做处理，那在Elasticsearch中就只能以全文检索的原始方式去使用日志，既不利于统计对比，也不利于条件过滤。”</p><h3 id="存储与查询"><a href="#存储与查询" class="headerlink" title="存储与查询"></a>存储与查询</h3><p>“经过收集、缓冲、聚合、加工的日志数据，终于可以放入Elasticsearch中索引存储了。Elasticsearch是整个Elastic Stack技术栈的核心，其他步骤的工具，如Filebeat、Logstash、Kibana都有替代品，有自由选择的余地，唯独Elasticsearch在日志分析这方面完全没有什么值得一提的竞争者，几乎就是解决此问题的唯一答案。这样的结果与Elasticsearch本身是一款优秀产品有关，然而更关键的是Elasticsearch的优势正好与日志分析的需求完美契合。”</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;“日志用于记录系统运行期间发生过的离散事件。”&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-248.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
&lt;p&gt; 从打印日志到分析查询之间，隔着收集、缓冲、聚合、加工、索引、存储等若干个步骤</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="日志" scheme="http://example.com/tags/%E6%97%A5%E5%BF%97/"/>
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>可观测性</title>
    <link href="http://example.com/2022/07/29/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/"/>
    <id>http://example.com/2022/07/29/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/</id>
    <published>2022-07-29T07:41:00.000Z</published>
    <updated>2022-07-29T07:51:37.410Z</updated>
    
    <content type="html"><![CDATA[<p>可观测性即：可以由外部输出推断其内部状态。具体可以分解为：事件日志、链路追踪以及聚合度量三部分，这三个方向各有侧重，又有重合或者可以结合支出。</p><p> <img src="/images/pasted-247.png" alt="upload successful"></p><p> “日志（Logging）：日志的职责是记录离散事件，通过这些记录分析出程序的行为，譬如曾经调用过什么方法，曾经操作过哪些数据，等等。输出日志很容易，但收集和分析日志可能会很复杂，面对成千上万的集群节点，面对迅速滚动的事件信息，面对以TB计算的文本，传输与归集并不简单。对大多数程序员来说，分析日志也许就是最常遇见也最有实践可行性的“大数据系统”了。”</p><p>“·追踪（Tracing）：单体系统时代追踪的范畴基本只局限于栈追踪（Stack Tracing），例如调试程序时，在IDE打个断点，看到的调用栈视图上的内容便是追踪；编写代码时，处理异常调用了Exception::printStackTrace()方法，它输出的堆栈信息也是追踪。微服务时代，追踪就不只局限于调用栈了，一个外部请求需要内部若干服务的联动响应，这时候完整的调用轨迹将跨越多个服务，同时包括服务间的网络传输信息与各个服务内部的调用堆栈信息，因此，分布式系统中的追踪在国内常被称为“全链路追踪”（后文简称“链路追踪”），许多资料中也称它为“分布式追踪”（Distributed Tracing）。追踪的主要目的是排查故障，如分析调用链的哪一部分、哪个方法出现错误或阻塞，输入输出是否符合预期，等等。”</p><p>“度量（Metrics）：度量是指对系统中某一类信息的统计聚合。譬如，证券市场的每一只股票都会定期公布财务报表，通过财报上的营收、净利、毛利、资产、负载等一系列数据来体现过去一个财务周期中公司的经营状况，这便是一种信息聚合。Java天生自带一种基本的度量，即由虚拟机直接提供的JMX（Java Management eXtensions）度量，诸如内存大小、各分代的用量、峰值的线程数、垃圾收集的吞吐量、频率等都可以从JMX中获得。度量的主要目的是监控（Monitoring）和预警（Alert），如在某些度量指标达到风险阈值时触发事件，以便自动处理或者提醒管理员介入。”</p><p>“追踪方面的情况与日志、度量有所不同，追踪是与具体网络协议、程序语言密切相关的。收集日志不必关心这段日志是由Java程序输出的还是由Golang程序输出的，对程序来说它们就只是一段非结构化文本而已，同理，度量对程序来说也只是一个个聚合的数据指标而已。但链路追踪不一样，各个服务之间是使用HTTP还是gRPC来进行通信会直接影响追踪的实现，各个服务是使用Java、Golang还是Node.js来编写，也会直接影响进程内调用栈的追踪方式。这种特性决定了追踪工具本身有较强的侵入性，通常是以插件式的探针来实现；也决定了追踪领域很难出现一家独大的情况，通常要有多种产品来针对不同的语言和网络进行追踪。”</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;可观测性即：可以由外部输出推断其内部状态。具体可以分解为：事件日志、链路追踪以及聚合度量三部分，这三个方向各有侧重，又有重合或者可以结合支出。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-247.png&quot; alt=&quot;upload successful&quot;</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="可观测性" scheme="http://example.com/tags/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>事务处理（一）</title>
    <link href="http://example.com/2022/07/28/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://example.com/2022/07/28/%E4%BA%8B%E5%8A%A1%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2022-07-28T02:03:00.000Z</published>
    <updated>2022-07-28T02:20:36.908Z</updated>
    
    <content type="html"><![CDATA[<p>“事务处理几乎在每一个信息系统中都会涉及，它存在的意义是为了保证系统中所有的数据都是符合期望的，且相互关联的数据之间不会产生矛盾，即数据状态的一致性（Consistency）。按照数据库的经典理论，要达成这个目标，需要三方面共同努力来保障。</p><p>·原子性（Atomic）：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。</p><p>·隔离性（Isolation）：在不同的业务处理过程中，事务保证了各业务正在读、写的数据相互独立，不会彼此影响。</p><p>·持久性（Durability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。”</p><p>“A、I、D是手段，C是目的，前者是因，后者是果”</p><p>“当一个服务只使用一个数据源时，通过A、I、D来获得一致性是最经典的做法，也是相对容易的。此时，多个并发事务所读写的数据能够被数据源感知是否存在冲突，并发事务的读写在时间线上的最终顺序是由数据源来确定的，这种事务间一致性被称为“内部一致性”。<br> ·当一个服务使用到多个不同的数据源，甚至多个不同服务同时涉及多个不同的数据源时，问题就变得困难了许多。此时，并发执行甚至是先后执行的多个事务，在时间线上的顺序并不由任何一个数据源来决定，这种涉及多个数据源的事务间一致性被称为“外部一致性”。”</p><p> “外部一致性问题通常很难使用A、I、D来解决，因为这样需要付出很大甚至不切实际的代价；但是外部一致性又是分布式系统中必然会遇到且必须要解决的问题，为此我们要转变观念，将一致性从“是或否”的二元属性转变为可以按不同强度分开讨论的多元属性，在确保代价可承受的前提下获得强度尽可能高的一致性保障”</p><h3 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h3><p>“本地事务是指仅操作单一事务资源的、不需要全局事务管理器进行协调的事务”</p><p>“本地事务是一种最基础的事务解决方案，只适用于单个服务使用单个数据源的场景。从应用角度看，它是直接依赖于数据源本身提供的事务能力来工作的，在程序代码层面，最多只能对事务接口做一层标准化的包装（如JDBC接口），并不能深入参与到事务的运作过程中，事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作，这一点与后续介绍的XA、TCC、SAGA等主要靠应用程序代码来实现的事务有着十分明显的区别。”</p><p>“原子性和持久性在事务里是密切相关的两个属性：原子性保证了事务的多个操作要么都生效要么都不生效，不会存在中间状态；持久性保证了一旦事务生效，就不会再因为任何原因而导致其修改的内容被撤销或丢失。”</p><p>“实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观存在着“正在写”的中间状态。由于写入中间状态与崩溃都不可能消除，所以如果不做额外保障措施的话，将内存中的数据写入磁盘，并不能保证原子性与持久性。”</p><p>“为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中的变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即以仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。只有在日志记录全部安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化，这种事务实现方法被称为“提交日志”（Commit Logging）。”</p><p>“通过日志实现事务的原子性和持久性是当今的主流方案，但并不是唯一的选择。除日志外，还有另外一种称为“Shadow Paging”（有中文资料翻译为“影子分页”）的事务实现机制，常用的轻量级数据库SQLite Version 3采用的事务机制就是Shadow Paging。”</p><p>“Shadow Paging的大体思路是对数据的变动会写到硬盘的数据中，但不是直接就地修改原先的数据，而是先复制一份副本，保留原数据，修改副本数据。在事务处理过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。当事务成功提交，所有数据的修改都成功持久化之后，最后一步是修改数据的引用指针，将引用从原数据改为新复制并“hadow Paging的大体思路是对数据的变动会写到硬盘的数据中，但不是直接就地修改原先的数据，而是先复制一份副本，保留原数据，修改副本数据。在事务处理过程中，被修改的数据会同时存在两份，一份是修改前的数据，一份是修改后的数据，这也是“影子”（Shadow）这个名字的由来。当事务成功提交，所有数据的修改都成功持久化之后，最后一步是修改数据的引用指针，将引用从原数据改为新复制并修改后的副本，最后的“修改指针”这个操作将被认为是原子操作，现代磁盘的写操作的作用可以认为是保证了在硬件上不会出现“改了半个值”的现象。所以Shadow Paging也可以保证原子性和持久性。Shadow Paging实现事务要比Commit Logging更加简单，但涉及隔离性与并发锁时，Shadow Paging实现的事务并发能力就相对有限，因此在高性能的数据库中应用”</p><p>隔离性：“不同隔离级别以及幻读、不可重复读、脏读等问题都只是表面现象，是各种锁在不同加锁时间上组合应用所产生的结果，以锁为手段来实现隔离性才是数据库表现出不同隔离级别的根本原因。”</p><h3 id="全局事务"><a href="#全局事务" class="headerlink" title="全局事务"></a>全局事务</h3><p>“本地事务相对的是全局事务（Global Transaction），在一些资料中也将其称为外部事务（External Transaction），在本节里，全局事务被限定为一种适用于单个服务使用多个数据源场景的事务解决方案。请注意，理论上真正的全局事务并没有“单个服务”的约束，它本来就是DTP（Distributed Transaction Processing，分布式事务处理）模型[1]中的概念，但本节讨论的是一种在分布式环境中仍追求强一致性的事务处理方案，对于多节点而且互相调用彼此服务的场合（典型的就是现在的微服务系统）是极不合适的，当前它几乎只实际应用于单服务多数据源的场合中，为了避免与后续介绍的放弃了ACID的弱一致性事务处理方式混淆，所以这里的全局事务的范围有所缩减，后续涉及多服务多数据源的事务，笔者将称其为“分布式事务”。”</p><p>“为了解决分布式事务的一致性问题，X/Open组织（后来并入了The Open Group）提出了一套名为X/Open XA（XA是eXtended Architecture的缩写）的处理事务架构，其核心内容是定义了全局的事务管理器（Transaction Manager，用于协调全局事务）和局部的资源管理器（Resource Manager，用于驱动本地事务）之间的通信接口。XA接口是双向的，能在一个事务管理器和多个资源管理器（Resource Manager）之间形成通信桥梁，通过协调多个数据源的一致动作，实现全局事务的统一提交或者统一回滚，现在我们在Java代码中还偶尔能看见的XADataSource、XAResource都源于此。</p><p>不过，XA并不是Java的技术规范（XA提出那时还没有Java），而是一套语言无关的通用规范，所以Java中专门定义了JSR 907 Java Transaction API，基于XA模式在Java语言中实现了全局事务处理的标准，这也是我们现在所熟知的JTA。”</p><p>“XA将事务提交拆分成两阶段。”</p><p>“准备阶段：又叫作投票阶段，在这一阶段，协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复Prepared，否则回复Non-Prepared。这里所说的准备操作跟人类语言中通常理解的准备不同，对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条Commit Record而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。</p><p>·提交阶段：又叫作执行阶段，协调者如果在上一阶段收到所有事务参与者回复的Prepared消息，则先自己在本地持久化事务状态为Commit，然后向所有参与者发送Commit指令，让所有参与者立即执行提交操作；否则，任意一个参与者回复了Non-Prepared消息，或任意一个参与者超时未回复时，协调者将在自己完成事务状态为[…]”</p><p>“以上这两个过程被称为“两段式提交”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件。”</p><p>“必须假设网络在提交阶段的短时间内是可靠的，即提交阶段不会丢失消息。同时也假设网络通信在全过程都不会出现误差，即可以丢失消息，但不会传递错误的消息，XA的设计目标并不是解决诸如拜占庭将军一类的问题。在两段式提交中，投票阶段失败了可以补救（回滚），提交阶段失败了则无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险。<br> ·必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，进而向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。”</p><p> <img src="/images/pasted-245.png" alt="upload successful"></p><p>三段式提交把原本的两段式提交的准备阶段再细分为两个阶段，分别称为CanCommit、PreCommit，把提交阶段改称为DoCommit阶段。其中，新增的CanCommit是一个询问阶段，即协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。将准备阶段一分为二的理由是这个阶段是重负载的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，它们所涉及的数据资源即被锁住，如果此时某一个参与者宣告无法完成提交，相当于大家都做了一轮无用功。所以，增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，这也意味着因某个参与者提交时发生崩溃而导致大家全部回滚的风险相对变小。因此，在事务需要回滚的场景中，三段式提交的性能通常要比两段式提交好很多，但在事务能够正常提交的场景中[…]”</p><p> <img src="/images/pasted-246.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;“事务处理几乎在每一个信息系统中都会涉及，它存在的意义是为了保证系统中所有的数据都是符合期望的，且相互关联的数据之间不会产生矛盾，即数据状态的一致性（Consistency）。按照数据库的经典理论，要达成这个目标，需要三方面共同努力来保障。&lt;/p&gt;
&lt;p&gt;·原子性（Atom</summary>
      
    
    
    
    <category term="事务" scheme="http://example.com/categories/%E4%BA%8B%E5%8A%A1/"/>
    
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
    <category term="分布式" scheme="http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>redis的二进制位数组</title>
    <link href="http://example.com/2022/07/27/redis%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BD%8D%E6%95%B0%E7%BB%84/"/>
    <id>http://example.com/2022/07/27/redis%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BD%8D%E6%95%B0%E7%BB%84/</id>
    <published>2022-07-27T13:40:00.000Z</published>
    <updated>2022-07-27T13:56:11.470Z</updated>
    
    <content type="html"><![CDATA[<p>redis提供了setbit、getbit、bitcount、bitop指令来处理二进制位数组。而实际上，redis是使用字符串对象的SDS来表示位数组的，因为SDS数据结构是二进制安全的，并且可以使用SDS的相关函数。但值得注意的是，关于其二进制数组在SDS数据结构中是逆序存放的，主要用于简化setbit命令时涉及到扩容时移动元素的问题。</p><h3 id="getbit命令的实现"><a href="#getbit命令的实现" class="headerlink" title="getbit命令的实现"></a>getbit命令的实现</h3><ol><li>计算byte = offset / 8 :byte记录了offset值记录的偏移量保存在那个字节</li><li>计算bit =  offset % 8 + 1 ：bit记录了在指定字节上的偏移量</li><li>根据byte和bit定位</li></ol><h3 id="setbit命令的实现"><a href="#setbit命令的实现" class="headerlink" title="setbit命令的实现"></a>setbit命令的实现</h3><ol><li>计算len = offset / 8 + 1：计算保存数据的偏移量</li><li>检测是否足够空间</li><li>不足够，扩容</li><li>足够，则加进去（根据byte和bit的偏移量）</li></ol><p>(逆序存放作用便在此，扩容不需要移动元素)</p><h3 id="bitcount命令的实现"><a href="#bitcount命令的实现" class="headerlink" title="bitcount命令的实现"></a>bitcount命令的实现</h3><p>我们很容易能想到通过遍历来实现该指令，但显然遍历的效率并不高，因此我们可以创建一个表，表的键为某种排列的数组，值为相应的数组中1的数量，但查表的实际效果收到内存和缓存的影响（特别是数据量大的时候）。在redis中，使用的是variable-precision SWAR算法来实现的。感兴趣的可以去查阅资料了解一下。</p><h3 id="bitop命令的实现"><a href="#bitop命令的实现" class="headerlink" title="bitop命令的实现"></a>bitop命令的实现</h3><p>常规的变量做比较，&amp;，|之类，因为SDS支持这些操作。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;redis提供了setbit、getbit、bitcount、bitop指令来处理二进制位数组。而实际上，redis是使用字符串对象的SDS来表示位数组的，因为SDS数据结构是二进制安全的，并且可以使用SDS的相关函数。但值得注意的是，关于其二进制数组在SDS数据结构中是逆</summary>
      
    
    
    
    <category term="Redis" scheme="http://example.com/categories/Redis/"/>
    
    
    <category term="Redis" scheme="http://example.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>CPU Cache的数据结构和读取过程</title>
    <link href="http://example.com/2022/07/10/CPU-Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E8%AF%BB%E5%8F%96%E8%BF%87%E7%A8%8B/"/>
    <id>http://example.com/2022/07/10/CPU-Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E8%AF%BB%E5%8F%96%E8%BF%87%E7%A8%8B/</id>
    <published>2022-07-10T13:43:00.000Z</published>
    <updated>2022-07-10T13:51:35.402Z</updated>
    
    <content type="html"><![CDATA[<p>CPU Cache 的数据是从内存中读取过来的，它是以⼀⼩块⼀⼩块读取数据的，⽽不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样⼀⼩块⼀⼩块的数据，称为Cache Line（缓存块）。</p><p>事实上，CPU 读取数据的时候，⽆论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读⼊到 Cache 中，CPU 再从 CPU Cache 读取数据。</p><p>那 CPU 怎么知道要访问的内存数据，是否在 Cache ⾥？如果在的话，如何找到 Cache 对应的数据呢？我们从最简单、基础的直接映射 Cache（Direct Mapped Cache）说起，来看看整个 CPU Cache 的数据结构和访问逻辑。</p><h3 id="直接映射"><a href="#直接映射" class="headerlink" title="直接映射"></a>直接映射</h3><p>对于直接映射 Cache 采⽤的策略，就是把内存块的地址始终「映射」在⼀个 CPU Line（缓存块）的地址，⾄于映射关系实现⽅式，则是使⽤「取模运算」，取模运算的结果就是内存块地址对应的 CPU Line</p><p>举个例⼦，内存共被划分为 32 个内存块，CPU Cache 共有 8 个 CPU Line，假设 CPU 想要访问第 15 号内存块，如果 15 号内存块中的数据已经缓存在 CPU Line 中的话，则是⼀定映射在 7 号 CPU Line 中，因15 % 8 = 7</p><p>机智的你肯定发现了，使⽤取模⽅式映射的话，就会出现多个内存块对应同⼀个 CPU Line，⽐如上⾯的例⼦，除了 15 号内存块是映射在 7 号 CPU Line 中，还有 7 号、23 号、31 号内存块都是映射到 7 号 CPU Line 中。</p><p> <img src="/images/pasted-243.png" alt="upload successful"></p><p> 因此，为了区别不同的内存块，在对应的 CPU Line 中我们还会存储⼀个组标记（Tag）。这个组标记会记录当前 CPU Line 中存储的数据对应的内存块，我们可以⽤这个组标记来区分不同的内存块。</p><p> 除了组标记信息外，CPU Line 还有两个信息：</p><ul><li>⼀个是，从内存加载过来的实际存放数据（Data）。</li><li>另⼀个是，有效位（Valid bit），它是⽤来标记对应的 CPU Line 中的数据是否是有效的，如果有效位是 0，⽆论 CPU Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。</li></ul><p> CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，⽽是读取 CPU 所需要的⼀个数据⽚段，这样的数据统称为⼀个字（Word）。那怎么在对应的 CPU Line 中数据块中找到所需的字呢？答案是，需要⼀个偏移量（Offset）。</p><p> 因此，⼀个内存的访问地址，包括组标记、CPU Line 索引、偏移量这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。⽽对于 CPU Cache ⾥的数据结构，则是由索引 + 有效位 + 组标记 + 数据块组成。</p><p> <img src="/images/pasted-244.png" alt="upload successful"></p><p> 如果内存中的数据已经在 CPU Cahe 中了，那 CPU 访问⼀个内存地址的时候，会经历这 4 个步骤：</p><ol><li>根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Line 的地址；</li><li>找到对应 CPU Line 后，判断 CPU Line 中的有效位，确认 CPU Line 中数据是否是有效的，如果是⽆效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执⾏；</li><li>对⽐内存地址中组标记和 CPU Line 中的组标记，确认 CPU Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执⾏；</li><li>根据内存地址中偏移量信息，从 CPU Line 的数据块中，读取对应的字。<br>到这⾥，相信你对直接映射 Cache 有了⼀定认识，但其实除了直接映射 Cache 之外，还有其他通过内存地址找到 CPU Cache 中的数据的策略，⽐如全相连 Cache （Fully Associative Cache）、组相连 Cache（Set Associative Cache）等，这⼏种策策略的数据结构都⽐较相似，我们理解了直接映射 Cache 的⼯作⽅式，其他的策略如果你有兴趣去看，相信很快就能理解的了。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;CPU Cache 的数据是从内存中读取过来的，它是以⼀⼩块⼀⼩块读取数据的，⽽不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样⼀⼩块⼀⼩块的数据，称为Cache Line（缓存块）。&lt;/p&gt;
&lt;p&gt;事实上，CPU 读取数据的时候，⽆论数据是否存放到 C</summary>
      
    
    
    
    <category term="Cache" scheme="http://example.com/categories/Cache/"/>
    
    
    <category term="计算机组成原理" scheme="http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
    <category term="Cache" scheme="http://example.com/tags/Cache/"/>
    
    <category term="CPU" scheme="http://example.com/tags/CPU/"/>
    
  </entry>
  
  <entry>
    <title>hashCode 的计算逻辑中，为什么是 31 作为乘数？</title>
    <link href="http://example.com/2022/07/09/hashCode-%E7%9A%84%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E4%B8%AD%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-31-%E4%BD%9C%E4%B8%BA%E4%B9%98%E6%95%B0%EF%BC%9F/"/>
    <id>http://example.com/2022/07/09/hashCode-%E7%9A%84%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E4%B8%AD%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-31-%E4%BD%9C%E4%B8%BA%E4%B9%98%E6%95%B0%EF%BC%9F/</id>
    <published>2022-07-09T12:01:00.000Z</published>
    <updated>2022-07-09T12:13:44.655Z</updated>
    
    <content type="html"><![CDATA[<p> <img src="/images/pasted-241.png" alt="upload successful"><br> 在获取 hashCode 的源码中可以看到，有一个固定值 31，在 for 循环每次执行时<br>进行乘积计算，循环后的公式如下； s[0]*31^(n-1) + s[1]*31^(n-2) + … +<br>s[n-1]<br>那么这里为什么选择 31 作为乘积值呢？</p><ol><li>31 是一个奇质数，如果选择偶数会导致乘积运算时数据溢出。</li><li>另外在二进制中，2 个 5 次方是 32，那么也就是 31 * i == (i &lt;&lt; 5) - i。这主要是说乘积运算可以使用位移提升性能，同时目前的 JVM 虚拟机也会自动支持此类的优化。</li><li>经过大量测试，相对于其他数，31得到的hash碰撞结果最小</li></ol><p>当然一个好的哈希函数除了要尽量减少碰撞外，关于散列表也就是 hash，<br>还有一个非常重要的点，那就是要尽可能的让数据散列分布。只有这样才能减少<br>hash 碰撞次数。</p><h3 id="扰动函数"><a href="#扰动函数" class="headerlink" title="扰动函数"></a>扰动函数</h3><p>在 HashMap 存放元素时候有这样一段代码来处理哈希值，这是 java 8 的散列值<br>扰动函数，用于优化散列效果；</p><p> <img src="/images/pasted-242.png" alt="upload successful"></p><p> 理论上来说字符串的 hashCode是一个 int 类型值，那可以直接作为数组下标了，<br>且不会出现碰撞。但是这个 hashCode 的取值范围是[-2147483648, 2147483647]，<br>有将近 40 亿的长度，谁也不能把数组初始化的这么大，内存也是放不下的。</p><p>我们默认初始化的 Map 大小是 16 个长度 DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4，<br>所以获取的 Hash 值并不能直接作为下标使用，需要与数组长度进行取模运算得<br>到一个下标值，也就是我们上面做的散列列子。</p><p>那么，hashMap 源码这里不只是直接获取哈希值，还进行了一次扰动计算，(h =<br>key.hashCode()) ^ (h &gt;&gt;&gt; 16)。把哈希值右移 16 位，也就正好是自己长度的一<br>半，之后与原哈希值做异或运算，这样就混合了原哈希值中的高位和低位，增大<br>了随机性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; &lt;img src=&quot;/images/pasted-241.png&quot; alt=&quot;upload successful&quot;&gt;&lt;br&gt; 在获取 hashCode 的源码中可以看到，有一个固定值 31，在 for 循环每次执行时&lt;br&gt;进行乘积计算，循环后的公式如下； s[0]*31</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="HashMap" scheme="http://example.com/tags/HashMap/"/>
    
  </entry>
  
  <entry>
    <title>Thread.start（）启动原理</title>
    <link href="http://example.com/2022/07/09/Thread-start%EF%BC%88%EF%BC%89%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86/"/>
    <id>http://example.com/2022/07/09/Thread-start%EF%BC%88%EF%BC%89%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86/</id>
    <published>2022-07-09T09:00:00.000Z</published>
    <updated>2022-07-09T10:52:32.322Z</updated>
    
    <content type="html"><![CDATA[<p>java中启动一个线程很简单</p><p>new Thread(()-&gt;{</p><p>// TODD</p><p>}).start();</p><p>但是这个线程是如何启动起来的呢？主要会经过下面这个流程</p><p> <img src="/images/pasted-237.png" alt="upload successful"></p><ol><li>线程的启动涉及到本地方法JNI的调用</li><li>具体的线程是映射到操作系统层面由操作系统处理</li><li>线程的启动涉及到线程的生命周期状态以及唤醒操作，所有有回调操作run()</li></ol><p>具体的UML图如下<br> <img src="/images/pasted-238.png" alt="upload successful"></p><h3 id="Java-层面-Thread-启动"><a href="#Java-层面-Thread-启动" class="headerlink" title="Java 层面 Thread 启动"></a>Java 层面 Thread 启动</h3><p>new Thread(() -&gt; {</p><p>// todo</p><p>}).start();</p><p>// JDK 源码</p><p>public synchronized void start() {</p><p>if (threadStatus != 0)</p><p>throw new IllegalThreadStateException();</p><p>group.add(this);</p><p>boolean started = false;</p><p>try {</p><p>start0();</p><p>started = true;</p><p>} finally {</p><p>try {</p><p>if (!started) {</p><p>group.threadStartFailed(this);</p><p>} } catch (Throwable ignore) {}</p><p>} }</p><p> 线程启动方法 start()，在它的方法英文注释中已经把核心内容描述出来。<br>Causes this thread to begin execution; the Java Virtual<br>Machine calls the run method of this thread. 这段话的意思<br>是：由 JVM 调用此线程的 run 方法，使线程开始执行。其实这就是一个 JVM 的<br>回调过程，下文源码分析中会讲到</p><p> 另外 start() 是一个 synchronized 方法，但为了避免多次调用，在方法中<br>会由线程状态判断。threadStatus != 0。 </p><p> group.add(this)，是把当前线程加入到线程组，ThreadGroup。 </p><p> start0()，是一个本地方法，通过 JNI 方式调用执行。这一步的操作才是启动<br>线程的核心步骤。</p><p> <img src="/images/pasted-239.png" alt="upload successful"></p><p> start0()，是一个本地方法，用于启动线程。</p><p> registerNatives()，这个方法是用于注册线程执行过程中需要的一些本地方<br>法，比如：start0、isAlive、yield、sleep、interrupt0 等。</p><p>后面线程的启动过程涉及到了 JVM 的参与，整个源码分析可以结合着代码调用 UML 时序图进行观看，基本核心过程包括：<br>Java 创建线程和启动、调用本地方法 start0()、JVM 中<br>JVM_StartThread 的创建和启动、设置线程状态等待被唤醒、根据不同<br>的 OS 启动线程并唤醒、最后回调 run() 方法启动 Java 线程</p><p>待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;java中启动一个线程很简单&lt;/p&gt;
&lt;p&gt;new Thread(()-&amp;gt;{&lt;/p&gt;
&lt;p&gt;// TODD&lt;/p&gt;
&lt;p&gt;}).start();&lt;/p&gt;
&lt;p&gt;但是这个线程是如何启动起来的呢？主要会经过下面这个流程&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="线程" scheme="http://example.com/tags/%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>打破双亲委派机制的一些场景</title>
    <link href="http://example.com/2022/07/05/%E6%89%93%E7%A0%B4%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF/"/>
    <id>http://example.com/2022/07/05/%E6%89%93%E7%A0%B4%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF/</id>
    <published>2022-07-05T11:42:00.000Z</published>
    <updated>2022-07-05T12:29:39.462Z</updated>
    
    <content type="html"><![CDATA[<p>前言：在说打破双亲委派机制的一些场景前，先聊一聊为什么需要双亲委派机制。</p><p>在双亲委派机制中，父子类通过组合的方式聚合在一起。由应用类加载器开始到系统类加器。主要是这几步：</p><ol><li>在自身的loadclass方法中先检查类是否已经被加载过</li><li>若没有加载则调用父类加载器的loadclass方法加载，若父类为空则默认用启动类加载器作为父加载器加载。</li><li>如果父类加载器失败，抛出异常classnotfoundexception后，调用自身的findclass方法进行加载类</li></ol><p>这样做的好处是一方面可以避免类的重复加载，当父类加载器已经加载过这个类时，子类不会再去加载。另一方面，通过这样的方式可以保证安全性。因为引导类加载在加载的时候只会加载JAVA_HOME的jar包，这个类及时被同名的类破坏也不会有影响，除非你本地jdk的jar被改写。即可以有效的防止核心java api被篡改。</p><p>而既然知道了双亲委派机制的实现，那么想要破坏双亲委派机制就简单了。只需要自定义一个类加载器，重写其中的loadclass方法，使其不进行双亲委派机制。而如果我们要自定义一个类加载器而又不想破坏双亲委派机制，只需集成classloader然后重写findclass方法。</p><p>而在某些场景下，我们却需要去打破双亲委派机制，比如我下面将要提到的几种</p><h3 id="JNDI、JDBC等"><a href="#JNDI、JDBC等" class="headerlink" title="JNDI、JDBC等"></a>JNDI、JDBC等</h3><p>在我们通过API调用一些java的基类时，存在一种SPI机制。比如JDBC。在类加载时，会先加载驱动DriverManger类，该类由类加载器加载。因为java.sql.DriverManger类位于rt.jar下面，会被根类加载器加载。而在其加载时，会执行静态方法，静态方法会尝试加载classpath下的所有实现driver接口的类。但这些实现类基本由各大数据库厂商实现，如果根据双亲委派机制来执行时行不通的。因为第三方的类不能被根加载器加载。因此，在jdbc中引入了线程上下文加载器的方式破坏双亲委派机制。</p><h3 id="Tomcat"><a href="#Tomcat" class="headerlink" title="Tomcat"></a>Tomcat</h3><p>在tomcat中为了应用程序访问不同存储库中的类和资源，达到应用类之间隔离的目的，打破了双亲委派机制。即为给个容器单独提供一个WebAppClassLoader加载器（优先加载web应用自身的类，即优先由WebAppClassLoader加载，加载不到在由CommonClassLoader加载，这和双亲委派刚好相反）。</p><p>Tomcat整体类加载器结构如下：<br> <img src="/images/pasted-235.png" alt="upload successful"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前言：在说打破双亲委派机制的一些场景前，先聊一聊为什么需要双亲委派机制。&lt;/p&gt;
&lt;p&gt;在双亲委派机制中，父子类通过组合的方式聚合在一起。由应用类加载器开始到系统类加器。主要是这几步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在自身的loadclass方法中先检查类是否已经被加载过&lt;/l</summary>
      
    
    
    
    <category term="JVM" scheme="http://example.com/categories/JVM/"/>
    
    
    <category term="类加载机制" scheme="http://example.com/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
    
    <category term="双亲委派机制" scheme="http://example.com/tags/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>Spring编程式事务</title>
    <link href="http://example.com/2022/06/17/Spring%E7%BC%96%E7%A8%8B%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2022/06/17/Spring%E7%BC%96%E7%A8%8B%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2022-06-17T08:55:00.000Z</published>
    <updated>2022-06-17T12:43:17.962Z</updated>
    
    <content type="html"><![CDATA[<p>描述：今天在做项目实现活动领取功能模块时，考虑到在系统中，用户的领取次数表和领取活动表的后续开销问题，在设计时通过自研的分库分表db-router-Spring-boot-starter组件对该功能涉及的两张表进行了分库操作。即让不同uid的用户产生的领取活动信息和活动次数信息打到不同的数据库上，减轻数据库的压力。但在后续开发时，发现涉及到两张表的修改，而这里又用到了分库操作，对数据源进行了切换。导致常用的@trancation注解在这里并不适用。为此，去温习了一下编程式事务，用于解决此处的问题。在这里记录一下。</p><p>编程式事务主要有2种用法</p><ul><li>方式1：通过PlatformTransactionManager控制事务</li><li>方式2：通过TransactionTemplate控制事务</li></ul><h3 id="方式1：PlatformTransactionManager"><a href="#方式1：PlatformTransactionManager" class="headerlink" title="方式1：PlatformTransactionManager"></a>方式1：PlatformTransactionManager</h3><ol><li>定义事务管理器PlatformTransactionManager<br>（事务管理器相当于一个管理员，这个管理员就是用来帮你控制事务的，比如开启事务，提交事务，回滚事务等等。spring中使用PlatformTransactionManager这个接口来表示事务管理器，PlatformTransactionManager多个实现类，用来应对不同的环境<br>）</li></ol><ul><li><p>JpaTransactionManager：如果你用jpa来操作db，那么需要用这个管理器来帮你控制事务。</p></li><li><p>DataSourceTransactionManager：如果你用是指定数据源的方式，比如操作数据库用的是：JdbcTemplate、mybatis、ibatis，那么需要用这个管理器来帮你控制事务。</p></li><li><p>HibernateTransactionManager：如果你用hibernate来操作db，那么需要用这个管理器来帮你控制事务。</p></li><li><p>JtaTransactionManager：如果你用的是java中的jta来操作db，这种通常是分布式事务，此时需要用这种管理器来控制事务。<br><img src="/images/pasted-234.png" alt="upload successful"></p></li></ul><ol start="2"><li><p>定义事务属性TransactionDefinition：定义事务属性，比如事务隔离级别、事务超时时间、事务传播方式、是否是只读事务等等。spring中使用TransactionDefinition接口来表示事务的定义信息，有个子类比较常用：DefaultTransactionDefinition。</p></li><li><p>开启事务：调用事务管理器的getTransaction方法，即可以开启一个事务，这个方法会返回一个TransactionStatus表示事务状态的一个对象，通过TransactionStatus提供的一些方法可以用来控制事务的一些状态，比如事务最终是需要回滚还是需要提交。（执行了getTransaction后，spring内部会执行一些操作。将数据源datasource和connection映射起来放在了ThreadLocal中。通过resources这个ThreadLocal获取datasource其对应的connection对象）</p></li><li><p>执行业务操作：用同一个dataSource，而事务管理器开启事务的时候，会创建一个连接，将datasource和connection映射之后丢在了ThreadLocal中，而JdbcTemplate内部执行db操作的时候，也需要获取连接，JdbcTemplate会以自己内部的datasource去上面的threadlocal中找有没有关联的连接，如果有直接拿来用，若没找到将重新创建一个连接，而此时是可以找到的，那么JdbcTemplate就参与到spring的事务中了。</p></li><li><p>提交或回滚</p></li></ol><p>分析：</p><p>TransactionTemplate，主要有2个方法：</p><p>executeWithoutResult：无返回值场景</p><p>executeWithoutResult(Consumer<TransactionStatus> action)：没有返回值的，需传递一个Consumer对象，在accept方法中做业务操作</p><p>execute：有返回值场景</p><p><T> T execute(TransactionCallback<T> action)：有返回值的，需要传递一个TransactionCallback对象，在doInTransaction方法中做业务操作</p><p>  通过上面2个方法，事务管理器会自动提交事务或者回滚事务。</p><p>什么时候事务会回滚，有2种方式</p><p>方式1</p><p>在execute或者executeWithoutResult内部执行transactionStatus.setRollbackOnly();将事务状态标注为回滚状态，spring会自动让事务回滚</p><p>方式2</p><p>execute方法或者executeWithoutResult方法内部抛出任意异常即可回滚。</p><p>总结：平时我们用的最多的是声明式事务，声明式事务的底层还是使用上面这种方式来控制事务的，只不过对其进行了封装，让我们用起来更容易些。了解不同的方法有助于我们在不同的场景的应用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;描述：今天在做项目实现活动领取功能模块时，考虑到在系统中，用户的领取次数表和领取活动表的后续开销问题，在设计时通过自研的分库分表db-router-Spring-boot-starter组件对该功能涉及的两张表进行了分库操作。即让不同uid的用户产生的领取活动信息和活动次数</summary>
      
    
    
    
    <category term="Spring" scheme="http://example.com/categories/Spring/"/>
    
    
    <category term="事务" scheme="http://example.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
    <category term="Spring" scheme="http://example.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>误删数据库后除了跑路，还能怎么办？</title>
    <link href="http://example.com/2022/06/15/%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/"/>
    <id>http://example.com/2022/06/15/%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%EF%BC%8C%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/</id>
    <published>2022-06-15T14:23:00.000Z</published>
    <updated>2022-06-15T15:43:59.602Z</updated>
    
    <content type="html"><![CDATA[<p>传统的高可用架构是不能预防误删除数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。</p><p>为了找到解决误删数据库的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：</p><ol><li>使用delete语句误删数据行</li><li>使用drop table或者truncate table语句误删数据库</li><li>使用drop database语句误删数据库</li><li>使用rm命令误删整个MySQL实例</li></ol><h3 id="误删行"><a href="#误删行" class="headerlink" title="误删行"></a>误删行</h3><p>方案：使用delete语句误删了数据行，可以用Flashback工具通过闪回把数据恢复回来。</p><p>原理：修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row和binlog_row_image=FULL。</p><p>具体：</p><ol><li>对于insert语句，对应的binlog event类型是Write_rows event，把它改成Delete_rows event即可。</li><li>同理，对于delete语句，也是将Delete_rows event改为Write_rows event。</li><li>而如果是Update_rows的话,binlog里面记录了数据行修改前和修改后的值,对调这两行的位置即可。</li></ol><p>而对于误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。</p><p>当然恢复过程并不建议在主库上进行，而是恢复出一个备份，或者找一个从库作为临时库，在临时库上执行恢复操作，确认过数据无误后，在恢复回主库。（原因：一个在执行线上逻辑的主库，数据状态往往是有关联的。可能由于发现数据问题的实际晚了一点，就导致已经在之前误删的基础上，业务代码逻辑又继续修改了其他数据，如果这时进行数据恢复，未经确认，会导致出现对数据的二次破坏）</p><pre><code>    注意：不止要了解误删数据的事后处理方法，更重要的是做到事前预防。    建议：    1. 把sql_safe_updates参数设置成on，在delete或者update语句中写where，或者where条件不包含索引字段，这条语句就会报错。    2. 代码上线前，必须经过SQL审计</code></pre><h3 id="误删库-表"><a href="#误删库-表" class="headerlink" title="误删库/表"></a>误删库/表</h3><p>这种情况下，想要恢复数据就需要使用全量备份了，加增量日志的方式。这个方案要求线上定期的全量备份，并且实时备份binlog（因为对于drop/turncate table/database binlog记录的是statement格式，没法通过flasback进行恢复）</p><p>恢复数据的流程：</p><ol><li>取最近一次全量备份（假设是一天一备，上次备份是当天0点）</li><li>用备份恢复出一个临时库</li><li>从日志备份里面，取出凌晨0点之后的日志</li><li>把这些日志，除了误删除数据的语句外，全部应用到临时库</li></ol><p>说明：为了加速数据恢复，可以在mysqlbinlog加上-database，用来指定误删除表所在的库，但是这样还是不够快（1.误删表，不能指定解析一个表的日志；2.用mysqlbinlog解析出日志应用，应用日志的过程就只能是单线程）</p><p>误删库或表后，恢复数据的思路主要就是通过备份，再加上应用binlog的方式。最好把数据恢复功能做成自动化工具。</p><h3 id="延迟复制备库"><a href="#延迟复制备库" class="headerlink" title="延迟复制备库"></a>延迟复制备库</h3><p>延迟复制备库是一种特殊的备库，通过CHANGE MASTER TO_DELAY = N命令，可以指定这个备库持续保持主库有N秒的延迟。</p><h3 id="预防误删库表的方法"><a href="#预防误删库表的方法" class="headerlink" title="预防误删库表的方法"></a>预防误删库表的方法</h3><ul><li>账号分离，权限控制</li><li>制定操作规范</li><li>定期给开发进行培训</li><li>搭建延迟备库</li><li>做好sql审计</li><li>做好备份</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;传统的高可用架构是不能预防误删除数据的，因为主库的一个drop table命令，会通过binlog传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。&lt;/p&gt;
&lt;p&gt;为了找到解决误删数据库的更高效的方法，我们需要先对和MySQL相关的误删数据，做下分类：&lt;/p&gt;</summary>
      
    
    
    
    <category term="MySQL" scheme="http://example.com/categories/MySQL/"/>
    
    
    <category term="MySQL" scheme="http://example.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>关于ZAB协议</title>
    <link href="http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EZAB%E5%8D%8F%E8%AE%AE/"/>
    <id>http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EZAB%E5%8D%8F%E8%AE%AE/</id>
    <published>2022-05-25T14:02:00.000Z</published>
    <updated>2022-05-25T14:19:02.540Z</updated>
    
    <content type="html"><![CDATA[<p>Zab 借鉴了 Paxos 算法，是特别为 Zookeeper 设计的支持崩溃恢复的原子广播协议。基于该协议，Zookeeper 设计为只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader 客户端将数据同步到其他 Follower 节点。Zookeeper 只有一个 Leader 可以发起提案</p><p>Zab协议包括两种基本的模式：消息广播、崩溃恢复。</p><h3 id="消息广播"><a href="#消息广播" class="headerlink" title="消息广播"></a>消息广播</h3><p>ZAB协议针对事务请求的处理过程类似于一个两阶段提交过程</p><p>（1）广播事务阶段</p><p>（2）广播提交操作<br>这两阶段提交模型如下，有可能因为Leader宕机带来数据不一致，比如</p><p>（1） Leader 发 起 一 个 事 务Proposal1 后 就 宕 机 ， Follower 都 没有Proposal1 </p><p>（2）Leader收到半数ACK宕 机，没来得及向Follower发送Commit<br>怎么解决呢？ZAB引入了崩溃恢复模式。</p><p> <img src="/images/pasted-231.png" alt="upload successful"></p><p>（1）客户端发起一个写操作请求。 </p><p>（2）Leader服务器将客户端的请求转化为事务Proposal 提案，同时为每个Proposal 分配一个全局的ID，即zxid。 </p><p>（3）Leader服务器为每个Follower服务器分配一个单独的队列，然后将需要广播的 Proposal依次放到队列中去，并且根据FIFO策略进行消息发送。 </p><p>（4）Follower接收到Proposal后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向Leader反馈一个Ack响应消息。 </p><p>（5）Leader接收到超过半数以上Follower的Ack响应消息后，即认为消息发送成功，可以发送commit消息。 </p><p>（6）Leader向所有Follower广播commit消息，同时自身也会完成事务提交。Follower 接收到commit消息后，会将上一条事务提交。 </p><p>（7）Zookeeper采用Zab协议的核心，就是只要有一台服务器提交了Proposal，就要确保所有的服务器最终都能正确提交Proposal。</p><h3 id="崩溃恢复——异常假设"><a href="#崩溃恢复——异常假设" class="headerlink" title="崩溃恢复——异常假设"></a>崩溃恢复——异常假设</h3><p> 一旦Leader服务器出现崩溃或者由于网络原因导致Leader服务器失去了与过半 Follower的联系，那么就会进入崩溃恢复模式。</p><p> <img src="/images/pasted-232.png" alt="upload successful"></p><p> 假设两种服务器异常情况</p><ol><li>假设一个事务在Leader提出之后，Leader挂了</li><li>一个事务在Leader上提交了，并且过半的Follower都响应ACK了，但是Leader在Commit消息发出之前挂了。</li></ol><p> Zab协议崩溃恢复要满足以下两个要求</p><p> 1、 确保已经被Leader提交的提案Proposal，必须最终被所有的Follower服务器提交。 （已经产生的提案，Follower必须执行） </p><p> 2、 确保丢弃已经被Leader提出的，但是没有被提交的Proposal。（丢弃胎死腹中的提案）</p><p> 崩溃恢复主要包括两部分：Leader选举和数据恢复。</p><h3 id="崩溃恢复—Leader选举"><a href="#崩溃恢复—Leader选举" class="headerlink" title="崩溃恢复—Leader选举"></a>崩溃恢复—Leader选举</h3><p> <img src="/images/pasted-233.png" alt="upload successful"></p><p>Leader选举：根据上述要求，Zab协议需要保证选举出来的Leader需要满足以下条件：</p><p>（1）新选举出来的Leader不能包含未提交的Proposal。即新Leader必须都是已经提交了Proposal的Follower服务器节点。</p><p>（2）新选举的Leader节点中含有最大的zxid。这样做的好处是可以避免Leader服务器检查Proposal的提交和丢弃工作。</p><h3 id="崩溃恢复——数据恢复"><a href="#崩溃恢复——数据恢复" class="headerlink" title="崩溃恢复——数据恢复"></a>崩溃恢复——数据恢复</h3><p>Zab如何数据同步： </p><p>（1）完成Leader选举后，在正式开始工作之前（接收事务请求，然后提出新的Proposal），Leader服务器会首先确认事务日志中的所有的Proposal 是否已经被集群中过半的服务器Commit。</p><p>（2）Leader服务器需要确保所有的Follower服务器能够接收到每一条事务的Proposal，并且能将所有已经提交的事务Proposal应用到内存数据中。等到Follower将所有尚未同步的事务Proposal都从Leader服务器上同步过，并且应用到内存数据中以后，<br>Leader才会把该Follower加入到真正可用的Follower列表中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Zab 借鉴了 Paxos 算法，是特别为 Zookeeper 设计的支持崩溃恢复的原子广播协议。基于该协议，Zookeeper 设计为只有一台客户端（Leader）负责处理外部的写事务请求，然后Leader 客户端将数据同步到其他 Follower 节点。Zookeepe</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="ZAB协议" scheme="http://example.com/tags/ZAB%E5%8D%8F%E8%AE%AE/"/>
    
    <category term="数据一致性" scheme="http://example.com/tags/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>关于Paxos算法</title>
    <link href="http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EPaxos%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2022/05/25/%E5%85%B3%E4%BA%8EPaxos%E7%AE%97%E6%B3%95/</id>
    <published>2022-05-25T13:38:00.000Z</published>
    <updated>2022-05-25T13:59:20.676Z</updated>
    
    <content type="html"><![CDATA[<p>Paxos算法是一种基于消息传递且具有高度容错特性的一致性算法。其通常用于快速正确的在一个分布式系统中对某个数据值达成一致，并且保证无论发送任何异常都不会破坏整个系统的一致性。</p><p> <img src="/images/pasted-226.png" alt="upload successful"></p><p> 在一个Paxos系统中，首先将所有节点划分为Proposer（提议者）、Acceptor（接受者）和Learner（学习者）</p><pre><code>     注意：每个节点可以身兼数职    </code></pre><p>一个完整的Paxos算法流程分为三个阶段</p><ol><li><p>Prepare准备阶段</p><ol><li>Proposer向多个Acceptor发出Propose请求Promise（承诺）</li><li>Acceptor针对收到的Propose请求进行Promise（承诺）</li></ol></li><li><p>Accept接受阶段</p><ol><li>Proposer收到多数Acceptor承诺的Promise后，向Acceptor发出Propose请求</li><li>Acceptor针对收到的Propose请求进行Accept处理</li></ol></li><li><p>Learn学习阶段</p><ol><li>Proposer将形成的决议发送给所有Learners</li></ol></li></ol><p> <img src="/images/pasted-227.png" alt="upload successful"></p><p> 1、 Prepare: Proposer生成全局唯一且递增的Proposal ID，向所有Acceptor发送Propose请求，这里无需携带提案内容，只携带Proposal ID即可。</p><p> 2、 Promise: Acceptor收到Propose请求后，做出“两个承诺，一个应答”。<br>    - 不再接受Proposal ID小于等于（注意：这里是&lt;= ）当前请求的Propose请求。<br>    - 不再接受Proposal ID小于（注意：这里是&lt; ）当前请求的Accept请求。<br>    - 不违背以前做出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。</p><p>3、 Propose: Proposer收到多数Acceptor的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptor发送Propose请求。</p><p>4、 Accept: Acceptor收到Propose请求后，在不违背自己之前做出的承诺下，接受并持久化当前Proposal ID和提案Value。</p><p>5、 Learn: Proposer收到多数Acceptor的Accept后，决议形成，将形成的决议发送给所有Learner。</p><p>下面举例以说明：</p><ol><li>情况1：</li></ol><p> <img src="/images/pasted-228.png" alt="upload successful"></p><ul><li>有A1, A2, A3, A4, A5 5位议员，就税率问题进行决议。</li><li>A1发起1号Proposal的Propose，等待Promise承诺； </li><li>A2-A5回应Promise； </li><li>A1在收到两份回复时就会发起税率10%的Proposal； </li><li>A2-A5回应Accept； </li><li>通过Proposal，税率10%。</li></ul><ol start="2"><li>情况2：</li></ol><p> <img src="/images/pasted-229.png" alt="upload successful"><br>     - 现在我们假设在A1提出提案的同时, A5决定将税率定为20%<br>     - A2承诺A1，A4承诺A5，A3行为成为关键<br>     - 情况1：A3先收到A1消息，承诺A1。<br>     - A1发起Proposal（1，10%），A2，A3接受。<br>     - 之后A3又收到A5消息，回复A1：（1，10%），并承诺A5<br>     - A5发起Proposal（2，20%），A3，A4接受。之后A1，A5同时广播决议。</p><pre><code>    由此可见Paxos 算法缺陷：在网络复杂的情况下，一个应用 Paxos 算法的分布式系统，可能很久无法收敛，甚至陷入活锁的情况。</code></pre><ol start="3"><li>情况3：</li></ol><p> <img src="/images/pasted-230.png" alt="upload successful"></p><pre><code> - 现在我们假设在A1提出提案的同时, A5决定将税率定为20% - A1，A5同时发起Propose（序号分别为1，2） - A2承诺A1，A4承诺A5，A3行为成为关键 - 情况2：A3先收到A1消息，承诺A1。之后立刻收到A5消息，承诺A5。 - A1发起Proposal（1，10%），无足够响应，A1重新Propose （序号3），A3再次承诺A1。 - A5发起Proposal（2，20%），无足够相应。A5重新Propose （序号4），A3再次承诺A5。</code></pre><p> 造成这种情况的原因是系统中有一个以上的 Proposer，多个 Proposers 相互争夺 Acceptor，造成迟迟无法达成一致的情况。针对这种情况，一种改进的 Paxos 算法被提出：从系统中选出一个节点作为 Leader，只有 Leader 能够发起提案。这样，一次 Paxos 流程中只有一个Proposer，不会出现活锁的情况，此时只会出现例子中第一种情况。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Paxos算法是一种基于消息传递且具有高度容错特性的一致性算法。其通常用于快速正确的在一个分布式系统中对某个数据值达成一致，并且保证无论发送任何异常都不会破坏整个系统的一致性。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/images/pasted-226.png&quot; alt=&quot;u</summary>
      
    
    
    
    <category term="分布式" scheme="http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="Paxos" scheme="http://example.com/tags/Paxos/"/>
    
    <category term="一致性算法" scheme="http://example.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper选举机制</title>
    <link href="http://example.com/2022/05/25/Zookeeper%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/"/>
    <id>http://example.com/2022/05/25/Zookeeper%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/</id>
    <published>2022-05-25T12:24:00.000Z</published>
    <updated>2022-05-25T12:40:27.471Z</updated>
    
    <content type="html"><![CDATA[<p>在了解Zookeeper的选举机制之前，首先需要了解</p><ul><li>SID(服务器ID，用于唯一标识一台Zookeeper集群中的机器，每台机器不能重复，和myid一致)</li><li>ZXID（事务ID。用来标识一次服务器状态的变更。在某一时刻，集群中的每台机器的ZXID值不一定完全一致，这和Zookeeper服务器对于客户端“更新请求”的处理逻辑有关）</li><li>Epoch(每个Leader任期的代号。没有Leader时同一轮投票过程中的逻辑时钟是相同的。每投完一次票，这个数据会增加)</li></ul><p>了解上述三个参数之后，后续Zookeeper的选举机制便和其有关。关于其选举机制可以分为两种情况。</p><p>第一种情况是第一次启动集群时，Leader的选举是根据其myid的大小进行选举的。</p><pre><code>    例如：目前有一个五台Zookeeper的集群。当启动id为1的Zookeeper时，它投自己一票。此时不满足Leader成立的条件。票数半数以上。因此进入looking状态。然后id为2的服务器启动，id1和id2的服务器都投自己一票，然后交换选票信息。此时服务器1发现服务器2的id比自己大，因此服务器1转投服务器2一票。服务器1只有0票，而服务器2有2票。但此时还是不满足半数以上，因此两者都进入looking状态。然后服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING；服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为 1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING；服务器5启动，同4一样当小弟。    </code></pre><p>而第二种情况是非第一次启动，而是在集群运行中，Leader宕机了，需要重新选举Leader。</p><pre><code>    例如：假设ZooKeeper由5台服务器组成，SID分别为1、2、3、4、5，ZXID分别为8、8、8、7、7，并且此时SID为3的服务器是Leader。某一时刻，3和5服务器出现故障，因此开始进行Leader选举。</code></pre><p> <img src="/images/pasted-225.png" alt="upload successful"></p><p> 选举Leader规则： ①EPOCH大的直接胜出 ②EPOCH相同，事务id大的胜出 ③事务id相同，服务器id大的胜出</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在了解Zookeeper的选举机制之前，首先需要了解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SID(服务器ID，用于唯一标识一台Zookeeper集群中的机器，每台机器不能重复，和myid一致)&lt;/li&gt;
&lt;li&gt;ZXID（事务ID。用来标识一次服务器状态的变更。在某一时刻，集群中的每</summary>
      
    
    
    
    <category term="Zookeeper" scheme="http://example.com/categories/Zookeeper/"/>
    
    
    <category term="Zookeeper" scheme="http://example.com/tags/Zookeeper/"/>
    
    <category term="选举机制" scheme="http://example.com/tags/%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>为什么要使用泛型程序设计？</title>
    <link href="http://example.com/2022/05/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%EF%BC%9F/"/>
    <id>http://example.com/2022/05/15/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B3%9B%E5%9E%8B%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%EF%BC%9F/</id>
    <published>2022-05-15T13:49:00.000Z</published>
    <updated>2022-05-18T11:13:31.973Z</updated>
    
    <content type="html"><![CDATA[<p>最近一直忙于编译原理的学习，难得空闲下来，重新巩固了一下泛型的知识。在此小记一下。</p><p>泛型程序设计意味着编写的代码可以被很多不同类型的对象重用</p><h2 id="泛型类"><a href="#泛型类" class="headerlink" title="泛型类"></a>泛型类</h2><p>在java中增加泛型类前，泛型程序设计时通过继承等方式实现的。例如：ArrayList维护一个Object数组的引用。 这种方式存在着两个问题：</p><ol><li>当获取一个值时，必须进行强制类型转换。</li><li>没有进行任何检测，可以向其中添加任何类的对象。</li></ol><p>因此，对于调用，编译和运行都不会出错。但在某些情况下进行了错误的强制类型转换使用。就会报错。</p><p>对此，泛型提供了更好的解决方案：类型参数。这不仅使得代码更具可读性，也使得代码更加安全。因为编译器可以根据这个信息推断出get时的类型，不需要进行强制类型转换。在编译期间检查出类型错误，而不是在运行时才检测出。</p><p>一个泛型类就是具有一个或多个类型变量的类。（使用大写形式，且比较短。在java中，E表示集合类型，K和V则是键值对，T表示任意类型）</p><h2 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h2><p>泛型方法的类型变量放在修饰符后，返回值前面。泛型方法可以定义在普通类中，也可以定义在泛型类中。</p><p>当调用一个泛型方法时，在方法名前的尖括号中放入具体的类型。当然在大多数情况下，编译器可以推导出类型，意味着我们可以省去。（在某些情况下，编译器无法推导出，此时需要指明）</p><h2 id="类型变量的限定"><a href="#类型变量的限定" class="headerlink" title="类型变量的限定"></a>类型变量的限定</h2><p>有时候类或方法需要对类型变量加以约束，&lt; T extends Object &gt; T</p><p>当做出这样的限定后，泛型的变量类型便被约束了。当然一个类型变量或通配符可以有多个限定，只需要用&amp;隔开即可。&lt; T extends Object1 &amp; Object2 &gt; T<br>值得注意的是，在java中可以根据需要拥有多个接口超类型，但限定中至多有一个类。如果用一个类作为限定，它必须位于限定列表的第一个</p><p>extends决定了泛型变量的上限。</p><h2 id="泛型代码和虚拟机"><a href="#泛型代码和虚拟机" class="headerlink" title="泛型代码和虚拟机"></a>泛型代码和虚拟机</h2><p>虚拟机没有泛型类对象，所有对象都是属于普通对象。</p><ul><li><p>类型擦除：无论何时定义一个泛型类型，都自动提供了一个相应的原始类型。原始类型的名字就是删去类型参数后的泛型类型名。擦除类型变量，并替换为限定类型类型。（无限定的变量用Object）</p></li><li><p>翻译泛型表达式：当程序调用泛型方法时，如果擦除返回类型，编译器会插入强制类型转换。</p></li><li><p>翻译泛型方法：类型擦除也会出现在泛型方法中，只留下限定类型。但这可能会导致类型擦除和多态发生冲突。</p></li></ul><h2 id="约束与局限性"><a href="#约束与局限性" class="headerlink" title="约束与局限性"></a>约束与局限性</h2><ul><li><p>不能用基本数据类型实例化类型参数，即不能有&lt; double &gt;，但可以有&lt; Double &gt;,原因是类型擦除。</p></li><li><p>运行时类型查询只适用于原始类型，而不适用于泛型类型。当试图查询一个对象是否属于某个泛型类型时，倘若使用instanceof会得到一个编译器错误。同样的道理，getClass方法总是返回原始类型。</p></li><li><p>不能创建参数化类型的数组，例如：Pair&lt; String &gt;[] table = new Pair&lt; String &gt; [10];类型擦除之后，table类型时Pair[],，可以把它转化为Object[],数组会记住其元素类型，如果试图存其他类型，则会报错。不过对于泛型，这种机制会使之无效。不过仍会导致一个类型错误。因此，不能创建参数化类型的数组。当然可以声明通配类型的数组，然后进行类型转换。</p></li><li><p>不能构造泛型数组，因为数组本身也有类型，用来监控存在虚拟机中的数组。</p></li><li><p>泛型类的静态上下文中类型变量无效：不能在静态域或方法中使用类型变量。</p></li><li><p>不能抛出或捕获泛型类的实例：可以消除对受查异常的检查</p></li><li><p>注意擦除后的冲突：要想支持擦除的转换，就需要强制限制一个类或类型变量不能同时成为两个接口类型的子类，而这两个接口时同一接口的不同参数。</p></li></ul><h2 id="泛型类型的继承规则"><a href="#泛型类型的继承规则" class="headerlink" title="泛型类型的继承规则"></a>泛型类型的继承规则</h2><ul><li>无论S和T有什么关系，通常calssName &lt; S &gt; 和 calssName &lt; T &gt; 没有任何关系</li></ul><p>待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近一直忙于编译原理的学习，难得空闲下来，重新巩固了一下泛型的知识。在此小记一下。&lt;/p&gt;
&lt;p&gt;泛型程序设计意味着编写的代码可以被很多不同类型的对象重用&lt;/p&gt;
&lt;h2 id=&quot;泛型类&quot;&gt;&lt;a href=&quot;#泛型类&quot; class=&quot;headerlink&quot; title=&quot;泛</summary>
      
    
    
    
    <category term="Java" scheme="http://example.com/categories/Java/"/>
    
    
    <category term="Java" scheme="http://example.com/tags/Java/"/>
    
    <category term="泛型" scheme="http://example.com/tags/%E6%B3%9B%E5%9E%8B/"/>
    
  </entry>
  
</feed>
