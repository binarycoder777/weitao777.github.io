{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2022-01-05T06:15:01.841Z","updated":"2022-01-05T06:10:01.885Z","comments":false,"path":"/404.html","permalink":"http://example.com/404.html","excerpt":"","text":""},{"title":"书单","date":"2022-03-05T01:29:35.000Z","updated":"2022-03-05T01:33:11.946Z","comments":false,"path":"books/index.html","permalink":"http://example.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-01-05T08:23:46.960Z","updated":"2022-01-05T06:10:01.887Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-03-05T01:29:53.000Z","updated":"2022-03-05T01:31:10.414Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"对待工作认真负责，富有上进心，热爱学习，喜欢专研新技术，能很快掌握新技术。为人诚恳乐观，心里素质较好，抗压能力较强， 可以适应较强的压力。具备模块设计及开发能力，能独立完成开发任务。此外也喜欢阅读相关技术的书籍文档。平时编码严格遵守相关 编码规范。"},{"title":"Repositories","date":"2022-01-05T06:15:01.947Z","updated":"2022-01-05T06:10:01.888Z","comments":false,"path":"repository/index.html","permalink":"http://example.com/repository/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2022-01-05T08:22:49.166Z","updated":"2022-01-05T06:10:01.888Z","comments":true,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-01-05T08:24:21.310Z","updated":"2022-01-05T06:10:01.888Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Elasticsearch分片原理","slug":"Elasticsearch分片原理","date":"2022-03-14T07:09:00.000Z","updated":"2022-03-14T08:17:41.076Z","comments":true,"path":"2022/03/14/Elasticsearch分片原理/","link":"","permalink":"http://example.com/2022/03/14/Elasticsearch%E5%88%86%E7%89%87%E5%8E%9F%E7%90%86/","excerpt":"","text":"倒排索引分片是 Elasticsearch 最小的工作单元。一个分片是一个Lucene索引。 而索引采用的是一种称为倒排索引的结构，它适用于快速的全文搜索。 见其名，知其意，有倒排索引，肯定会对应有正向索引。正向索引（forward index），反向索引（inverted index）更熟悉的名字是倒排索引。 所谓的正向索引，就是搜索引擎会将待搜索的文件都对应一个文件 ID，搜索时将这个ID 和搜索关键字进行对应，形成 K-V 对，然后对关键字进行统计计数。 但是互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。 一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。 例如，假设我们有两个文档，每个文档的 content 域包含如下内容：  The quick brown fox jumped over the lazy dog  Quick brown foxes leap over lazy dogs in summer 为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的词（我们称它为词条或 tokens ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。 现在，如果我们想搜索 quick brown ，我们只需要查找包含每个词条的文档： 两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单相似性算法，那么我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。 但是，我们目前的倒排索引有一些问题：  Quick 和 quick 以独立的词条出现，然而用户可能认为它们是相同的词。  fox 和 foxes 非常相似, 就像 dog 和 dogs ；他们有相同的词根。  jumped 和 leap, 尽管没有相同的词根，但他们的意思很相近。他们是同义词。 使用前面的索引搜索 +Quick +fox 不会得到任何匹配文档。（记住，+ 前缀表明这个词必须存在。）只有同时出现 Quick 和 fox 的文档才满足这个查询条件，但是第一个文档包含quick fox ，第二个文档包含 Quick foxes 。 我们的用户可以合理的期望两个文档与查询匹配。我们可以做的更好。如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。 例如：  Quick 可以小写化为 quick 。  foxes 可以 词干提取 –变为词根的格式– 为 fox 。类似的， dogs 可以为提取为 dog 。  jumped 和 leap 是同义词，可以索引为相同的单词 jump 。 这还远远不够。我们搜索 +Quick +fox 仍然 会失败，因为在我们的索引中，已经没有 Quick 了。但是，如果我们对搜索的字符串使用与 content 域相同的标准化规则，会变成查询+quick +fox，这样两个文档都会匹配！分词和标准化的过程称为分析. 这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。 文档搜索早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检到。 倒排索引被写入磁盘后是 不可改变 的:它永远不会修改。 不变性有重要的价值： 不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。 其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。 写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。 当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档 可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。 动态更新索引如何在保留不变性的前提下实现倒排索引的更新？ 答案是: 用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到，从最早的开始查询完后再对结果进行合并。 Elasticsearch 基于 Lucene, 这个 java 库引入了按段搜索的概念。 每一段本身都是一个倒排索引， 但索引在 Lucene 中除表示所有段的集合外，还增加了提交点的概念 — 一个列出了所有已知段的文件。 按段搜索会以如下流程执行： 新文档被收集到内存索引缓存 不时地, 缓存被提交 (1) 一个新的段—一个追加的倒排索引—被写入磁盘。 (2) 一个新的包含新段名字的 提交点 被写入磁盘 (3) 磁盘进行 同步 — 所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件 新的段被开启，让它包含的文档可见以被搜索 内存缓存被清空，等待接收新的文档 当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。 这种方式可以用相对较低的成本将新文档添加到索引。 段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。 取而代之的是，每个提交点会包含一个 .del 文件，文件中会列出这些被删除文档的段信息。 当一个文档被 “删除” 时，它实际上只是在 .del 文件中被 标记 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。 近实时搜索随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。磁盘在这里成为了瓶颈。提（Commiting）一个新的段到磁盘需要一个 fsync 来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。 但是 fsync 操作代价很大; 如果每次索引一个文档都去执行一次的话会造成很大的性能问题。 我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着 fsync 要从整个过程中被移除。在 Elasticsearch 和磁盘之间是文件系统缓存。 像之前描述的一样， 在内存索引缓冲区中的文档会被写入到一个新的段中。 但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。 Lucene 允许新段被写入和打开—使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。 在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是 近 实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。 这些行为可能会对新用户造成困惑: 他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用 refresh API 执行一次手动刷新: /users/_refresh 尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候， 手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。 相反，你的应用需要意识到 Elasticsearch 的近实时的性质，并接受它的不足。 并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件，你可能想优化索引速度而不是近实时搜索， 可以通过设置 refresh_interval ， 降低每个索引的刷新频率 refresh_interval 可以在既存索引上进行动态更新。 在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来 持久变更如果没有用 fsync 把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证 Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。在 动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。 即使通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办？我们也不希望丢失掉这些数据。Elasticsearch 增加了一个 translog ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录 一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog 刷新（refresh）使分片每秒被刷新（refresh）一次： 这些在内存缓冲区的文档被写入到一个新的段中，且没有进行 fsync 操作。 这个段被打开，使其可被搜索 内存缓冲区被清空 这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志 每隔一段时间—例如 translog 变得越来越大—索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行 所有在内存缓冲区的文档都被写入一个新的段。 缓冲区被清空。 一个提交点被写入硬盘。 文件系统缓存通过 fsync 被刷新（flush）。 老的 translog 被删除。 translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。 translog 也被用来提供实时 CRUD 。当你试着通过 ID 查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。 执行一个提交并且截断 translog 的行为在 Elasticsearch 被称作一次 flush分片每 30 分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新 你很少需要自己手动执行 flush 操作；通常情况下，自动刷新就足够了。这就是说，在重启节点或关闭索引之前执行 flush 有益于你的索引。当 Elasticsearch 尝试恢复或重新打开一个索引， 它需要重放 translog 中所有的操作，所以如果日志越短，恢复越快。 translog 的目的是保证操作不会丢失，在文件被 fsync 到磁盘前，被写入的文件在重启之后就会丢失。默认 translog 是每 5 秒被 fsync 刷新到硬盘， 或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。最终， 基本上，这意味着在整个请求被 fsync 到主分片和复制分片的 translog 之前，你的客户端不会得到一个 200 OK 响应。 在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小（特别是 bulk 导入，它在一次请求中平摊了大量文档的开销）。但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每 5 秒执行一次 fsync 。如果你决定使用异步 translog 的话，你需要 保证 在发生 crash 时，丢失掉 sync_interval 时间段的数据也无所谓。请在决定前知晓这个特性。如果你不确定这个行为的后果，最好是使用默认的参数（ “index.translog.durability”: “request” ）来避免数据丢失。 段合并由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。 每一个段都会消耗文件句柄、内存和 cpu 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。Elasticsearch 通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。启动段合并不需要你做任何事。进行索引和搜索时会自动进行。 当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。 合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。 一旦合并结束，老的段被删除 新的段被刷新（flush）到了磁盘。 ** 写入一个包含新段且排除旧的和较小的段的新提交点。 新的段被打开用来搜索。 老的段被删除。 合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/categories/Elasticsearch/"}],"tags":[{"name":"分片","slug":"分片","permalink":"http://example.com/tags/%E5%88%86%E7%89%87/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/tags/Elasticsearch/"}],"author":"John Doe"},{"title":"Elasticsearch分片控制","slug":"Elasticsearch分片控制","date":"2022-03-14T06:55:00.000Z","updated":"2022-03-14T07:09:39.594Z","comments":true,"path":"2022/03/14/Elasticsearch分片控制/","link":"","permalink":"http://example.com/2022/03/14/Elasticsearch%E5%88%86%E7%89%87%E6%8E%A7%E5%88%B6/","excerpt":"","text":"每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。 写流程： 新建、索引和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片 新建，索引和删除文档所需要的步骤顺序： 客户端向 Node 1 发送新建、索引或者删除请求。 节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。 Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。 在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。有一些可选的请求参数允许您影响这个过程，可能以数据安全为代价提升性能。 读流程：我们可以从主分片或者从其它任意副本分片检索文档。 从主分片或者副本分片检索文档的步骤顺序： 客户端向 Node 1 发送获取请求。 节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。 Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。在处理读取请求时，协调结点在每次请求的时候都会通过轮询所有的副本分片来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 一旦索引请求成功返回给用户，文档在主分片和副本分片都是可用的。 更新流程： 客户端向 Node 1 发送更新请求。 它将请求转发到主分片所在的 Node 3 。 Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。 如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。 注意：当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用改，导致得到损坏的文档。 多文档操作流程：mget 和 bulk API 的模式类似于单文档模式。区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成每个分片的多文档请求，并且将这些请求并行转发到每个参与节点。协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。 用单个 mget 请求取回多个文档所需的步骤顺序: 客户端向 Node 1 发送 mget 请求。 Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端 bulk API 按如下步骤顺序执行： 客户端向 Node 1 发送 bulk 请求。 Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。 主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/categories/Elasticsearch/"}],"tags":[{"name":"分片","slug":"分片","permalink":"http://example.com/tags/%E5%88%86%E7%89%87/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/tags/Elasticsearch/"}],"author":"John Doe"},{"title":"Elasticsearch路由计算","slug":"Elasticsearch路由计算","date":"2022-03-14T06:53:00.000Z","updated":"2022-03-14T06:55:12.233Z","comments":true,"path":"2022/03/14/Elasticsearch路由计算/","link":"","permalink":"http://example.com/2022/03/14/Elasticsearch%E8%B7%AF%E7%94%B1%E8%AE%A1%E7%AE%97/","excerpt":"","text":"当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的： routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。 这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。所有的文档 API（ get 、 index 、 delete 、 bulk 、 update 以及 mget ）都接受一个叫做 routing 的路由参数 ，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/categories/Elasticsearch/"}],"tags":[{"name":"routing","slug":"routing","permalink":"http://example.com/tags/routing/"}],"author":"John Doe"},{"title":"Elasticsearch的基本概念","slug":"Elasticsearch的基本概念","date":"2022-03-14T06:09:00.000Z","updated":"2022-03-14T06:23:48.299Z","comments":true,"path":"2022/03/14/Elasticsearch的基本概念/","link":"","permalink":"http://example.com/2022/03/14/Elasticsearch%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"","text":"Elasticsearch 索引的精髓：一切设计都是为了提高搜索的性能。 Elasticsearch的索引就是一个拥有相似特征的文档的集合。一个索引由一个名字来标识（必须全是小写字母）。当我们要对这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。 在一个索引中，你可以定义一种或多种类型。这个类型是索引的一个逻辑分区/分类。但在7.x已经默认不再支持自定义索引类型。 文档（Document）：一个文档是一个可被索引的基础信息单元，也就是一条数据。 字段（Field）：相当于数据表的字段，对文档数据根据不同属性进行的分类标识。 映射（Mapping）：mapping 是处理数据的方式和规则方面做一些限制，如：某个字段的数据类型、默认值、分析器、是否被索引等等。这些都是映射里面可以设置的，其它就是处理 ES 里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。 分片（Shards）：一个索引可以存储超出单个节点硬件限制的大量数据。比如，一个具有 10 亿文档数据的索引占据 1TB 的磁盘空间，而任一节点都可能没有这样大的磁盘空间。或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch 提供了将索引划分成多份的能力，每一份就称之为分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。 分片很重要，主要有两方面的原因： 1）允许你水平分割 / 扩展你的内容容量。 2）允许你在分片之上进行分布式的、并行的操作，进而提高性能/吞吐量。 至于一个分片怎样分布，它的文档怎样聚合和搜索请求，是完全由 Elasticsearch 管理的，对于作为用户的你来说，这些都是透明的，无需过分关心。 被混淆的概念是，一个 Lucene 索引 我们在 Elasticsearch 称作 分片 。 一个Elasticsearch 索引 是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片(Lucene 索引)，然后合并每个分片的结果到一个全局的结果集。（即Elasticsearch 索引 是分片的集合，Lucene 索引在Elasticsearch 称作 分片） 副本（Replicas）：在一个网络 / 云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch 允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片(副本)。 复制分片之所以重要，有两个主要原因：  在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。  扩展你的搜索量/吞吐量，因为搜索可以在所有的副本上并行运行。 总之，每个索引可以被分成多个分片。一个索引也可以被复制 0 次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。默认情况下，Elasticsearch 中的每个索引被分片 1 个主分片和 1 个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有 1 个主分片和另外 1 个复制分片（1 个完全拷贝），这样的话每个索引总共就有 2 个分片，我们需要根据索引需要确定分片个数。 分配（Allocation）：将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。这个过程是由 master 节点完成的。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/categories/Elasticsearch/"}],"tags":[{"name":"基础概念","slug":"基础概念","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/tags/Elasticsearch/"}],"author":"John Doe"},{"title":"时间轮算法","slug":"时间轮算法","date":"2022-03-13T05:08:00.000Z","updated":"2022-03-13T05:18:08.769Z","comments":true,"path":"2022/03/13/时间轮算法/","link":"","permalink":"http://example.com/2022/03/13/%E6%97%B6%E9%97%B4%E8%BD%AE%E7%AE%97%E6%B3%95/","excerpt":"","text":"时间轮就是和手表时钟很相似的存在。时间轮用环形数组实现，数组的每个元素可以称为槽，和 HashMap一样称呼。 槽的内部用双向链表存着待执行的任务，添加和删除的链表操作时间复杂度都是 O(1)，槽位本身也指代时间精度，比如一秒扫一个槽，那么这个时间轮的最高精度就是 1 秒。 也就是说延迟 1.2 秒的任务和 1.5 秒的任务会被加入到同一个槽中，然后在 1 秒的时候遍历这个槽中的链表执行任务。 从图中可以看到此时指针指向的是第一个槽，一共有八个槽0~7，假设槽的时间单位为 1 秒，现在要加入一个延时 5 秒的任务，计算方式就是 5 % 8 + 1 = 6，即放在槽位为 6，下标为 5 的那个槽中。 更具体的就是拼到槽的双向链表的尾部。然后每秒指针顺时针移动一格，这样就扫到了下一格，遍历这格中的双向链表执行任务。然后再循环继续。 可以看到插入任务从计算槽位到插入链表，时间复杂度都是O(1)。那假设现在要加入一个50秒后执行的任务怎么办？这槽好像不够啊？难道要加槽嘛？和HashMap一样扩容？ 不是的，常见有两种方式，一种是通过增加轮次的概念。50 % 8 + 1 = 3，即应该放在槽位是 3，下标是2 的位置。然后 (50 - 1) / 8 = 6，即轮数记为 6。也就是说当循环 6 轮之后扫到下标的 2 的这个槽位会触发这个任务。Netty中HashedWheelTimer 使用的就是这种方式。 还有一种是通过多层次的时间轮，这个和我们的手表就更像了，像我们秒针走一圈，分针走一格，分针走一圈，时针走一格。 多层次时间轮就是这样实现的。假设上图就是第一层，那么第一层走了一圈，第二层就走一格，可以得知第二层的一格就是8秒，假设第二层也是 8 个槽，那么第二层走一圈，第三层走一格，可以得知第三层一格就是 64 秒。那么一格三层，每层8个槽，一共 24 个槽时间轮就可以处理最多延迟 512 秒的任务。 而多层次时间轮还会有降级的操作，假设一个任务延迟 500 秒执行，那么刚开始加进来肯定是放在第三层的，当时间过了 436 秒后，此时还需要 64 秒就会触发任务的执行，而此时相对而言它就是个延迟 64秒后的任务，因此它会被降低放在第二层中，第一层还放不下它。再过个 56 秒，相对而言它就是个延迟 8 秒后执行的任务，因此它会再被降级放在第一层中，等待执行。 降级是为了保证时间精度一致性Kafka内部用的就是多层次的时间轮算法。 Kafka 就利用了空间换时间的思想，通过 DelayQueue，来保存每个槽，通过每个槽的过期时间排序。这样拥有最早需要执行任务的槽会有优先获取。如果时候未到，那么 delayQueue.poll 就会阻塞着，这样就不会有空推进的情况发送。 总的来说Kafka用了多层次时间轮来实现，并且是按需创建时间轮，采用任务的绝对时间来判断延期，并且对于每个槽(槽内存放的也是任务的双向链表)都会维护一个过期时间，利用 DelayQueue 来对每个槽的过期时间排序，来进行时间的推进，防止空推进的存在。 每次推进都会更新 currentTime 为当前时间戳，当然做了点微调使得 currentTime 是 tickMs 的整数倍。并且每次推进都会把能降级的任务重新插入降级。 可以看到这里的 DelayQueue 的元素是每个槽，而不是任务，因此数量就少很多了，这应该是权衡了对于槽操作的延时队列的时间复杂度与空推进的影响。 总结： Timer、DelayQueue 和 ScheduledThreadPool，它们都是基于优先队列实现的，O(logn)的时间复杂度在任务数多的情况下频繁的入队出队对性能来说有损耗。因此适合于任务数不多的情况。 Timer 是单线程的会有阻塞的风险，并且对异常没有做处理，一个任务出错 Timer 就挂了。而ScheduledThreadPool 相比于 Timer 首先可以多线程来执行任务，并且线程池对异常做了处理，使得任务之间不会有影响。 并且 Timer和ScheduledThreadPool 可以周期性执行任务。 而 DelayQueue 就是个具有优先级的阻塞队列。 对比而言时间轮更适合任务数很大的延时场景，它的任务插入和删除时间复杂度都为O(1)。对于延迟超过时间轮所能表示的范围有两种处理方式，一是通过增加一个字段-轮数，Netty 就是这样实现的。二是多层次时间轮，Kakfa 是这样实现的。 相比而言 Netty 的实现会有空推进的问题，而 Kafka 采用 DelayQueue 以槽为单位，利用空间换时间的思想解决了空推进的问题。 可以看出延迟任务的实现都不是很精确的，并且或多或少都会有阻塞的情况，即使你异步执行，线程不够的情况下还是会阻塞。","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"Kafka","slug":"算法/Kafka","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/Kafka/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"时间轮","slug":"时间轮","permalink":"http://example.com/tags/%E6%97%B6%E9%97%B4%E8%BD%AE/"}],"author":"John Doe"},{"title":"延迟队列 DelayQueue","slug":"延迟队列-DelayQueue","date":"2022-03-13T05:05:00.000Z","updated":"2022-03-13T05:07:25.947Z","comments":true,"path":"2022/03/13/延迟队列-DelayQueue/","link":"","permalink":"http://example.com/2022/03/13/%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97-DelayQueue/","excerpt":"","text":"Java 中还有个延迟队列 DelayQueue，加入延迟队列的元素都必须实现 Delayed 接口。延迟队列内部是利用 PriorityQueue 实现的，所以还是利用优先队列！Delayed 接口继承了Comparable 因此优先队列是通过 delay 来排序的。 延迟队列是利用优先队列实现的，元素通过实现 Delayed 接口来返回延迟的时间。不过延迟队列就是个容器，需要其他线程来获取和执行任务。 对于 Timer 、ScheduledThreadPool 和 DelayQueue，总结的说下它们都是通过优先队列来获取最早需要执行的任务，因此插入和删除任务的时间复杂度都为O(logn)，并且 Timer 、ScheduledThreadPool 的周期性任务是通过重置任务的下一次执行时间来完成的。 问题就出在时间复杂度上，插入删除时间复杂度是O(logn)，那么假设频繁插入删除次数为 m，总的时间复杂度就是O(mlogn)，这种时间复杂度满足不了 Kafka 这类中间件对性能的要求，而时间轮算法的插入删除时间复杂度是O(1)。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"DelayQueue","slug":"DelayQueue","permalink":"http://example.com/tags/DelayQueue/"},{"name":"队列","slug":"队列","permalink":"http://example.com/tags/%E9%98%9F%E5%88%97/"}],"author":"John Doe"},{"title":"ScheduledThreadPoolExecutor，更多功能的Timer","slug":"ScheduledThreadPoolExecutor，更多功能的Timer","date":"2022-03-13T05:02:00.000Z","updated":"2022-03-13T05:05:25.870Z","comments":true,"path":"2022/03/13/ScheduledThreadPoolExecutor，更多功能的Timer/","link":"","permalink":"http://example.com/2022/03/13/ScheduledThreadPoolExecutor%EF%BC%8C%E6%9B%B4%E5%A4%9A%E5%8A%9F%E8%83%BD%E7%9A%84Timer/","excerpt":"","text":"jdk1.5 引入了 ScheduledThreadPoolExecutor，它是一个具有更多功能的 Timer 的替代品，允许多个服务线程。如果设置一个服务线程和 Timer 没啥差别。 从注释看出相对于 Timer ，可能就是单线程跑任务和多线程跑任务的区别。但ScheduledThreadPoolExecutor继承了 ThreadPoolExecutor，实现了 ScheduledExecutorService。可以定性操作就是正常线程池差不多了。 区别就在于两点，一个是 ScheduledFutureTask ，一个是 DelayedWorkQueue。其实 DelayedWorkQueue 就是优先队列，也是利用数组实现的小顶堆。而 ScheduledFutureTask 继承自 FutureTask 重写了 run 方法，实现了周期性任务的需求。 ScheduledThreadPoolExecutor 大致的流程和 Timer 差不多，也是维护一个优先队列，然后通过重写task 的 run 方法来实现周期性任务，主要差别在于能多线程运行任务，不会单线程阻塞。并且 Java 线程池的设定是 task 出错会把错误吃了，无声无息的。因此一个任务出错也不会影响之后的任务。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"ScheduledThreadPoolExecutor","slug":"ScheduledThreadPoolExecutor","permalink":"http://example.com/tags/ScheduledThreadPoolExecutor/"}],"author":"John Doe"},{"title":"JDK中的Timer","slug":"JDK中的Timer","date":"2022-03-13T04:57:00.000Z","updated":"2022-03-13T05:01:58.460Z","comments":true,"path":"2022/03/13/JDK中的Timer/","link":"","permalink":"http://example.com/2022/03/13/JDK%E4%B8%AD%E7%9A%84Timer/","excerpt":"","text":"java提供了延时操作的timer，里面由一个小根堆数组和执行线程构成。小根堆数组堆顶是当前最先需要执行的任务。执行线程通过不断轮询询问该任务（同系统当前时间做比对）是否需要执行。当需要执行时，看是否是周期性任务，是则将任务执行时间改到下一个周期，然后执行，不是则删除，执行任务。 可以看出 Timer 实际就是根据任务的执行时间维护了一个优先队列，并且起了一个线程不断地拉取任务执行。 有什么弊端呢？ 首先优先队列的插入和删除的时间复杂度是O(logn)，当数据量大的时候，频繁的入堆出堆性能有待考虑。 并且是单线程执行，那么如果一个任务执行的时间过久则会影响下一个任务的执行时间(当然你任务的run要是异步执行也行)。并且从代码可以看到对异常没有做什么处理，那么一个任务出错的时候会导致之后的任务都无法执行。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Timer","slug":"Timer","permalink":"http://example.com/tags/Timer/"},{"name":"JDK","slug":"JDK","permalink":"http://example.com/tags/JDK/"}],"author":"John Doe"},{"title":"I/O 多路复⽤：select/poll/epoll","slug":"I-O-多路复⽤：select-poll-epoll","date":"2022-03-12T11:22:00.000Z","updated":"2022-03-12T11:44:57.876Z","comments":true,"path":"2022/03/12/I-O-多路复⽤：select-poll-epoll/","link":"","permalink":"http://example.com/2022/03/12/I-O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E2%BD%A4%EF%BC%9Aselect-poll-epoll/","excerpt":"","text":"最基本的 Socket 模型：要想客户端和服务器能在⽹络中通信，那必须得使⽤ Socket 编程，它是进程间通信⾥⽐较特别的⽅式，特别之处在于它是可以跨主机间通信。创建 Socket 的时候，可以指定⽹络层使⽤的是 IPv4 还是 IPv6，传输层使⽤的是 TCP 还是 UDP。 服务端⾸先调⽤ socket() 函数，创建⽹络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调⽤bind() 函数，给这个 Socket 绑定⼀个 IP 地址和端⼝。 绑定端⼝的⽬的：当内核收到 TCP 报⽂，通过 TCP 头⾥⾯的端⼝号，来找到我们的应⽤程序，然后把数据传递给我们。 绑定 IP 地址的⽬的：⼀台机器是可以有多个⽹卡的，每个⽹卡都有对应的 IP 地址，当绑定⼀个⽹卡时，内核在收到该⽹卡上的包，才会发给我们； 绑定完 IP 地址和端⼝后，就可以调⽤ listen() 函数进⾏监听，此时对应 TCP 状态图中的 listen ，如果我们要判定服务器中⼀个⽹络程序有没有启动，可以通过 netstat 命令查看对应的端⼝号是否有被监听。 服务端进⼊了监听状态后，通过调⽤ accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。 客户端在创建好 Socket 后，调⽤ connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端⼝号，然后万众期待的 TCP 三次握⼿就开始了。 在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列： ⼀个是还没完全建⽴连接的队列，称为 TCP 半连接队列，这个队列都是没有完成三次握⼿的连接， 此时服务端处于 syn_rcvd 的状态；⼀个是⼀件建⽴连接的队列，称为 TCP 全连接队列，这个队列都是完成了三次握⼿的连接，此时服务端处于 established 状态； 当 TCP 全连接队列不为空后，服务端的 accept() 函数，就会从内核中的 TCP 全连接队列⾥拿出⼀个已经完成连接的 Socket 返回应⽤程序，后续数据传输都⽤这个 Socket。 （注意，监听的 Socket 和真正⽤来传数据的 Socket 是两个：⼀个叫作监听 Socket；⼀个叫作已连接 Socket；） 连接建⽴后，客户端和服务端就开始相互传输数据了，双⽅都可以通过 read() 和 write() 函数来读写数据。 基于 Linux ⼀切皆⽂件的理念，在内核中 Socket 也是以「⽂件」的形式存在的，也是有对应的⽂件描述符。 上面提到的TCP Socket 调⽤流程是最简单、最基本的，它基本只能⼀对⼀通信，因为使⽤的是同步阻塞的⽅式，当服务端在还没处理完⼀个客户端的⽹络 I/O 时，或者 读写操作发⽣阻塞时，其他客户端是⽆法与服务端连接的。可如果我们服务器只能服务⼀个客户，那这样就太浪费资源了，于是我们要改进这个⽹络 I/O 模型，以⽀持更多的客户端。 服务器作为服务⽅，通常会在本地固定监听⼀个端⼝，等待客户端的连接。因此服务器的本地 IP 和端⼝是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端⼝是会变化的，所以最⼤ TCP 连接数 = 客户端 IP 数×客户端端⼝数。 对于 IPv4，客户端的 IP 数最多为 2 的 32 次⽅，客户端的端⼝数最多为 2 的 16 次⽅，也就是服务端单机最⼤ TCP 连接数约为 2 的 48 次⽅。 这个理论值相当“丰满”，但是服务器肯定承载不了那么⼤的连接数，主要会受两个⽅⾯的限制： ⽂件描述符，Socket 实际上是⼀个⽂件，也就会对应⼀个⽂件描述符。在 Linux 下，单个进程打开的⽂件描述符数是有限制的，没有经过修改的值⼀般都是 1024，不过我们可以通过 ulimit 增⼤⽂件描述符的数⽬； 系统内存，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占⽤⼀定内存的； 基于最原始的阻塞⽹络 I/O， 如果服务器要⽀持多个客户端，其中⽐较传统的⽅式，就是使⽤多进程模型，也就是为每个客户端分配⼀个进程来处理请求。 服务器的主进程负责监听客户的连接，⼀旦与客户端连接完成，accept() 函数就会返回⼀个「已连接Socket」，这时就通过 fork() 函数创建⼀个⼦进程，实际上就把⽗进程所有相关的东⻄都复制⼀份，包括⽂件描述符、内存地址空间、程序计数器、执⾏的代码等。 这两个进程刚复制完的时候，⼏乎⼀摸⼀样。不过，会根据返回值来区分是⽗进程还是⼦进程，如果返回值是 0，则是⼦进程；如果返回值是其他的整数，就是⽗进程。 正因为⼦进程会复制⽗进程的⽂件描述符，于是就可以直接使⽤「已连接 Socket 」和客户端通信了，可以发现，⼦进程不需要关⼼「监听 Socket」，只需要关⼼「已连接 Socket」；⽗进程则相反，将客户服务交给⼦进程来处理，因此⽗进程不需要关⼼「已连接 Socket」，只需要关⼼「监听 Socket」。 另外，当「⼦进程」退出时，实际上内核⾥还会保留该进程的⼀些信息，也是会占⽤内存的，如果不做好“回收”⼯作，就会变成僵⼫进程，随着僵⼫进程越多，会慢慢耗尽我们的系统资源。 因此，⽗进程要“善后”好⾃⼰的孩⼦，怎么善后呢？那么有两种⽅式可以在⼦进程退出后回收资源，分别是调⽤ wait() 和 waitpid() 函数。 这种⽤多个进程来应付多个客户端的⽅式，在应对 100 个客户端还是可⾏的，但是当客户端数量⾼达⼀万时，肯定扛不住的，因为每产⽣⼀个进程，必会占据⼀定的系统资源，⽽且进程间上下⽂切换的“包袱”是很重的，性能会⼤打折扣。 进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。 既然进程间上下⽂切换的“包袱”很重，那我们就搞个⽐较轻量级的模型来应对多⽤户的请求 —— 多线程模型。 线程是运⾏在进程中的⼀个“逻辑流”，单进程中可以运⾏多个线程，同进程⾥的线程可以共享进程的部分资源的，⽐如⽂件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下⽂切换时是不需要切换，⽽只需要切换线程的私有数据、寄存器等不共享的数据，因此同⼀个进程下的线程上下⽂切换的开销要⽐进程⼩得多。 当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的⽂件描述符传递给线程函数，接着在线程⾥和客户端进⾏通信，从⽽达到并发处理的⽬的。 如果每来⼀个连接就创建⼀个线程，线程运⾏完后，还得操作系统还得销毁线程，虽说线程切换的上写⽂开销不⼤，但是如果频繁创建和销毁线程，系统开销也是不⼩的。 那么，我们可以使⽤线程池的⽅式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若⼲个线程，这样当由新连接建⽴时，将这个已连接的 Socket 放⼊到⼀个队列⾥，然后线程池⾥的线程负责从队列中取出已连接 Socket 进程处理。 需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。 上⾯基于进程或者线程模型的，其实还是有问题的。新到来⼀个 TCP 连接，就需要分配⼀个进程或者线程，那么如果要达到 C10K，意味着要⼀台机器维护 1 万个连接，相当于要维护 1 万个进程/线程，操作系统就算死扛也是扛不住的。 既然为每个请求分配⼀个进程/线程的⽅式不合适，那有没有可能只使⽤⼀个进程来维护多个 Socket 呢？答案是有的，那就是 I/O 多路复⽤技术。 ⼀个进程虽然任⼀时刻只能处理⼀个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1秒内就可以处理上千个请求，把时间拉⻓来看，多个请求复⽤了⼀个进程，这就是多路复⽤，这种思想很类似⼀个 CPU 并发多个进程，所以也叫做时分多路复⽤。 我们熟悉的 select/poll/epoll 内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核中获取多个事件。 select/poll/epoll 是如何获取⽹络事件的呢？在获取事件时，先把所有连接（⽂件描述符）传给内核，再由内核返回产⽣了事件的连接，然后在⽤户态中再处理这些连接对应的请求即可。 所以，对于 select 这种⽅式，需要进⾏ 2 次「遍历」⽂件描述符集合，⼀次是在内核态⾥，⼀个次是在⽤户态⾥ ，⽽且还会发⽣ 2 次「拷⻉」⽂件描述符集合，先从⽤户空间传⼊内核空间，由内核修改后，再传出到⽤户空间中。 select 使⽤固定⻓度的 BitsMap，表示⽂件描述符集合，⽽且所⽀持的⽂件描述符的个数是有限制的，在Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最⼤值为 1024 ，只能监听 0~1023 的⽂件描述符。 poll 不再⽤ BitsMap 来存储所关注的⽂件描述符，取⽽代之⽤动态数组，以链表形式来组织，突破了select 的⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。 但是 poll 和 select 并没有太⼤的本质区别，都是使⽤「线性结构」存储进程关注的 Socket 集合，因此都需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。 epoll 通过两个⽅⾯，很好解决了 select/poll 的问题。 第⼀点，epoll 在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字，把需要监控的 socket 通过epoll_ctl() 函数加⼊内核中的红⿊树⾥，红⿊树是个⾼效的数据结构，增删查⼀般时间复杂度是O(logn) ，通过对这棵⿊红树进⾏操作，这样就不需要像 select/poll 每次操作时都传⼊整个 socket 集合，只需要传⼊⼀个待检测的 socket，减少了内核和⽤户空间⼤量的数据拷⻉和内存分配。 第⼆点， epoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个 socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件列表中，当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率。 epoll 的⽅式即使监听的 Socket 数量越多的时候，效率不会⼤幅度降低，能够同时监听的 Socket 的数⽬也⾮常的多了，上限就为系统定义的进程打开的最⼤⽂件描述符个数。因⽽，epoll 被称为解决 C10K 问题的利器。 （注意：epoll_wait 返回时，对于就绪的事件，epoll使⽤的是共享内存的⽅式，即⽤户态和内核态都指向了就绪链表，所以就避免了内存拷⻉消耗。这是错的！看过 epoll 内核源码的都知道，压根就没有使⽤共享内存这个玩意。你可以从下⾯这份代码看到， epoll_wait 实现的内核代码中调⽤了 __put_user 函数，这个函数就是将数据从内核拷⻉到⽤户空间。） epoll ⽀持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和⽔平触发（level-triggered，LT）。 使⽤边缘触发模式时，当被监控的 Socket 描述符上有可读事件发⽣时，服务器端只会从 epoll_wait中苏醒⼀次，即使进程没有调⽤ read 函数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完； 使⽤⽔平触发模式时，当被监控的 Socket 上有可读事件发⽣时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，⽬的是告诉我们有数据需要读取； 举个例⼦，你的快递被放到了⼀个快递箱⾥，如果快递箱只会通过短信通知你⼀次，即使你⼀直没有去取，它也不会再发送第⼆条短信提醒你，这个⽅式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是⽔平触发的⽅式。 这就是两者的区别，⽔平触发的意思是只要满⾜事件的条件，⽐如内核中有数据需要读，就⼀直不断地把这个事件传递给⽤户；⽽边缘触发的意思是只有第⼀次满⾜条件的时候才触发，之后就不会再传递同样的事件了。 如果使⽤⽔平触发模式，当内核通知⽂件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要⼀次执⾏尽可能多的读写操作。 如果使⽤边缘触发模式，I/O 事件发⽣时只会通知⼀次，⽽且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从⽂件描述符读写数据，那么如果⽂件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那⾥，程序就没办法继续往下执⾏。所以，边缘触发模式⼀般和⾮阻塞 I/O 搭配使⽤，程序会⼀直执⾏ I/O 操作，直到系统调⽤（如 read 和write ）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK 。 ⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，系统调⽤也是有⼀定的开销的的，毕竟也存在上下⽂的切换。 select/poll 只有⽔平触发模式，epoll 默认的触发模式是⽔平触发，但是可以根据应⽤场景设置为边缘触发模式。 另外，使⽤ I/O 多路复⽤时，最好搭配⾮阻塞 I/O ⼀起使⽤，简单点理解，就是多路复⽤ API 返回的事件并不⼀定可读写的，如果使⽤阻塞 I/O， 那么在调⽤read/write 时则会发⽣程序阻塞，因此最好搭配⾮阻塞 I/O，以便应对极少数的特殊情况。 最基础的 TCP 的 Socket 编程，它是阻塞 I/O 模型，基本上只能⼀对⼀通信，那为了服务更多的客户端，我们需要改进⽹络 I/O 模型。 ⽐较传统的⽅式是使⽤多进程/线程模型，每来⼀个客户端连接，就分配⼀个进程/线程，然后后续的读写都在对应的进程/线程，这种⽅式处理 100 个客户端没问题，但是当客户端增⼤到 10000 个时，10000 个进程/线程的调度、上下⽂切换以及它们占⽤的内存，都会成为瓶颈。 为了解决上⾯这个问题，就出现了 I/O 的多路复⽤，可以只在⼀个进程⾥处理多个⽂件的 I/O，Linux 下有三种提供 I/O 多路复⽤的 API，分别是： select、poll、epoll。 select 和 poll 并没有本质区别，它们内部都是使⽤「线性结构」来存储进程关注的 Socket 集合。在使⽤的时候，⾸先需要把关注的 Socket 集合通过 select/poll 系统调⽤从⽤户态拷⻉到内核态，然后由内核检测事件，当有⽹络事件产⽣时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷⻉到⽤户态，⽤户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。 很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越⼤，Socket 集合的遍历和拷⻉会带来很⼤的开销，因此也很难应对 C10K。 epoll 是解决 C10K 问题的利器，通过两个⽅⾯解决了 select/poll 的问题。 epoll 在内核⾥使⽤「红⿊树」来关注进程所有待检测的 Socket，红⿊树是个⾼效的数据结构，增删查⼀般时间复杂度是 O(logn)，通过对这棵⿊红树的管理，不需要像 select/poll 在每次操作时都传⼊整个 Socket 集合，减少了内核和⽤户空间⼤量的数据拷⻉和内存分配。 epoll 使⽤事件驱动的机制，内核⾥维护了⼀个「链表」来记录就绪事件，只将有事件发⽣的 Socket集合传递给应⽤程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和⽆事件的 Socket ），⼤⼤提⾼了检测的效率。 ⽽且，epoll ⽀持边缘触发和⽔平触发的⽅式，⽽ select/poll 只⽀持⽔平触发，⼀般⽽⾔，边缘触发的⽅式会⽐⽔平触发的效率⾼。","categories":[{"name":"I/O多路复用","slug":"I-O多路复用","permalink":"http://example.com/categories/I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"IO","slug":"IO","permalink":"http://example.com/tags/IO/"},{"name":"I/O多路复用","slug":"I-O多路复用","permalink":"http://example.com/tags/I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"name":"select/epoll/poll","slug":"select-epoll-poll","permalink":"http://example.com/tags/select-epoll-poll/"}],"author":"John Doe"},{"title":"Kafka-Kraft 模式","slug":"Kafka-Kraft-模式","date":"2022-03-12T05:30:00.000Z","updated":"2022-03-12T05:32:23.547Z","comments":true,"path":"2022/03/12/Kafka-Kraft-模式/","link":"","permalink":"http://example.com/2022/03/12/Kafka-Kraft-%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由controller 进行 Kafka 集群管理。右图为 kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理。 这样做的好处有以下几个： ⚫ Kafka 不再依赖外部框架，而是能够独立运行； ⚫ controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升； ⚫ 由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制； ⚫ controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"Kraft模式","slug":"Kraft模式","permalink":"http://example.com/tags/Kraft%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"Kafka数据积压（消费者如何提高吞吐量）","slug":"Kafka数据积压（消费者如何提高吞吐量）","date":"2022-03-12T05:28:00.000Z","updated":"2022-03-12T05:29:37.815Z","comments":true,"path":"2022/03/12/Kafka数据积压（消费者如何提高吞吐量）/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B%EF%BC%88%E6%B6%88%E8%B4%B9%E8%80%85%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%89/","excerpt":"","text":"1）如果是Kafka消费能力不足，则可以考虑增 加Topic的分区数，并且同时提升消费组的消费者数量，消费者数 = 分区数。（两者缺一不可） 2）如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间 &lt; 生产速度），使处理的数据小于生产的数据，也会造成数据积压。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"数据积压","slug":"数据积压","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B/"},{"name":"消费者","slug":"消费者","permalink":"http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"}],"author":"John Doe"},{"title":"Kafka消费者漏消费和重复消费问题","slug":"Kafka消费者漏消费和重复消费问题","date":"2022-03-12T05:12:00.000Z","updated":"2022-03-12T05:27:39.970Z","comments":true,"path":"2022/03/12/Kafka消费者漏消费和重复消费问题/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E6%BC%8F%E6%B6%88%E8%B4%B9%E5%92%8C%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E9%97%AE%E9%A2%98/","excerpt":"","text":"重复消费：已经消费了数据，但是 offset 没提交，下次还会消费到当前数据。 漏消费：先提交 offset 后消费，有可能会造成数据的漏消费。 如果想完成Consumer端的精准一次性消费（既不漏消费也不重复消费），那么需要Kafka消费端将消费过程和提交offset过程做原子绑定。此时我们需要将Kafka的offset保存到支持事务的自定义介质（比 如MySQL）。 参考：https://blog.csdn.net/qingqing7/article/details/80054281?spm=1001.2101.3001.6650.14&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-14.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-14.pc_relevant_default&amp;utm_relevant_index=25","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"消费者","slug":"消费者","permalink":"http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"},{"name":"漏消费","slug":"漏消费","permalink":"http://example.com/tags/%E6%BC%8F%E6%B6%88%E8%B4%B9/"},{"name":"重复消费","slug":"重复消费","permalink":"http://example.com/tags/%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9/"}],"author":"John Doe"},{"title":"Kafka消费者的offset提交","slug":"Kafka消费者的offset提交","date":"2022-03-12T05:00:00.000Z","updated":"2022-03-12T05:11:59.292Z","comments":true,"path":"2022/03/12/Kafka消费者的offset提交/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84offset%E6%8F%90%E4%BA%A4/","excerpt":"","text":"offset偏移量表明了该消费者当前消费的数据到哪一步，其存储在系统主题_consumer_offset中（0.9版本之前是存在Zookeeper中），以key,value形式，每隔一段时间kafka都会对其Compact（即保留当前最新的数据）。 1、自动提交offset：为了能让我们专注于业务处理，Kafka提供了自动提交offset功能，通过参数 ⚫ enable.auto.commit：是否开启自动提交offset功能，默认是true ⚫ auto.commit.interval.ms：自动提交offset的时间间隔，默认是5s 2、手动提交：自动提交固然遍历，但基于时间的提交，我们很难把握那个度，因此更多时候，我们可以选择手动提交。 1）同步提交：同步提交会阻塞当前线程，一直到成功为止，并且失败会自动重试 2）异步提交：异步提交则不会阻塞当前线程，且没有重试机制，可能提交失败。 两者都会将本次提交的一批数据最高偏移量提交。 指定offset消费：auto.offset.reset = earliest | latest | none 默认是 latest。 当kafka中没有初始偏移量（消费者组第一次消费）或服务器上不存在当前偏移量时（数据被删除）需要指定offset消费。 1）earliest：自动将偏移量重置为最早的偏移量，–from-beginning。 2）latest（默认值）：自动将偏移量重置为最新偏移量。 （3）none：如果未找到消费者组的先前偏移量，则向消费者抛出异常。 （4）任意指定 offset 位移开始消费 指定时间消费：在生产环境中，会遇到最近消费的几个小时数据异常，想重新按照时间消费。例如要求按照时间消费前一天的数据","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"消费者","slug":"消费者","permalink":"http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"},{"name":"offset","slug":"offset","permalink":"http://example.com/tags/offset/"}],"author":"John Doe"},{"title":"Kafka消费者分区的分配以及再平衡","slug":"Kafka消费者分区的分配以及再平衡","date":"2022-03-12T04:47:00.000Z","updated":"2022-03-12T04:53:38.116Z","comments":true,"path":"2022/03/12/Kafka消费者分区的分配以及再平衡/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E6%B6%88%E8%B4%B9%E8%80%85%E5%88%86%E5%8C%BA%E7%9A%84%E5%88%86%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1/","excerpt":"","text":"一个consumer group中有多个consumer组成，一个 topic有多个partition组成，现在的问题是，到底由哪个consumer来消费哪个partition的数据。 2、Kafka有四种主流的分区分配策略： Range、RoundRobin、Sticky、CooperativeSticky。可以通过配置参数partition.assignment.strategy，修改分区的分配策略。默认策略是Range + CooperativeSticky。Kafka可以同时使用多个分区分配策略。 1）Range 是对每个 topic 而言的。 首先对同一个 topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。 假如现在有 7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6；消费者排序完之后将会是C0,C1,C2。例如，7/3 = 2 余 1 ，除不尽，那么 消费者 C0 便会多消费 1 个分区。 8/3=2余2，除不尽，那么C0和C1分别多消费一个。 通过 partitions数/consumer数 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。 注意：如果只是针对 1 个 topic 而言，C0消费者多消费1个分区影响不是很大。但是如果有 N 多个 topic，那么针对个 topic，消费者 C0都将多消费 1 个分区，topic越多，C0消 费的分区会比其他消费者明显多消费 N 个分区。容易产生数据倾斜！ （注意：说明：某个消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。） 2）RoundRobin 分区策略原理： RoundRobin 针对集群中所有Topic而言。RoundRobin 轮询分区策略，是把所有的 partition 和所有的consumer 都列出来，然后按照 hashcode 进行排序，最后通过轮询算法来分配 partition 给到各个消费者。 3） Sticky 以及再平衡： 粘性分区定义：可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前，考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分区不变化。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"消费者","slug":"消费者","permalink":"http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"},{"name":"分区分配策略","slug":"分区分配策略","permalink":"http://example.com/tags/%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/"}],"author":"John Doe"},{"title":"Kafka高效读写数据","slug":"Kafka高效读写数据","date":"2022-03-12T03:23:00.000Z","updated":"2022-03-12T03:24:21.616Z","comments":true,"path":"2022/03/12/Kafka高效读写数据/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE/","excerpt":"","text":"1）Kafka 本身是分布式集群，可以采用分区技术，并行度高 2）读数据采用稀疏索引，可以快速定位要消费的数据 3）顺序写磁盘（Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。） 4）页缓存 + 零拷贝技术","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"高效读写","slug":"高效读写","permalink":"http://example.com/tags/%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99/"}],"author":"John Doe"},{"title":"Kafka文件清理策略","slug":"Kafka文件清理策略","date":"2022-03-12T03:19:00.000Z","updated":"2022-03-12T03:23:07.944Z","comments":true,"path":"2022/03/12/Kafka文件清理策略/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E6%96%87%E4%BB%B6%E6%B8%85%E7%90%86%E7%AD%96%E7%95%A5/","excerpt":"","text":"Kafka 中默认的日志保存时间为 7 天，可以通过调整如下参数修改保存时间。⚫ log.retention.hours，最低优先级小时，默认 7 天。 ⚫ log.retention.minutes，分钟。 ⚫ log.retention.ms，最高优先级毫秒。 ⚫log.retention.check.interval.ms，负责设置检查周期，默认 5 分钟。 对于超过设置事件的数据，有两种清楚策略，delete和Compact 1）delete 日志删除：将过期数据删除 ⚫ log.cleanup.policy = delete 所有数据启用删除策略 （1）基于时间：默认打开。以 segment 中所有记录中的最大时间戳作为该文件时间戳。 （2）基于大小：默认关闭。超过设置的所有日志总大小，删除最早segment。log.retention.bytes，默认等于-1，表示无穷大。 2）compact 日志压缩 compact日志压缩：对于相同key的不同value值，只保留最后一个版本。 ⚫ log.cleanup.policy = compact 所有数据启用压缩策略 压缩后的offset可能是不连续的，比如上图中没有6，当从这些offset消费消息时，将会拿到比这个offset大 的offset对应的消息，实际上会拿到offset为7的消息，并从这个位置开始消费。 这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"清楚策略","slug":"清楚策略","permalink":"http://example.com/tags/%E6%B8%85%E6%A5%9A%E7%AD%96%E7%95%A5/"}],"author":"John Doe"},{"title":"Kafka文件存储机制","slug":"Kafka文件存储机制","date":"2022-03-12T03:16:00.000Z","updated":"2022-03-12T03:19:20.616Z","comments":true,"path":"2022/03/12/Kafka文件存储机制/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6/","excerpt":"","text":"Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制， 将每个partition分为多个segment。每个segment包括：“.index”文件、“.log”文件和.timeindex等文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号，例如：first-0。 Log文件和Index文件详解：","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"文件存储","slug":"文件存储","permalink":"http://example.com/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"}],"author":"John Doe"},{"title":"Leader Partition 负载平衡","slug":"Leader-Partition-负载平衡","date":"2022-03-12T03:11:00.000Z","updated":"2022-03-12T03:15:02.258Z","comments":true,"path":"2022/03/12/Leader-Partition-负载平衡/","link":"","permalink":"http://example.com/2022/03/12/Leader-Partition-%E8%B4%9F%E8%BD%BD%E5%B9%B3%E8%A1%A1/","excerpt":"","text":"正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡。 策略： 1、auto.leader.rebalance.enable，默认是true。（自动Leader Partition 平衡） 2、leader.imbalance.per.broker.percentage，默认是10%。每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。 3、leader.imbalance.check.interval.seconds，默认值300秒。检查leader负载是否平衡的间隔时间。 例如：针对broker0节点，分区2的AR优先副本是0节点，但是0节点却不是Leader节点，所以不平衡数加1，AR副本总数是4，所以broker0节点不平衡率为1/4&gt;10%，需要再平衡。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"Leader","slug":"Leader","permalink":"http://example.com/tags/Leader/"},{"name":"Partition","slug":"Partition","permalink":"http://example.com/tags/Partition/"}],"author":"John Doe"},{"title":"Leader 和 Follower 故障处理细节","slug":"Leader-和-Follower-故障处理细节","date":"2022-03-12T03:06:00.000Z","updated":"2022-03-12T03:10:07.966Z","comments":true,"path":"2022/03/12/Leader-和-Follower-故障处理细节/","link":"","permalink":"http://example.com/2022/03/12/Leader-%E5%92%8C-Follower-%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E7%BB%86%E8%8A%82/","excerpt":"","text":"LEO（Log End Offset）：每个副本的最后一个offset，LEO其实就是最新的offset + 1。 HW（High Watermark）：所有副本中最小的LEO 。 1）Follower故障： （1） Follower发生故障后会被临时踢出ISR （2） 这个期间Leader和Follower继续接收数据 （3）待该Follower恢复后，Follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向Leader进行同步。 （4）等该Follower的LEO大于等于该Partition的HW，即Follower追上Leader之后，就可以重新加入ISR了。 2）Leader故障： （1） Leader发生故障之后，会从ISR中选出一个新的Leader （2）为保证多个副本之间的数据一致性，其余的Follower会先将各自的log文件高于HW的部分截掉，然后从新的Leader同步数据。 注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"Leader和Follower故障","slug":"Leader和Follower故障","permalink":"http://example.com/tags/Leader%E5%92%8CFollower%E6%95%85%E9%9A%9C/"}],"author":"John Doe"},{"title":"Kafka Broker总体工作流程","slug":"Kafka-Broker总体工作流程","date":"2022-03-12T03:00:00.000Z","updated":"2022-03-12T03:00:21.303Z","comments":true,"path":"2022/03/12/Kafka-Broker总体工作流程/","link":"","permalink":"http://example.com/2022/03/12/Kafka-Broker%E6%80%BB%E4%BD%93%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/","excerpt":"","text":"","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"工作流程","slug":"工作流程","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"}],"author":"John Doe"},{"title":"Zookeeper中存储的Kafka 信息","slug":"Zookeeper中存储的Kafka-信息","date":"2022-03-12T02:52:00.000Z","updated":"2022-03-12T02:53:19.813Z","comments":true,"path":"2022/03/12/Zookeeper中存储的Kafka-信息/","link":"","permalink":"http://example.com/2022/03/12/Zookeeper%E4%B8%AD%E5%AD%98%E5%82%A8%E7%9A%84Kafka-%E4%BF%A1%E6%81%AF/","excerpt":"","text":"在zookeeper的服务端存储的Kafka相关信息： 1）/kafka/brokers/ids [0,1,2] 记录有哪些服务器 2）/kafka/brokers/topics/first/partitions/0/state{“leader”:1 ,”isr”:[1,0,2] } 记录谁是Leader，有哪些服务器可用 3）/kafka/controller{“brokerid”:0}辅助选举Leader","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"},{"name":"Zookeeper","slug":"Kafka/Zookeeper","permalink":"http://example.com/categories/Kafka/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://example.com/tags/Zookeeper/"}],"author":"John Doe"},{"title":"Kafka数据乱序","slug":"Kafka数据乱序","date":"2022-03-12T02:47:00.000Z","updated":"2022-03-12T02:50:26.550Z","comments":true,"path":"2022/03/12/Kafka数据乱序/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E6%95%B0%E6%8D%AE%E4%B9%B1%E5%BA%8F/","excerpt":"","text":"1）kafka在1.x版本之前保证数据单分区有序，条件如下：max.in.flight.requests.per.connection=1（不需要考虑是否开启幂等性）。 2）kafka在1.x及以后版本保证数据单分区有序，条件如下： （1）未开启幂等性max.in.flight.requests.per.connection需要设置为1。 （2）开启幂等性max.in.flight.requests.per.connection需要设置小于等于5。 原因说明：因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据，故无论如何，都可以保证最近5个request的数据都是有序的。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"数据有序","slug":"数据有序","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F/"}],"author":"John Doe"},{"title":"Kafka的生产者事务原理","slug":"Kafka的生产者事务原理","date":"2022-03-12T02:29:00.000Z","updated":"2022-03-12T02:33:52.261Z","comments":true,"path":"2022/03/12/Kafka的生产者事务原理/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E7%9A%84%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1%E5%8E%9F%E7%90%86/","excerpt":"","text":"注意：开启事务，必须要开启幂等性。另外Procuder在使用事务功能前，必须先自定义一个唯一的transaction.id。有了transaction.id，即使客户端挂掉了，它重启后也能继续处理未完成的事务。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"}],"author":"John Doe"},{"title":"Kafka保证生产者生产的数据不重复：幂等性+至少一次","slug":"Kafka保证生产者生产的数据不重复：幂等性-至少一次","date":"2022-03-12T02:25:00.000Z","updated":"2022-03-12T02:34:13.739Z","comments":true,"path":"2022/03/12/Kafka保证生产者生产的数据不重复：幂等性-至少一次/","link":"","permalink":"http://example.com/2022/03/12/Kafka%E4%BF%9D%E8%AF%81%E7%94%9F%E4%BA%A7%E8%80%85%E7%94%9F%E4%BA%A7%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8D%E9%87%8D%E5%A4%8D%EF%BC%9A%E5%B9%82%E7%AD%89%E6%80%A7-%E8%87%B3%E5%B0%91%E4%B8%80%E6%AC%A1/","excerpt":"","text":"至少一次：ack级别设置为-1+分区副本大于等于2+ISR里面的应答最小副本大于等于2（保证数据不会丢失） 幂等性：指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。（重复数据的判断标准：具有&lt;PID, Partition, SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其 中PID是Kafka每次重启都会分配一个新的；Partition 表示分区号；Sequence Number是单调自增的。） 因此幂等性只能保证的是在单分区单会话内不重复。 如何使用幂等性：开启参数 enable.idempotence 默认为 true，false 关闭。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"},{"name":"消息队列","slug":"Kafka/消息队列","permalink":"http://example.com/categories/Kafka/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"}],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"数据","slug":"数据","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE/"}],"author":"John Doe"},{"title":"Spring Security认证过程","slug":"Spring-Security认证过程","date":"2022-03-11T13:54:00.000Z","updated":"2022-03-11T14:09:54.174Z","comments":true,"path":"2022/03/11/Spring-Security认证过程/","link":"","permalink":"http://example.com/2022/03/11/Spring-Security%E8%AE%A4%E8%AF%81%E8%BF%87%E7%A8%8B/","excerpt":"","text":"我们知道Spring Security的核心就是认证和授权，但是具体它是如何进行认证和授权的呢？下面让我们来聊聊Spring Security的认证过程，具体步骤如下图所示： 在开始之前，我们需要了解一下如下类： AuthenticationManager核心验证器，该对象提供了认证方法的入口，接收一个Authentiation对象作为参数。 public interface AuthenticationManager &#123; Authentication authenticate(Authentication authentication) throws AuthenticationException; &#125; ProviderManager：它是 AuthenticationManager 的一个实现类，提供了基本的认证逻辑和方法；它包含了一个 List 对象，通过 AuthenticationProvider 接口来扩展出不同的认证提供者(当Spring Security默认提供的实现类不能满足需求的时候可以扩展AuthenticationProvider 覆盖supports(Class&lt;?&gt; authentication)方法)； 具体验证逻辑： AuthenticationManager 接收 Authentication 对象作为参数，并通过 authenticate(Authentication) 方法对其进行验证；AuthenticationProvider实现类用来支撑对 Authentication 对象的验证动作；UsernamePasswordAuthenticationToken实现了 Authentication主要是将用户输入的用户名和密码进行封装，并供给 AuthenticationManager 进行验证；验证完成以后将返回一个认证成功的 Authentication 对象；","categories":[{"name":"Spring Security","slug":"Spring-Security","permalink":"http://example.com/categories/Spring-Security/"}],"tags":[{"name":"认证","slug":"认证","permalink":"http://example.com/tags/%E8%AE%A4%E8%AF%81/"}],"author":"John Doe"},{"title":"Spring的AOP是在哪个阶段创建的动态代理？","slug":"Spring的AOP是在哪个阶段创建的动态代理？","date":"2022-03-10T00:44:00.000Z","updated":"2022-03-10T00:47:08.519Z","comments":true,"path":"2022/03/10/Spring的AOP是在哪个阶段创建的动态代理？/","link":"","permalink":"http://example.com/2022/03/10/Spring%E7%9A%84AOP%E6%98%AF%E5%9C%A8%E5%93%AA%E4%B8%AA%E9%98%B6%E6%AE%B5%E5%88%9B%E5%BB%BA%E7%9A%84%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%EF%BC%9F/","excerpt":"","text":"1、正常情况下会在bean的生命周期“初始化”后，通过BeanPostProcessor.postProcessAfterInitialization创建AOP的动态代理 2、特殊情况下，即存在循环依赖的时候，Bean会在生命周期的“属性注入”时，通过MergedBeanDefinitionPostProcessor.postProcessMergedBeanDefinition创建aop动态代理","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"},{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"什么情况下AOP会失效,怎么解决？","slug":"什么情况下AOP会失效-怎么解决？","date":"2022-03-10T00:37:00.000Z","updated":"2022-03-10T00:42:55.549Z","comments":true,"path":"2022/03/10/什么情况下AOP会失效-怎么解决？/","link":"","permalink":"http://example.com/2022/03/10/%E4%BB%80%E4%B9%88%E6%83%85%E5%86%B5%E4%B8%8BAOP%E4%BC%9A%E5%A4%B1%E6%95%88-%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%EF%BC%9F/","excerpt":"","text":"1、方法是private 2、目标类没有配置为Bean 3、切点表达式没有写正确 4、jdk动态代理下内部调用不会触发AOP（ 原因： 内部进行自调用，是走的实例对象，而不是代理对象。 解决： 1、在本类中自动注入当前的bean 2、@EnableAspectJAutoProxy(exposProxy = true) 设置暴露当前代理对象到本地线程，可以通过AopContent.currentProxy()拿到当前的动态代理对象。）","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"},{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"AOP有几种实现方式 ","slug":"AOP有几种实现方式","date":"2022-03-10T00:34:00.000Z","updated":"2022-03-10T00:36:27.821Z","comments":true,"path":"2022/03/10/AOP有几种实现方式/","link":"","permalink":"http://example.com/2022/03/10/AOP%E6%9C%89%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/","excerpt":"","text":"1、Spring 1.2 基于接口的配置：最早的 Spring AOP 是完全基于几个接口的，想看源码的同学可以从这里起步。 2、Spring 2.0 schema-based 配置：Spring 2.0 以后使用 XML 的方式来配置，使用 命名空间 3、Spring 2.0 @AspectJ 配置：使用注解的方式来配置，这种方式感觉是最方便的，还有，这里虽然叫做 @AspectJ，但是这个和 AspectJ 其实没啥关系。 4、AspectJ 方式，这种方式其实和Spring没有关系，采用AspectJ 进行动态织入的方式实现AOP，需要用AspectJ 单独编译。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"}],"author":"John Doe"},{"title":"Spring的AOP通知执行顺序","slug":"Spring的AOP通知执行顺序","date":"2022-03-09T13:25:00.000Z","updated":"2022-03-09T13:28:17.294Z","comments":true,"path":"2022/03/09/Spring的AOP通知执行顺序/","link":"","permalink":"http://example.com/2022/03/09/Spring%E7%9A%84AOP%E9%80%9A%E7%9F%A5%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/","excerpt":"","text":"执行顺序： 5.2.7之前： 1、正常执行：@Before­­­&gt;方法­­­­&gt;@After­­­&gt;@AfterReturning 2、异常执行：@Before­­­&gt;方法­­­­&gt;@After­­­&gt;@AfterThrowing 5.2.7之后： 1、正常执行：@Before­­­&gt;方法­­­­&gt;@AfterReturning­­­&gt;@After 2、异常执行：@Before­­­&gt;方法­­­­&gt;@AfterThrowing­­­&gt;@After","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"},{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"说说@Import可以有几种用法？","slug":"说说-Import可以有几种用法？","date":"2022-03-09T10:41:00.000Z","updated":"2022-03-09T10:43:33.973Z","comments":true,"path":"2022/03/09/说说-Import可以有几种用法？/","link":"","permalink":"http://example.com/2022/03/09/%E8%AF%B4%E8%AF%B4-Import%E5%8F%AF%E4%BB%A5%E6%9C%89%E5%87%A0%E7%A7%8D%E7%94%A8%E6%B3%95%EF%BC%9F/","excerpt":"","text":"1、 直接指定类 （如果配置类会按配置类正常解析、 如果是个普通类就会解析成Bean) 2、 通过ImportSelector 可以一次性注册多个，返回一个string[] 每一个值就是类的完整类路径 3、 通过DeferredImportSelector可以一次性注册多个，返回一个string[] 每一个值就是类的完整类路径 区别：DeferredImportSelector 顺序靠后 4、 通过ImportBeanDefinitionRegistrar 可以一次性注册多个，通过BeanDefinitionRegistry来动态注册BeanDefintion","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"如何让自动注入找到多个依赖Bean时不报错","slug":"如何让自动注入找到多个依赖Bean时不报错","date":"2022-03-09T10:36:00.000Z","updated":"2022-03-09T10:39:06.070Z","comments":true,"path":"2022/03/09/如何让自动注入找到多个依赖Bean时不报错/","link":"","permalink":"http://example.com/2022/03/09/%E5%A6%82%E4%BD%95%E8%AE%A9%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%85%A5%E6%89%BE%E5%88%B0%E5%A4%9A%E4%B8%AA%E4%BE%9D%E8%B5%96Bean%E6%97%B6%E4%B8%8D%E6%8A%A5%E9%94%99/","excerpt":"","text":"自动注入找到多个依赖Bean时，@primary可以指定注入哪一个。 @Primary：自动装配时当出现多个Bean候选者时，被注解为@Primary的Bean将作为首选者，否则将抛出异常 @Autowired 默认按类型装配，如果我们想使用按名称装配，可以结合@Qualifier注解一起使用 @Autowired @Qualifier(“personDaoBean”) 存在多个实例配合使用","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"说一说@Autowired和@Resource之间的区别","slug":"说一说-Autowired和-Resource之间的区别","date":"2022-03-09T10:31:00.000Z","updated":"2022-03-09T10:35:41.053Z","comments":true,"path":"2022/03/09/说一说-Autowired和-Resource之间的区别/","link":"","permalink":"http://example.com/2022/03/09/%E8%AF%B4%E4%B8%80%E8%AF%B4-Autowired%E5%92%8C-Resource%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"@Autowired可用于：构造函数、成员变量、Setter方法 @Autowired和@Resource之间的区别 @Autowired默认是按照类型装配注入的（按照名称匹配需要@Qualifier），默认情况下它要求依赖对象必须存在（可以设置它required属性为false）。 @Resource默认是按照名称来装配注入的，只有当找不到与名称匹配的bean才会按照类型来装配注入。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"使用@Autowired注解自动装配的过程是怎样的？","slug":"使用-Autowired注解自动装配的过程是怎样的？","date":"2022-03-09T10:11:00.000Z","updated":"2022-03-09T10:20:50.684Z","comments":true,"path":"2022/03/09/使用-Autowired注解自动装配的过程是怎样的？/","link":"","permalink":"http://example.com/2022/03/09/%E4%BD%BF%E7%94%A8-Autowired%E6%B3%A8%E8%A7%A3%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84%EF%BC%9F/","excerpt":"","text":"记住：@Autowired 通过Bean的后置处理器进行解析的 1、 在创建一个Spring上下文的时候再构造函数中进行注册AutowiredAnnotationBeanPostProcessor 2、 在Bean的创建过程中进行解析 2.1、 在实例化后预解析（解析@Autowired标注的属性、方法 比如：把属性的类型、名称、属性所在的类..... 元数据缓存起） 2.2、 在属性注入真正的解析（拿到上一步缓存的元数据 去ioc容器帮进行查找，并且返回注入） a. 首先根据预解析的元数据拿到 类型去容器中进行查找 （如果查询结果刚好为一个，就将该bean装配给@Autowired指定的数据；如果查询的结果不止一个，那么@Autowired会根据名称来查找；如果上述查找的结果为空，那么会抛出异常。解决方法时，使用required=false。）","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"配置类@Configuration的作用解析原理","slug":"配置类-Configuration的作用解析原理","date":"2022-03-09T09:00:00.000Z","updated":"2022-03-09T10:09:42.110Z","comments":true,"path":"2022/03/09/配置类-Configuration的作用解析原理/","link":"","permalink":"http://example.com/2022/03/09/%E9%85%8D%E7%BD%AE%E7%B1%BB-Configuration%E7%9A%84%E4%BD%9C%E7%94%A8%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/","excerpt":"","text":"1、@Configuration用来代替xml配置方式spring.xml配置文件 2、没有@Configuration也是可以配置@Bean 3、 加了@Configuration会为配置类创建cglib动态代理（保证配置类@Bean方法调用Bean的单例），@Bean方法的调用就会通过容器.getBean进行获取 原理： 1、创建Spring上下文的时候会注册一个解析配置的处理器ConfigurationClassPostProcessor（实现BeanFactoryPostProcessor和BeanDefinitionRegistryPostProcessor) 2、在调用invokeBeanFactoryPostProcessor，就会去调用ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry进行解析配置（解析配置类说白就是去解析各种注解(@Bean @Configuration@Import @Component … 就是注册BeanDefinition) 3、ConfigurationClassPostProcessor.postProcessBeanFactory去创建cglib动态代理","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"对于@Bean之间的方法调用是怎么保证单例的？","slug":"对于@Bean之间的方法调用是怎么保证单例的？","date":"2022-03-09T08:44:00.000Z","updated":"2022-03-09T08:57:45.869Z","comments":true,"path":"2022/03/09/对于@Bean之间的方法调用是怎么保证单例的？/","link":"","permalink":"http://example.com/2022/03/09/%E5%AF%B9%E4%BA%8E@Bean%E4%B9%8B%E9%97%B4%E7%9A%84%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E5%8D%95%E4%BE%8B%E7%9A%84%EF%BC%9F/","excerpt":"","text":"如果希望@bean方法返回的对象是单例，需要在类上加上@Configuration注解。 原因：Spring会使用invokeBeanFactoryPostProcessor 在内置BeanFactoryPostProcessor中使用CGLib生成动态代理，当@Bean方法进行互调时， 则会通过CGLIB进行增强，通过调用的方法名作为bean的名称去ioc容器中获取，进而保证了@Bean方法的单例 。 换句话说：被@Configuration修饰的类，spring容器中会通过cglib给这个类创建一个代理，代理会拦截所有被@Bean 修饰的方法，默认情况（bean为单例）下确保这些方法只被调用一次，从而确保这些bean是同一个bean，即单例的。@Configuration修饰的类有cglib代理效果，默认添加的bean都为单例","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"要将一个第三方的类配成为Bean有哪些方式？","slug":"要将一个第三方的类配成为Bean有哪些方式？","date":"2022-03-09T08:39:00.000Z","updated":"2022-03-09T08:42:14.407Z","comments":true,"path":"2022/03/09/要将一个第三方的类配成为Bean有哪些方式？/","link":"","permalink":"http://example.com/2022/03/09/%E8%A6%81%E5%B0%86%E4%B8%80%E4%B8%AA%E7%AC%AC%E4%B8%89%E6%96%B9%E7%9A%84%E7%B1%BB%E9%85%8D%E6%88%90%E4%B8%BABean%E6%9C%89%E5%93%AA%E4%BA%9B%E6%96%B9%E5%BC%8F%EF%BC%9F/","excerpt":"","text":"1、通过@bean注解（搭配@Configurtion） 2、通过@import注解 3、通过Spring的拓展接口BeanDefinitionRegistryPostProcessor","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"为什么@ComponentScan 不设置basePackage也会扫描？","slug":"为什么-ComponentScan-不设置basePackage也会扫描？","date":"2022-03-09T08:36:00.000Z","updated":"2022-03-09T08:38:51.082Z","comments":true,"path":"2022/03/09/为什么-ComponentScan-不设置basePackage也会扫描？/","link":"","permalink":"http://example.com/2022/03/09/%E4%B8%BA%E4%BB%80%E4%B9%88-ComponentScan-%E4%B8%8D%E8%AE%BE%E7%BD%AEbasePackage%E4%B9%9F%E4%BC%9A%E6%89%AB%E6%8F%8F%EF%BC%9F/","excerpt":"","text":"@componentScan注解不设置basePackage默认会将你的类所在的包的地址作为扫描包的地址","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"John Doe"},{"title":"Spring是如何解决循环依赖问题的？","slug":"Spring是如何解决循环依赖问题的？","date":"2022-03-09T02:54:00.000Z","updated":"2022-03-09T03:11:12.718Z","comments":true,"path":"2022/03/09/Spring是如何解决循环依赖问题的？/","link":"","permalink":"http://example.com/2022/03/09/Spring%E6%98%AF%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E9%97%AE%E9%A2%98%E7%9A%84%EF%BC%9F/","excerpt":"","text":"什么是循环依赖问题？ 类与类之间的依赖关系形成了闭环，就会导致循环依赖问题的产生。（比如A类依赖了B类，B类依赖了C类，而最后C类又依赖了A类，这样就形成了循环依赖问题。） 循环依赖问题在Spring中主要有三种情况： 1、通过构造方法进行依赖注入时产生的循环依赖问题。 2、通过setter方法进行依赖注入且是在多例（原型）模式下产生的循环依赖问题。 3、通过setter方法进行依赖注入且是在单例模式下产生的循环依赖问题。 注意：在Spring中，只有【第三种方式】的循环依赖问题被解决了，其他两种方式在遇到循环依赖问题时都会产生异常。 因为第一种构造方法注入的情况下，在new对象的时候就会堵塞住了，其实也就是”先有鸡还是先有蛋“的历史难题。 第二种setter方法&amp;&amp;多例的情况下，每一次getBean()时，都会产生一个新的Bean，如此反复下去就会有无穷无尽的Bean产生了，最终就会导致OOM问题的出现。 如何解决循环依赖问题？ Spring中有三个缓存，用于存储单例的Bean实例，这三个缓存是彼此互斥的，不会针对同一个Bean的实例同时存储。 如果调用getBean，则需要从三个缓存中依次获取指定的Bean实例。读取顺序依次是一级缓存–&gt;二级缓存–&gt;三级缓存 一级缓存：Map&lt;String, Object&gt; singletonObjects第一级缓存的作用？ 用于存储单例模式下创建的Bean实例（已经创建完毕）。该缓存是对外使用的，指的就是使用Spring框架的程序员。 存储什么数据？ K：bean的名称 V：bean的实例对象（有代理对象则指的是代理对象，已经创建完毕） 第二级缓存：Map&lt;String, Object&gt; earlySingletonObjects第二级缓存的作用？ 用于存储单例模式下创建的Bean实例（该Bean被提前暴露的引用,该Bean还在创建中）。该缓存是对内使用的，指的就是Spring框架内部逻辑使用该缓存。为了解决第一个classA引用最终如何替换为代理对象的问题（如果有代理对象） 存储什么数据？ K：bean的名称 V：bean的实例对象（有代理对象则指的是代理对象，该Bean还在创建中） 第三级缓存：Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories第三级缓存的作用？ 通过ObjectFactory对象来存储单例模式下提前暴露的Bean实例的引用（正在创建中）。该缓存是对内使用的，指的就是Spring框架内部逻辑使用该缓存。此缓存是解决循环依赖最大的功臣 存储什么数据？ K：bean的名称 V：ObjectFactory，该对象持有提前暴露的bean的引用 为什么第三级缓存要使用ObjectFactory？需要提前产生代理对象。 什么时候将Bean的引用提前暴露给第三级缓存的ObjectFactory持有？时机就是在第一步实例化之后，第二步依赖注入之前，完成此操作。 总结以上就是Spring解决循环依赖的关键点！总结来说，就是要搞清楚以下几点： 搞清楚Spring三级缓存的作用？搞清楚第三级缓存中ObjectFactory的作用？搞清楚为什么需要第二级缓存？搞清楚什么时候使用三级缓存（添加和查询操作）？搞清楚什么时候使用二级缓存（添加和查询操作）？当目标对象产生代理对象时，Spring容器中（第一级缓存）到底存储的是谁？","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"循环依赖","slug":"循环依赖","permalink":"http://example.com/tags/%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/"}],"author":"John Doe"},{"title":"Spring AOP实现机制的一个小小陷阱","slug":"Spring AOP实现机制的一个小小陷阱","date":"2022-03-08T12:36:00.000Z","updated":"2022-03-08T12:48:29.130Z","comments":true,"path":"2022/03/08/Spring AOP实现机制的一个小小陷阱/","link":"","permalink":"http://example.com/2022/03/08/Spring%20AOP%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E5%B0%8F%E9%99%B7%E9%98%B1/","excerpt":"","text":"我们知道Spring AOP采用代理模式实现，具体的横切逻辑会被添加到动态生成的代理对象中，只要调用的是目标对象的代理对象上的方法就可以保证目标对象的方法执行可以被拦截。 不过遗憾的是，代理模式的实现机制在处理方法调用的时序方面会给使用这种机制实现的AOP产品造成一个缺憾。在处理对象方法中，不管你如何添加横切逻辑，也不管添加多少横切逻辑，有一点是确定的，你最终需要调用目标对象的同一方法来执行最初所应以的方法逻辑。如果目标对象中原始方法调用依赖于其他对象，那没问题。我们可以为目标对象注入所依赖对象的代理，并且可以保证相应的Joinpoint被拦截并且织入相应横切逻辑。但是如果目标对象中的原始方法调用直接调用自身方法时，会导致出现问题 在代理对象的method1执行经历了层层拦截后，最终会将调用转向目标对象上的method1，之后调用流程全部在走targetobject之上，当method1调用method2时，它调用targetobject的method2，而不是代理对象的method2，而针对method2的横切逻辑是织入到代理对象上的，因此method1中调用的method2没有被成功拦截。 好在Spring AOP提供了AopContent来公开当前目标对象的代理对象，我们只要在目标对象中使用AopContent.currentProxy()就可以获取当前目标对象所对应的代理对象。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"}],"author":"John Doe"},{"title":"AOP的常见应用案例","slug":"AOP的应用案例","date":"2022-03-08T11:26:00.000Z","updated":"2022-03-08T12:33:39.435Z","comments":true,"path":"2022/03/08/AOP的应用案例/","link":"","permalink":"http://example.com/2022/03/08/AOP%E7%9A%84%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B/","excerpt":"","text":"1、异常处理： 通常将Error和RuntimeException及其子类称作非受检异常。（编译器不会对这些类型的异常进行编译期检查），而其他的则为受检异常（编写程序期间就应进行处理）。Fault Barrier即为对非受检异常的处理。 对于这些非受检异常的处理可以归并于溢出进行处理，而不是让他们散落到系统的各处。介于此，我们可以通过实现一个Aspect来处理，让其对系统中所有可能的falut情况进行统一的处理。而这个专职于处理Falut的Aspect即为Falut Barrier。 2、安全检查： Filter是Servlet规范为我们提供的一种AOP支持。通过它我们可以为基于servlet的web应用添加相应的资源访问控制等等。但是，基于filter的web应用的资源访问控制仅仅是特定领域安全检查需求。而通过AOP，我们可以为任何类型的应用添加安全支持。（Spring Security则是基于Spring的一款强大的安全框架） 3、缓存： AOP应用的另一个主要场景则是为系统透明地添加缓存支持。缓存可以在很大程度上提升系统性能。为了避免需要添加的缓存实现逻辑影响业务逻辑的实现，我们可以让缓存的实现独立于业务对象的实现外，将系统中的缓存需求通过AOP的Aspect进行封装，只在系统中某个点确切需要缓存的情况下才进行织入。（现在已经有许多现成的Caching产品实现，入EhCache、Redis等） Spring Modules项目提供了对现有Caching产品的集成，这样可以通过外部声明的方式为系统中的Joinpoint加Caching支持。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"},{"name":"应用","slug":"应用","permalink":"http://example.com/tags/%E5%BA%94%E7%94%A8/"}],"author":"John Doe"},{"title":"C语言程序经过预处理、编译、汇编和链接等各个阶段的变化情况","slug":"C语言程序经过预处理、编译、汇编和链接等各个阶段的变化情况","date":"2022-03-08T07:59:00.000Z","updated":"2022-03-08T11:26:01.536Z","comments":true,"path":"2022/03/08/C语言程序经过预处理、编译、汇编和链接等各个阶段的变化情况/","link":"","permalink":"http://example.com/2022/03/08/C%E8%AF%AD%E8%A8%80%E7%A8%8B%E5%BA%8F%E7%BB%8F%E8%BF%87%E9%A2%84%E5%A4%84%E7%90%86%E3%80%81%E7%BC%96%E8%AF%91%E3%80%81%E6%B1%87%E7%BC%96%E5%92%8C%E9%93%BE%E6%8E%A5%E7%AD%89%E5%90%84%E4%B8%AA%E9%98%B6%E6%AE%B5%E7%9A%84%E5%8F%98%E5%8C%96%E6%83%85%E5%86%B5/","excerpt":"","text":"编译过程概述：通常编译程序的过程分为词法分析、语法分析、语义分析、目目标代码生成4个阶段（如果编译器支持优化，还可以有中间代码生成和代码优化两个阶段）。 1、词法分析 此阶段的任务是从左到右一个字符一个字符地读入源程序，对构成源程序的字符进行扫描和分解，从而识别出一个个单词（逻辑上紧密相连的一组有集体含义的字符）。 2、语法分析 此阶段的任务是在词法分析的基础上将单词序列分解成各类语法短语（也称语法单位）可表示成语法树。 注：词法分析和语法分析本质上都是对源程序的结构进行分析。 3、语义分析 语义分析是审查源程序有无语义错误，为代码生成阶段收集类型信息。 4、中间代码生成 “中间代码”是一种结构简单，含义明确的记号系统，这种记号系统可以设计为多种多样的形式，重要的设计原则为两点：一是容易生成；二是容易将它翻译成目标代码。很多编译程序采用了一种近似“三地址指令”的“四元式”中间代码。这种四元式的形式为：（运算符，运算对象1，运算对象2，结果） 5、代码优化 将中间代码进行变换或进行改造，目的：使生成的目标代码更为高效，即省时间和空间 6、目标代码生成 任务是把中间代码变换成特定机器上的绝对指令代码或可重定位的指令代码或汇编指令代码。","categories":[{"name":"编译原理","slug":"编译原理","permalink":"http://example.com/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"基础概念","slug":"基础概念","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"}],"author":"John Doe"},{"title":"Spring AOP 一世","slug":"Spring-AOP-一世","date":"2022-03-07T12:03:00.000Z","updated":"2022-03-07T13:01:58.232Z","comments":true,"path":"2022/03/07/Spring-AOP-一世/","link":"","permalink":"http://example.com/2022/03/07/Spring-AOP-%E4%B8%80%E4%B8%96/","excerpt":"","text":"AOP的Joinpoint可以有许多类型，入构造方法调用、字段的设置及获取、方法调用等。但是在Spring AOP中，仅支持方法级别的Joinpoint。更确切的说，只支持方法执行类型的Joinpoint Spring中以接口定义Pointcut作为其AOP框架中所有Pointcut的最顶级抽象，该接口定义了两个方法来捕获系统中相应的Joinpoint，并提供了一个TruePointcut类型实例。如果Pointcut类型为TruePointcut，默认会对系统中的所有对象，以及对象上所有被支持的Joinpoint进行匹配。 ClassFileter和MethodMatcher分别用于匹配将被执行织入操作的对象以及相应的方法。（重用不同级别的匹配定义，并且可以在不同或相同的级别上进行组合操作，或者强制让某个子类只覆写相应的方法） Spring中各种advice实现全部遵循AOP ALLiance规定的接口。 advice实现了将被织入到Pointcut规定的Joinpoint处的横切逻辑。在Spring中，advice按照其自身实例能否在目标对象类的所有实例中共享这一标准，可以划分为两大类（per-class和per-instance） per-class类型的advice：该类型可以在目标对象类的所有实例之间共享。这种类型的advice通常只提供方法拦截的功能。不会为目标对象类保存任何状态或添加新特性。除了上图没有列出的intriuduction类型的advice外，其余都属于pre-class。（如：BeforeAdvice、ThrowsAdvic、AfterReturningAdvice、AroundAdvice等） per-instance类型的advice：introduction是唯一的一种per-instance型advice。其可以在不改目标类定义的情况下，为目标类添加新的属性和行为。 当所有的Pointcut和advice准备好之后，就可以将其装入Aspect。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"}],"author":"John Doe"},{"title":"Spring AOP的实现机制","slug":"Spring-AOP的实现机制","date":"2022-03-07T11:43:00.000Z","updated":"2022-03-07T11:57:38.005Z","comments":true,"path":"2022/03/07/Spring-AOP的实现机制/","link":"","permalink":"http://example.com/2022/03/07/Spring-AOP%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/","excerpt":"","text":"Spring AOP采用动态代理机制（先尝试jdk动态代理，如果没有实现相应接口，则采用cglib字节码生成技术）和字节码生成技术实现（对目标对象进行继承拓展，为其生成相应的子类，子类通过重写来扩展父类的行为，只要将横切逻辑的实现放到子类中，然后让系统使用扩展后的子类即可）。与最初AspectJ采用编译器将横切逻辑织入到目标对象不同，动态代理和字节码生成都是在运行期间为目标对象生成一个代理对象，而将横切逻辑织入到这个代理对象中，系统最终使用的是织入横切逻辑的代理对象而不是真正的目标对象。 注意：动态代理需要实现统一接口，而cglib生成字节码需要方法可以重写","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"}],"author":"John Doe"},{"title":"AOP国家的公民","slug":"AOP国家的公民","date":"2022-03-07T10:33:00.000Z","updated":"2022-03-07T11:39:52.542Z","comments":true,"path":"2022/03/07/AOP国家的公民/","link":"","permalink":"http://example.com/2022/03/07/AOP%E5%9B%BD%E5%AE%B6%E7%9A%84%E5%85%AC%E6%B0%91/","excerpt":"","text":"Joinpoint：在系统运行前，AOP的功能模块都需要编织入OOP的功能模块中。所以，要进行这种编织，我们需要在哪些执行点进行。这些将要在其上执行编织操作的系统执行点即称之为Joinpoint。 Pointcut：Pointcut是Joinpoint的表达方式。将横切逻辑编织入当前系统的过程中，需要参考Pointcut规定的Joinpoint信息，才可以指定应该往系统的哪些Joinpoint上编织横切逻辑。即声明了一个Pointcut就指定了系统中符合条件的一组Joinpoint。 advice：advice是单一横切关注点逻辑的载体，它代表将会编织到Joinpoint的横切逻辑。如果将Aspect比作OOP中的class，那么advice就相当于class中的method。（常见的如before advice、after advice、after returning advice、after throwing advice，after advice、around advice等） Aspect：Aspect是对系统中横切关注点进行模块化封装的AOP概念实体。通常情况下，Aspect可以含有多个Pointcut以及相关Advice定义。 织入和织入器：织入过程就是“飞架”AOP和OOP的那座桥，只有经过织入过程后，以Aspect模块化的横切关注点才会集成到OOP的现存系统中。而完成织入过程的那个人就是织入器。AspectJ有专门的编译器来完成织入操作，即ajc，所有ajc就是AspectJ完成织入的织入器；JBossAOP采用自定义的类加载器完成最终织入，那么这个类加载器就是他的织入器。SpringAOP使用一组自定义的类来完成最终的织入操作，proxyFactory类则是SpringAOP中最通用的织入器。 目标对象：符合Pointcut所指定的条件，将在织入过程中被织入横切逻辑的对象，称为目标对象。 当把所有这些概念组织到一个场景后，就有如下一副场景图：","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"}],"author":"John Doe"},{"title":"为什么需要AOP？","slug":"为什么需要AOP？","date":"2022-03-07T08:29:00.000Z","updated":"2022-03-07T08:46:14.426Z","comments":true,"path":"2022/03/07/为什么需要AOP？/","link":"","permalink":"http://example.com/2022/03/07/%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81AOP%EF%BC%9F/","excerpt":"","text":"软件开发的目的最终是为了解决各种需求，包括业务需求和系统需求。使用面向对象的思想，我们可以对业务需求等普通关注点进行很好的抽象和封装，并且使之模块化。但对于系统需求一类的关注点来说，情况有所不同。 对于业务需求而言，需求与具体实现直接的关系基本上是一对一的。我们可以在系统中某一个确定的点找到针对这种需求的实现。 但是在开发测试中或者进入生产环境后需要对系统进行监控，我们需要添加日志功能，除此之外，业务方法的执行可能需要一定的权限限制。那么方法执行前需要有相应的安全检查功能。对于这些系统需求，想要以面向对象的方式实现并集成待整个系统中，不仅仅是一个需求对应一个实现那么简单。可能遍布所有的业务对象。 因此，提出了AOP（面向切面编程），我们可以对类似于logging和security等系统需求进行模块化组织，简化系统需求和实现的对比关系，进而使得整个系统的实现更具模块化。 AOP是一种理念，其实现需要一种方式。就好似OOP需要对应的语言支撑一样。AOP也需要某种语言帮助实现相应的概念实体（AOL）。 静态AOP：相应的横切关注点以Aspect形式实现后，会通过特定的编译器，将实现后的Aspect编织到系统的静态类中。 静态AOP的优点：Aspect直接以java字节码的形式编译到java类。jvm可以想运行类一样运行，不会对系统造成任何性能损失。 静态AOP的缺点：灵活性不够，如果横切关注点需要改变织入位置，需要重新修改Aspect，编织进系统。 动态AOP：AOP的各种概念实体全部都是put的java类，所有容易开发和基础。Aspect和class一样以类的身份作为系统的一员。其织入过程在运行时进行，而不是预先编译织入。而且信息可以采用外部xml等形式保存，在调制编织点时不必变更系统其他模块，甚至在系统运行时，动态更改。但其缺点也很明显，就是在运行时编织，会造成一点的运行时性能损失。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"}],"author":"John Doe"},{"title":"创建者模式对比","slug":"创建者模式对比","date":"2022-03-07T07:55:00.000Z","updated":"2022-03-07T07:58:03.500Z","comments":true,"path":"2022/03/07/创建者模式对比/","link":"","permalink":"http://example.com/2022/03/07/%E5%88%9B%E5%BB%BA%E8%80%85%E6%A8%A1%E5%BC%8F%E5%AF%B9%E6%AF%94/","excerpt":"","text":"工厂方法模式vs建造者模式 工厂方法模式注重的是整体对象的创建方式；而建造者模式注重的是部件构建的过程，意在通过一步一步地精确构造创建出一个复杂的对象。 我们举个简单例子来说明两者的差异，如要制造一个超人，如果使用工厂方法模式，直接产生出来的就是一个力大无穷、能够飞翔、内裤外穿的超人；而如果使用建造者模式，则需要组装手、头、脚、躯干等部分，然后再把内裤外穿，于是一个超人就诞生了。 抽象工厂模式vs建造者模式 抽象工厂模式实现对产品家族的创建，一个产品家族是这样的一系列产品：具有不同分类维度的产品组合，采用抽象工厂模式则是不需要关心构建过程，只关心什么产品由什么工厂生产即可。 建造者模式则是要求按照指定的蓝图建造产品，它的主要目的是通过组装零配件而产生一个新产品。 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"创建者模式","slug":"创建者模式","permalink":"http://example.com/tags/%E5%88%9B%E5%BB%BA%E8%80%85%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"建造者模式","slug":"建造者模式","date":"2022-03-07T07:49:00.000Z","updated":"2022-03-07T07:55:15.846Z","comments":true,"path":"2022/03/07/建造者模式/","link":"","permalink":"http://example.com/2022/03/07/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"概述：将一个复杂对象的构建与表示分离，使得同样的构建过程可以创建不同的表示。 分离了部件的构造(由Builder来负责)和装配(由Director负责)。 从而可以构造出复杂的对象。这个模式适用于：某个对象的构建过程复杂的情况。 由于实现了构建和装配的解耦。不同的构建器，相同的装配，也可以做出不同的对象；相同的构建器，不同的装配顺序也可以做出不同的对象。也就是实现了构建算法、装配算法的解耦，实现了更好的复用。 建造者模式可以将部件和其组装过程分开，一步一步创建一个复杂的对象。用户只需要指定复杂对象的类型就可以得到该对象，而无须知道其内部的具体构造细节。 结构： 抽象建造者类（Builder）：这个接口规定要实现复杂对象的那些部分的创建，并不涉及具体的部件对象的创建。 具体建造者类（ConcreteBuilder）：实现 Builder 接口，完成复杂产品的各个部件的具体创建方法。在构造过程完成后，提供产品的实例。 产品类（Product）：要创建的复杂对象。 指挥者类（Director）：调用具体建造者来创建复杂对象的各个部分，在指导者中不涉及具体产品的信息，只负责保证对象各部分完整创建或按某种顺序创建。 优点：建造者模式的封装性很好。使用建造者模式可以有效的封装变化，在使用建造者模式的场景中，一般产品类和建造者类是比较稳定的，因此，将主要的业务逻辑封装在指挥者类中对整体而言可以取得比较好的稳定性。 在建造者模式中，客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。 可以更加精细地控制产品的创建过程 。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。 建造者模式很容易进行扩展。如果有新的需求，通过实现一个新的建造者类就可以完成，基本上不用修改之前已经测试通过的代码，因此也就不会对原有功能引入风险。符合开闭原则。 缺点：造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，则不适合使用建造者模式，因此其使用范围受到一定的限制。 使用场景： 创建的对象较复杂，由多个部件构成，各部件面临着复杂的变化，但构件间的建造顺序是稳定的。 创建复杂对象的算法独立于该对象的组成部分以及它们的装配方式，即产品的构建过程和最终的表示是独立的。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"建造者模式","slug":"建造者模式","permalink":"http://example.com/tags/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"原型模式","slug":"原型模式","date":"2022-03-07T07:41:00.000Z","updated":"2022-03-07T07:48:09.685Z","comments":true,"path":"2022/03/07/原型模式/","link":"","permalink":"http://example.com/2022/03/07/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"概述：用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型对象相同的新对象。 结构：原型模式包含如下角色：抽象原型类：规定了具体原型对象必须实现的的 clone() 方法。具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。访问类：使用具体原型类中的 clone() 方法来复制新的对象。 原型模式的克隆分为浅克隆和深克隆。 浅克隆：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。 深克隆：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。（使用对象流，先将原型对象存入file，然后从file读取，即为深克隆） Java中的Object类中提供了clone() 方法来实现浅克隆。 Cloneable 接口是上面的类图中的抽象原型类，而实现了Cloneable接口的子实现类就是具体的原型类。 使用场景：对象的创建非常复杂，可以使用原型模式快捷的创建对象。性能和安全要求比较高。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"原型模式","slug":"原型模式","permalink":"http://example.com/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"工厂模式","slug":"工厂模式","date":"2022-03-07T01:24:00.000Z","updated":"2022-03-07T01:39:37.035Z","comments":true,"path":"2022/03/07/工厂模式/","link":"","permalink":"http://example.com/2022/03/07/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"在java中，万物皆对象，这些对象都需要创建，如果创建的时候直接new该对象，就会对该对象耦合严重，假如我们要更换对象，所有new对象的地方都需要修改一遍，这显然违背了软件设计的开闭原则。如果我们使用工厂来生产对象，我们就只和工厂打交道就可以了，彻底和对象解耦，如果要更换对象，直接在工厂里更换该对象即可，达到了与对象解耦的目的；所以说，工厂模式最大的优点就是：解耦。 1、简单工厂模式：简单工厂不是一种设计模式，反而比较像是一种编程习惯。 结构： 简单工厂包含如下角色： 抽象产品 ：定义了产品的规范，描述了产品的主要特性和功能。 具体产品 ：实现或者继承抽象产品的子类 具体工厂 ：提供了创建产品的方法，调用者通过该方法来获取产品。 优点：封装了创建对象的过程，可以通过参数直接获取对象。把对象的创建和业务逻辑层分开，这样以后就避免了修改客户代码，如果要实现新产品直接修改工厂类，而不需要在原代码中修改，这样就降低了客户代码修改的可能性，更加容易扩展。 缺点：增加新产品时还是需要修改工厂类的代码，违背了“开闭原则”。 拓展：静态工厂– 在开发中也有一部分人将工厂类中的创建对象的功能定义为静态的，这个就是静态工厂模式，它也不是23种设计模式中的。 2、工厂方法模式：使用工厂方法模式就可以完美的解决，完全遵循开闭原则。 概念：定义一个用于创建对象的接口，让子类决定实例化哪个产品类对象。工厂方法使一个产品类的实例化延迟到其工厂的子类。 结构： 工厂方法模式的主要角色： 抽象工厂（Abstract Factory）：提供了创建产品的接口，调用者通过它访问具体工厂的工厂 方法来创建产品。 具体工厂（ConcreteFactory）：主要是实现抽象工厂中的抽象方法，完成具体产品的创建。 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能。 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间一一对应。 优点：用户只需要知道具体工厂的名称就可得到所要的产品，无须知道产品的具体创建过程；在系统增加新的产品时只需要添加具体产品类和对应的具体工厂类，无须对原工厂进行任何修改，满足开闭原则； 缺点：每增加一个产品就要增加一个具体产品类和一个对应的具体工厂类，这增加了系统的复杂度。 3、抽象工厂模式：是一种为访问类提供一个创建一组相关或相互依赖对象的接口，且访问类无须指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。 结构： 抽象工厂模式的主要角色如下： 抽象工厂（Abstract Factory）：提供了创建产品的接口，它包含多个创建产品的方法，可以创建多个不同等级的产品。 具体工厂（Concrete Factory）：主要是实现抽象工厂中的多个抽象方法，完成具体产品的创建。 抽象产品（Product）：定义了产品的规范，描述了产品的主要特性和功能，抽象工厂模式有多个抽象产品。 具体产品（ConcreteProduct）：实现了抽象产品角色所定义的接口，由具体工厂来创建，它同具体工厂之间是多对一的关系。 优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 缺点：当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。 使用场景： 当需要创建的对象是一系列相互关联或相互依赖的产品族时，如电器工厂中的电视机、洗衣机、空调等。 系统中有多个产品族，但每次只使用其中的某一族产品。如有人只喜欢穿某一个品牌的衣服和鞋。 系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。 如：输入法换皮肤，一整套一起换。生成不同操作系统的程序。 模式拓展（简单工厂+配置文件解除耦合）：可以通过工厂模式+配置文件的方式解除工厂对象和产品对象的耦合。在工厂类中加载配置文件中的全类名，并创建对象进行存储，客户端如果需要对象，直接进行获取即可。 jdk中的工厂方法使用： 1、集合-迭代器2、DateForamt类中的getInstance()方法使用的是工厂模式；3、Calendar类中的getInstance()方法使用的是工厂模式；","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"工厂模式","slug":"工厂模式","permalink":"http://example.com/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"elementData设置成了transient，那ArrayList是怎么把元素序列化的呢？","slug":"elementData设置成了transient，那ArrayList是怎么把元素序列化的呢？","date":"2022-03-05T05:00:00.000Z","updated":"2022-03-05T05:03:07.952Z","comments":true,"path":"2022/03/05/elementData设置成了transient，那ArrayList是怎么把元素序列化的呢？/","link":"","permalink":"http://example.com/2022/03/05/elementData%E8%AE%BE%E7%BD%AE%E6%88%90%E4%BA%86transient%EF%BC%8C%E9%82%A3ArrayList%E6%98%AF%E6%80%8E%E4%B9%88%E6%8A%8A%E5%85%83%E7%B4%A0%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84%E5%91%A2%EF%BC%9F/","excerpt":"","text":"查看writeObject()方法可知，先调用s.defaultWriteObject()方法，再把size写入到流中，再把元素一个一个的写入到流中。 一般地，只要实现了Serializable接口即可自动序列化，writeObject()和readObject()是为了自己控制序列化的方式，这两个方法必须声明为private，在java.io.ObjectStreamClass#getPrivateMethod()方法中通过反射获取到writeObject()这个方法。 在ArrayList的writeObject()方法中先调用了s.defaultWriteObject()方法，这个方法是写入非static非transient的属性，在ArrayList中也就是size属性。同样地，在readObject()方法中先调用了s.defaultReadObject()方法解析出了size属性。 elementData定义为transient的优势，自己根据size序列化真实的元素，而不是根据数组的长度序列化元素，减少了空间占用。 源码如下： private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // 防止序列化期间有修改 int expectedModCount = modCount; // 写出非transient非static属性（会写出size属性） s.defaultWriteObject(); // 写出元素个数 s.writeInt(size); // 依次写出元素 for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; // 如果有修改，抛出异常 if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; // 声明为空数组 elementData = EMPTY_ELEMENTDATA; // 读入非transient非static属性（会读取size属性） s.defaultReadObject(); // 读入元素个数，没什么用，只是因为写出的时候写了size属性，读的时候也要按顺序来读 s.readInt(); if (size &gt; 0) &#123; // 计算容量 int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); // 检查是否需要扩容 ensureCapacityInternal(size); Object[] a = elementData; // 依次读取元素到数组中 for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125; &#125;","categories":[{"name":"集合","slug":"集合","permalink":"http://example.com/categories/%E9%9B%86%E5%90%88/"},{"name":"ArrayList","slug":"集合/ArrayList","permalink":"http://example.com/categories/%E9%9B%86%E5%90%88/ArrayList/"}],"tags":[{"name":"transient","slug":"transient","permalink":"http://example.com/tags/transient/"}],"author":"John Doe"},{"title":"反射和反序列化对单例模式的破坏","slug":"反射和反序列化对单例模式的破坏","date":"2022-03-05T01:45:00.000Z","updated":"2022-03-05T02:44:20.102Z","comments":true,"path":"2022/03/05/反射和反序列化对单例模式的破坏/","link":"","permalink":"http://example.com/2022/03/05/%E5%8F%8D%E5%B0%84%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%AF%B9%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E7%A0%B4%E5%9D%8F/","excerpt":"","text":"除了枚举单列模式外，其余的单例实现方式都有可能被反射和反序列化所破坏。那么如何解决反射和反序列化对单例模式的破坏呢？ 1、反射方式破解单例的解决方法:这种方式比较好理解。当通过反射方式调用构造方法进行创建创建时，直接抛异常。不运行此中操作。 /** * @author atao * @version 1.0.0 * @ClassName Demo7.java * @Description 懒汉式-方式3（双重检查锁）双重检查锁模式是一种非常好的单例实现模式，解决了单例、性能、线程安全问题，上面的双重检 * 测锁模式看上去完美无缺，其实是存在问题，在多线程的情况下，可能会出现空指针问题，出现问 * 题的原因是JVM在实例化对象的时候会进行优化和指令重排序操作。 * 要解决双重检查锁模式带来空指针异常的问题，只需要使用 volatile 关键字, volatile 关 * 键字可以保证可见性和有序性。 * @createTime 2022年03月05日 10:35:00 */ public class Demo7 &#123; private static volatile Demo7 singleton; private Demo7()&#123; // 解决反射对单例模式的破坏 if (singleton != null)&#123; throw new RuntimeException(); &#125; &#125; public static Demo7 getInstance()&#123; if (singleton == null)&#123; synchronized (Demo2.class)&#123; if (singleton == null)&#123; singleton = new Demo7(); &#125; &#125; &#125; return singleton; &#125; &#125; 2、在Singleton类中添加 readResolve() 方法，在反序列化时被反射调用，如果定义了这个方法，就返回这个方法的值，如果没有定义，则返回新new出来的对象。 /** * @author atao * @version 1.0.0 * @ClassName Demo8.java * @Description 懒汉式-方式4（静态内部类方式）静态内部类单例模式中实例由内部类创建，由于 JVM 在加载外部类的过程中, 是不会加载静态 * 内部类的, 只有内部类的属性/方法被调用时才会被加载, 并初始化其静态属性。静态属性由于被 * static 修饰，保证只被实例化一次，并且严格保证实例化顺序。 * @createTime 2022年03月05日 10:37:00 */ public class Demo8 &#123; private Demo8 singleton; private Demo8()&#123; &#125; private static class inner&#123; public static Demo8 singleton = new Demo8(); &#125; public static Demo8 getInstance()&#123; return Demo8.inner.singleton; &#125; /** * 解决反序列化对单例模式的破坏 * @return */ private Object readResolve()&#123; return Demo8.inner.singleton; &#125; &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://example.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"破坏","slug":"破坏","permalink":"http://example.com/tags/%E7%A0%B4%E5%9D%8F/"}],"author":"John Doe"},{"title":"软件设计原则","slug":"软件设计原则","date":"2022-03-04T13:57:00.000Z","updated":"2022-03-04T14:04:16.777Z","comments":true,"path":"2022/03/04/软件设计原则/","link":"","permalink":"http://example.com/2022/03/04/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","excerpt":"","text":"在软件开发中，为了提高软件系统的可维护性和可复用性，增加软件的可扩展性和灵活性，程序员要尽量根据6条原则来开发程序，从而提高软件开发效率、节约软件开发成本和维护成本。 1、开闭原则：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。 简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类。因为抽象灵活性好，适应性广，只要抽象的合理，可以基本保持软件架构的稳定。而软件中易变的细节可以从抽象派生来的实现类来进行扩展，当软件需要发生变化时，只需要根据需求重新派生一个实现类来扩展就可以了。 2、里式替换原则：里氏代换原则是面向对象设计的基本原则之一。任何基类可以出现的地方，子类一定可以出现。通俗理解：子类可以扩展父类的功能，但不能改变父类原有的功能。换句话说，子类继承父类时，除添加新的方法完成新增功能外，尽量不要重写父类的方法。如果通过重写父类的方法来完成新的功能，这样写起来虽然简单，但是整个继承体系的可复用性会比较差，特别是运用多态比较频繁时，程序运行出错的概率会非常大。 3、依赖倒转原则：高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。简单的说就是要求对抽象进行编程，不要对实现进行编程，这样就降低了客户与实现模块间的耦合。 4、接口隔离原则：客户端不应该被迫依赖于它不使用的方法；一个类对另一个类的依赖应该建立在最小的接口上。 5、迪米特法则：迪米特法则又叫最少知识原则。只和你的直接朋友交谈，不跟“陌生人”说话（Talk only to your immediate friends andnot to strangers）。其含义是：如果两个软件实体无须直接通信，那么就不应当发生直接的相互调用，可以通过第三方转发该调用。其目的是降低类之间的耦合度，提高模块的相对独立性。迪米特法则中的“朋友”是指：当前对象本身、当前对象的成员对象、当前对象所创建的对象、当前对象的方法参数等，这些对象同当前对象存在关联、聚合或组合关系，可以直接访问这些对象的方法。 6、合成复用原则：合成复用原则是指：尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。通常类的复用分为继承复用和合成复用两种。继承复用虽然有简单和易实现的优点，但它也存在以下缺点： 继承复用破坏了类的封装性。因为继承会将父类的实现细节暴露给子类，父类对子类是透明的，所以这种复用又称为“白箱”复用。 子类与父类的耦合度高。父类的实现的任何改变都会导致子类的实现发生变化，这不利于类的扩展与维护。 它限制了复用的灵活性。从父类继承而来的实现是静态的，在编译时已经定义，所以在运行时不可能发生变化。采用组合或聚合复用时，可以将已有对象纳入新对象中，使之成为新对象的一部分，新对象可以调用已有对象的功能，它有以下优点： 它维持了类的封装性。因为成分对象的内部细节是新对象看不见的，所以这种复用又称为“黑箱”复用。 对象间的耦合度低。可以在类的成员位置声明抽象。 复用的灵活性高。这种复用可以在运行时动态进行，新对象可以动态地引用与成分对象类型相同的对象。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计原则","slug":"设计原则","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"}],"author":"John Doe"},{"title":"UML类图","slug":"UML类图","date":"2022-03-04T13:51:00.000Z","updated":"2022-03-04T13:57:31.240Z","comments":true,"path":"2022/03/04/UML类图/","link":"","permalink":"http://example.com/2022/03/04/UML%E7%B1%BB%E5%9B%BE/","excerpt":"","text":"属性/方法名称前加的加号和减号表示了这个属性/方法的可见性，UML类图中表示可见性的符号有三种： +：表示public -：表示private #：表示protected 属性的完整表示方式是： 可见性 名称 ：类型 [ = 缺省值]方法的完整表示方式是： 可见性 名称(参数列表) [ ： 返回类型] 类之间关系的表示方式： 1、关联关系：关联关系是对象之间的一种引用关系，用于表示一类对象与另一类对象之间的联系，如老师和学生、师傅和徒弟、丈夫和妻子等。关联关系是类与类之间最常用的一种关系，分为一般关联关系、聚合关系和组合关系。 自关联： 2、聚合关系：聚合关系是关联关系的一种，是强关联关系，是整体和部分之间的关系。聚合关系也是通过成员对象来实现的，其中成员对象是整体对象的一部分，但是成员对象可以脱离整体对象而独立存在。 3、组合关系：组合表示类之间的整体与部分的关系，但它是一种更强烈的聚合关系。在组合关系中，整体对象可以控制部分对象的生命周期，一旦整体对象不存在，部分对象也将不存在，部分对象不能脱离整体对象而存在。 4、依赖关系：依赖关系是一种使用关系，它是对象之间耦合度最弱的一种关联方式，是临时性的关联。在代码中，某个类的方法通过局部变量、方法的参数或者对静态方法的调用来访问另一个类（被依赖类）中的某些方法来完成一些职责。 5、继承关系：继承关系是对象之间耦合度最大的一种关系，表示一般与特殊的关系，是父类与子类之间的关系，是一种继承关系。 6、实现关系：实现关系是接口与实现类之间的关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的所有的抽象操作。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"UML","slug":"UML","permalink":"http://example.com/tags/UML/"}],"author":"John Doe"},{"title":"设计模式的分类","slug":"设计模式的分类","date":"2022-03-04T13:31:00.000Z","updated":"2022-03-04T13:34:39.072Z","comments":true,"path":"2022/03/04/设计模式的分类/","link":"","permalink":"http://example.com/2022/03/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%88%86%E7%B1%BB/","excerpt":"","text":"创建型模式：用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。（单例、原型、工厂方法、抽象工厂、建造者等） 结构型模式：用于描述如何将类或对象按某种布局成更大的结构。（代理、适配器、桥接、装饰、外观、享元、组合等） 行为型模式：用于描述类或对象之间怎样相互协作共同完成单个对象无法单独完成的任务，以及怎样分配职责。（模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等）","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"分类","slug":"分类","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB/"}],"author":"John Doe"},{"title":"将革命进行得更彻底一些（classpath-scanning 功能介绍）","slug":"将革命进行得更彻底一些（classpath-scanning-功能介绍）","date":"2022-03-04T08:23:00.000Z","updated":"2022-03-04T09:01:35.117Z","comments":true,"path":"2022/03/04/将革命进行得更彻底一些（classpath-scanning-功能介绍）/","link":"","permalink":"http://example.com/2022/03/04/%E5%B0%86%E9%9D%A9%E5%91%BD%E8%BF%9B%E8%A1%8C%E5%BE%97%E6%9B%B4%E5%BD%BB%E5%BA%95%E4%B8%80%E4%BA%9B%EF%BC%88classpath-scanning-%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D%EF%BC%89/","excerpt":"","text":"到目前为止，我们还是需要将相应对象的bean定义，一个个地添加到IoC容器的配置文件中。与之前唯一的区别就是，不用在配置文件中明确指定依赖关系了（改用注解来表达了嘛）。。既然使用注解来表达对象之间的依赖注入关系，那为什么不搞的彻底一点儿，将那些几乎“光秃秃”的bean定义从配置文件中彻底消灭呢？OK，我们想到了，Spring开发团队也想到了，classpath-scanning的功能正是因此而诞生的！ 使用相应的注解对组成应用程序的相关类进行标注之后，classpath-scanning功能可以从某一顶层包（base package）开始扫描。当扫描到某个类标注了相应的注解之后，就会提取该类的相关信息，构建对应的BeanDefinition，然后把构建完的BeanDefinition注册到容器。这之后所发生的事情就不用我说了，既然相关的类已经添加到了容器，那么后面BeanPostProcessor为@Autowired或者@Resource所提供的注入肯定是有东西拿咯！ classpath-scanning功能的触发是由context:component-scan决定的。 context:component-scan默认扫描的注解类型是@Component。不过，在@Component语义基础上细化后的@Repository、@Service和@Controller也同样可以获得context:component-scan的青睐。@Component的语义更广、更宽泛，而@Repository、@Service和@Controller的语义则更具体。所以，同样对于服务层的类定义来说，使用@Service标注它，要比使用@Component更为确切。对于其他两种注解也是同样道理，我们暂且使用语义更广的@Component来标注FXNews相关类，以便摆脱每次都要向IoC容器配置添加bean定义的苦恼。 context:component-scan在扫描相关类定义并将它们添加到容器的时候，会使用一种默认的命名规则，来生成那些添加到容器的bean定义的名称（beanName）。比如DowJonesNewsPersister通过默认命名规则将获得dowJonesNewsPersister作为bean定义名称。如果想改变这一默认行为，可以指定一个自定义的名称 你或许会觉得有些诧异，因为我们并没有使用context:annotation-config甚至直接将相应的BeanPostProcessor添加到容器中，而FXNewsProvider怎么会获得相应的依赖注入呢？这个得怪context:component-scan“多管闲事”，它同时将AutowiredAnnotationBeanPostProcessor和CommonAnnotationBeanPostProcessor一并注册到了容器中，所以，依赖注入的需求得以满足。如果你不喜欢，非要自己通过 context:annotation-config 或者直接添加相关 BeanPost\u0002Processor的方式来满足@Autowired或者@Resource的需求，可以将context:component-scan的annotation-config属性值从默认的true改为false。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"注解","slug":"注解","permalink":"http://example.com/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"IOC","slug":"IOC","permalink":"http://example.com/tags/IOC/"}],"author":"John Doe"},{"title":"Autowired之外的选择——使用JSR250 标注依赖注入关系","slug":"Autowired之外的选择——使用JSR250-标注依赖注入关系","date":"2022-03-04T08:20:00.000Z","updated":"2022-03-04T08:22:53.133Z","comments":true,"path":"2022/03/04/Autowired之外的选择——使用JSR250-标注依赖注入关系/","link":"","permalink":"http://example.com/2022/03/04/Autowired%E4%B9%8B%E5%A4%96%E7%9A%84%E9%80%89%E6%8B%A9%E2%80%94%E2%80%94%E4%BD%BF%E7%94%A8JSR250-%E6%A0%87%E6%B3%A8%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E5%85%B3%E7%B3%BB/","excerpt":"","text":"除了可以使用Spring提供的@Autowired和@Qualifier来标注相应类定义之外，还可以使用JSR250的@Resource和@PostConstruct以及@PreDestroy对相应类进行标注，这同样可以达到依赖注入的目的。 @Resource与@Autowired不同，它遵循的是byName自动绑定形式的行为准则，也就是说，IoC容器将根据@Resource所指定的名称，到容器中查找beanName与之对应的实例，然后将查找到的对象实例注入给@Resource所标注的对象。 JSR250规定，如果@Resource标注于属性域或者方法之上的话，相应的容器将负责把指定的资源注入给当前对象，所以，除了像我们这样直接在属性域上标注@Resource，还可以在构造方法或者普通方法定义上标注@Resource，这与@Autowired能够存在的地方大致相同。 确切地说， 10 @PostConstruct和@PreDestroy不是服务于依赖注入的，它们主要用于标注对象生命周期管理相关方法，这与Spring的InitializingBean和DisposableBean接口，以及配置项中的init-method和destroy-method起到类似的作用。 如果想某个方法在对象实例化之后被调用，以做某些准备工作，或者想在对象销毁之前调用某个方法清理某些资源，那么就可以像我们这样，使用@PostConstruct和@PreDestroy来标注这些方法。当然，是使用@PostConstruct和@PreDestroy，还是使用Spring的InitializingBean和Disposable-Bean接口，或者init-method和destroy-method配置项，可以根据个人的喜好自己决定。 天上永远不会掉馅饼，我们只是使用@Resource或者@PostConstruct和@PreDestroy标注了相应对象，并不能给该对象带来想要的东西。所以，就像@Autowired需要AutowiredAnnotationBean\u0002PostProcessor为它与IoC容器牵线搭桥一样，JSR250的这些注解也同样需要一个BeanPost\u0002Processor帮助它们实现自身的价值。这个BeanPostProcessor就是org.springframework.context.annotation.CommonAnnotationBeanPostProcessor，只有将CommonAnnotationBeanPostProcessor添加到容器，JSR250的相关注解才能发挥作用 既然不管是@Autowired还是@Resource都需要添加相应的BeanPostProcessor到容器，那么我们就可以在基于XSD的配置文件中使用一个context:annotation-config配置搞定以上所有的BeanPostProcessor配置 context:annotation-config 不但帮我们把 AutowiredAnnotationBeanPostProcessor 和CommonAnnotationBeanPostProcessor注册到容器，同时还会把PersistenceAnnotationBeanPost\u0002Processor和RequiredAnnotationBeanPostProcessor一并进行注册，可谓一举四得啊！","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://example.com/tags/%E5%AE%B9%E5%99%A8/"},{"name":"注解","slug":"注解","permalink":"http://example.com/tags/%E6%B3%A8%E8%A7%A3/"}],"author":"John Doe"},{"title":"Qualifier的陪伴","slug":"Qualifier的陪伴","date":"2022-03-04T08:19:00.000Z","updated":"2022-03-04T08:20:06.461Z","comments":true,"path":"2022/03/04/Qualifier的陪伴/","link":"","permalink":"http://example.com/2022/03/04/Qualifier%E7%9A%84%E9%99%AA%E4%BC%B4/","excerpt":"","text":"@Autowired是按照类型进行匹配，如果当前@Autowired标注的依赖在容器中只能找到一个实例与之对应的话，那还好。可是，要是能够同时找到两个或者多个同一类型的对象实例，又该怎么办呢？我们自己当然知道应该把具体哪个实例注入给当前对象，可是，IoC容器并不知道，所以，得通过某种方式告诉它。这时，就可以使用@Qualifier对依赖注入的条件做进一步限定，使得容器不再迷茫。 @Qualifier实际上是byName自动绑定的注解版，既然IoC容器无法自己从多个同一类型的实例中选取我们真正想要的那个，那么我们不妨就使用@Qualifier直接点名要哪个好了。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"注解","slug":"注解","permalink":"http://example.com/tags/%E6%B3%A8%E8%A7%A3/"}],"author":"John Doe"},{"title":"Spring基于注解的依赖注入","slug":"Spring基于注解的依赖注入","date":"2022-03-04T08:14:00.000Z","updated":"2022-03-04T08:18:55.251Z","comments":true,"path":"2022/03/04/Spring基于注解的依赖注入/","link":"","permalink":"http://example.com/2022/03/04/Spring%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/","excerpt":"","text":"@Autowired是基于注解的依赖注入的核心注解，它的存在可以让容器知道需要为当前类注入哪些依赖。比如可以使用@Autowired对类进行标注，以表明要为该类注入的依赖。 @Autowired也是按照类型匹配进行依赖注入的 @Autowired可以标注于类定义的多个位置，包括如下几个。 1、域（Filed）或者说属性（Property）。不管它们声明的访问限制符是private、protected还是public，只要标注了@Autowired，它们所需要的依赖注入需求就都能够被满足。 2、构造方法定义（Constructor）。标注于类的构造方法之上的@Autowired，相当于抢夺了原有自动绑定功能中“constructor”方式的权利，它将根据构造方法参数类型，来决定将什么样的依赖对象注入给当前对象。 3、方法定义（Method）。@Autowired不仅可以标注于传统的setter方法之上，而且还可以标注于任意名称的方法定义之上，只要该方法定义了需要被注入的参数。 现在，虽然可以随意地在类定义的各种合适的地方标注@Autowired，希望这些被@Autowired标注的依赖能够被注入，但是，仅将@Autowired标注于类定义中并不能让Spring的IoC容器聪明到自己去查看这些注解，然后注入符合条件的依赖对象。容器需要某种方式来了解，哪些对象标注了@Autowired，哪些对象可以作为可供选择的依赖对象来注入给需要的对象。在考虑使用什么方式实现这一功能之前，我们先比较一下原有的自动绑定功能与使用@Autowired之后产生了哪些差别。 使用自动绑定的时候，我们将所有对象相关的bean定义追加到了容器的配置文件中，然后使用default-autowire或者autowire告知容器，依照这两种属性指定的绑定方式，将容器中各个对象绑定到一起。在使用@Autowired之后，default-autowire或者autowire的职责就转给了@Autowired，所以，现在，容器的配置文件中就只剩下了一个个孤伶伶的bean定义 为了给容器中定义的每个bean定义对应的实例注入依赖，可以遍历它们，然后通过反射，检查每个bean定义对应的类上各种可能位置上的@Autowired。如果存在的话，就可以从当前容器管理的对象中获取符合条件的对象，设置给@Autowired所标注的属性域、构造方法或者方法定义。 我们可以提供一个Spring的IoC容器使用的BeanPostProcessor自定义实现，让这个BeanPostProcessor在实例化bean定义的过程中，来检查当前对象是否有@Autowired标注的依赖需要注入。org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor就是Spring提供的用于这一目的的BeanPostProcessor实现。所以，很幸运，我们不用自己去实现它了。 相关类定义使用@Autowired标注之后，只要在IoC容器的配置文件中追加Autowired\u0002AnnotationBeanPostProcessor就可以让整个应用开始运作了","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"注解","slug":"注解","permalink":"http://example.com/tags/%E6%B3%A8%E8%A7%A3/"}],"author":"John Doe"},{"title":"ApplicationContext统一资源加载策略","slug":"ApplicationContext统一资源加载策略","date":"2022-03-04T07:24:00.000Z","updated":"2022-03-04T07:55:24.970Z","comments":true,"path":"2022/03/04/ApplicationContext统一资源加载策略/","link":"","permalink":"http://example.com/2022/03/04/ApplicationContext%E7%BB%9F%E4%B8%80%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD%E7%AD%96%E7%95%A5/","excerpt":"","text":"Spring框架内部使用org.springframework.core.io.Resource接口作为所有资源的抽象和访问接口 其中ClassPathResource就是Resource的一个特定类型的实现，代表的是位于Classpath中的资源。 Resource接口可以根据资源的不同类型，或者资源所处的不同场合，给出相应的具体实现。Spring框架在这个理念的基础上，提供了一些实现类（可以在org.springframework.core.io包下找到这些实现类）。  ByteArrayResource。将字节（byte）数组提供的数据作为一种资源进行封装，如果通过InputStream形式访问该类型的资源，该实现会根据字节数组的数据，构造相应的ByteArray\u0002InputStream并返回。  ClassPathResource。该实现从Java应用程序的ClassPath中加载具体资源并进行封装，可以使用指定的类加载器（ClassLoader）或者给定的类进行资源加载。  FileSystemResource。对java.io.File类型的封装，所以，我们可以以文件或者URL的形式对该类型资源进行访问，只要能跟File打的交道，基本上跟FileSystemResource也可以。  UrlResource。通过java.net.URL进行的具体资源查找定位的实现类，内部委派URL进行具体的资源操作。  InputStreamResource。将给定的InputStream视为一种资源的Resource实现类，较为少用。可能的情况下，以ByteArrayResource以及其他形式资源实现代之。 如果给定的实现类不满足需求，还可以通过实现Resource接口自定义。 org.spr\u0002ingframework.core.io.ResourceLoader接口是资源查找定位策略的统一抽象，具体的资源查找定位策略则由相应的ResourceLoader实现类给出。 其中最主要的就是Resource getResource(String location);方法，通过它，我们就可以根据指定的资源位置，定位到具体的资源实例。 1、可用的ResourceLoader： ResourceLoader有一个默认的实现类，即org.springframework.core.io.DefaultResource\u0002Loader，该类默认的资源查找处理逻辑如下。 (1) 首先检查资源路径是否以classpath:前缀打头，如果是，则尝试构造ClassPathResource类型资源并返回。 (2) 否则，(a) 尝试通过URL，根据资源路径来定位资源，如果没有抛出MalformedURLException，有则会构造UrlResource类型的资源并返回；(b)如果还是无法根据资源路径定位指定的资源，则委派getResourceByPath(String) 方法来定位， DefaultResourceLoader 的getResourceByPath(String)方法默认实现逻辑是，构造ClassPathResource类型的资源并返回。 为了避免DefaultResourceLoader在最后getResourceByPath(String)方法上的不恰当处理，我们可以使用org.springframework.core.io.FileSystemResourceLoader，它继承自Default\u0002ResourceLoader，但覆写了getResourceByPath(String)方法，使之从文件系统加载资源并以FileSystemResource类型返回。这样，我们就可以取得预想的资源类型。 FileSystemResourceLoader在ResourceLoader家族中的兄弟FileSystemXmlApplication\u0002Context，也是覆写了getResourceByPath(String)方法的逻辑，以改变DefaultResourceLoader的默认资源加载行为，最终从文件系统中加载并返回FileSystemResource类型的资源。 2、 ResourcePatternResolver ——批量查找的ResourceLoader： ResourcePatternResolver是ResourceLoader的扩展，ResourceLoader每次只能根据资源路径返回确定的单个Resource实例，而ResourcePatternResolver则可以根据指定的资源路径匹配模式，每次返回多个Resource实例。 ResourcePatternResolver在继承ResourceLoader原有定义的基础上，又引入了Resource[]getResources(String)方法定义，以支持根据路径匹配模式返回多个Resources的功能。它同时还引入了一种新的协议前缀classpath*:，针对这一点的支持，将由相应的子类实现给出。 ResourcePatternResolver最常用的一个实现是org.springframework.core.io.support.PathMatchingResourcePatternResolver，该实现类支持ResourceLoader级别的资源加载，支持基于Ant风格的路径匹配模式（类似于**/.suffix之类的路径形式），支持ResourcePatternResolver新增加的classpath:前缀等，基本上集所有技能于一身。 在构造PathMatchingResourcePatternResolver实例的时候，可以指定一个ResourceLoader，如果不指定的话，则PathMatchingResourcePatternResolver内部会默认构造一个Default\u0002ResourceLoader实例。PathMatchingResourcePatternResolver内部会将匹配后确定的资源路径，委派给它的ResourceLoader来查找和定位资源。这样，如果不指定任何ResourceLoader的话，Path\u0002MatchingResourcePatternResolver在加载资源的行为上会与DefaultResourceLoader基本相同，只存在返回的Resource数量上的差异。 不过，可以通过传入其他类型的ResourceLoader来替换PathMatchingResourcePatternResolver内部默认使用的DefaultResourceLoader，从而改变其默认行为。 ApplicationContext继承了ResourcePatternResolver，当然就间接实现了ResourceLoader接口。所以，任何的ApplicationContext实现都可以看作是一个ResourceLoader甚至ResourcePatternResolver。而这就是ApplicationContext支持Spring内统一资源加载策略的真相。 通常，所有的ApplicationContext实现类会直接或者间接地继承org.springframework.context.support.AbstractApplicationContext，从这个类上，我们就可以看到Application\u0002Context与ResourceLoader之间的所有关系。AbstractApplicationContext继承了DefaultRe\u0002sourceLoader，那么，它的getResource(String)当然就直接用DefaultResourceLoader的了。剩下需要它“效劳”的，就是ResourcePatternResolver的Resource[]getResources (String)，当然，AbstractApplicationContext也不负众望，当即拿下。AbstractApplicationContext类的内部声明有一个resourcePatternResolver，类型是ResourcePatternResolver，对应的实例类型为PathMatchingResourcePatternResolver 。之前我们说过 PathMatchingResourcePattern\u0002Resolver构造的时候会接受一个ResourceLoader，而AbstractApplicationContext本身又继承自DefaultResourceLoader，当然就直接把自身给“贡献”了。这样，整个ApplicationContext的实现类就完全可以支持ResourceLoader或者ResourcePatternResolver接口，你能说Application\u0002Context不支持Spring的统一资源加载吗？说白了，ApplicationContext的实现类在作为Resource\u0002Loader或者ResourcePatternResolver时候的行为，完全就是委派给了PathMatchingResource\u0002PatternResolver和DefaultResourceLoader来做。 1、既然ApplicationContext可以作为ResourceLoader或者ResourcePatternResolver来使用，那么，很显然，我们可以通过ApplicationContext来加载任何Spring支持的Resource类型。与直接使用ResourceLoader来做这些事情相比，很明显，ApplicationContext的表现过于“谦虚”了。 2、ApplicationContext容器本身就是一个ResourceLoader，我们为了该类还需要单独提供一个resourceLoader实例就有些多于了，直接将当前的ApplicationContext容器作为Resource\u0002Loader注入不就行了？而ResourceLoaderAware和ApplicationContextAware接口正好可以帮助我们做到这一点，只不过现在的FooBar需要依赖于Spring的API了。不过，在我看来，这没有什么大不了，因为我们从来也没有真正逃脱过依赖（这种依赖也好，那种依赖也罢）。 3、容器可以将bean定义文件中的字符串形式表达的信息，正确地转换成具体对象定义的依赖类型。对于那些Spring容器提供的默认的PropertyEditors无法识别的对象类型，我们可以提供自定义的PropertyEditor实现并注册到容器中，以供容器做类型转换的时候使用。默认情况下，BeanFactory容器不会为org.springframework.core.io.Resource类型提供相应的Property\u0002Editor，所以，如果我们想注入Resource类型的bean定义，就需要注册自定义的PropertyEditor到BeanFactory容器。不过，对于ApplicationContext来说，我们无需这么做，因为Application\u0002Context容器可以正确识别Resource类型并转换后注入相关对象。 4、特定的 10 ApplicationContext容器实现，在作为ResourceLoader加载资源时，会有其特定的行为。我们下面主要讨论两种类型的ApplicationContext容器，即ClassPathXmlApplicationContext和FileSystemXmlApplicationContext。其他类型的ApplicationContext容器，会在稍后章节中提到。 11我们知道，对于URL所接受的资源路径来说，通常开始都会有一个协议前缀，比如file:、http:、ftp:等。既然Spring使用UrlResource对URL定位查找的资源进行了抽象，那么，同样也支持这样类型的资源路径，而且，在这个基础上，Spring还扩展了协议前缀的集合。ResourceLoader中增加了一种新的资源路径协议——classpath:，ResourcePatternResolver又增加了一种——classpath*:。这样，我们就可以通过这些资源路径协议前缀，明确地告知Spring容器要从classpath中加载资源 当ClassPathXmlApplicationContext在实例化的时候，即使没有指明classpath:或者classpath*:等前缀，它会默认从classpath中加载bean定义配置文件 而FileSystemXmlApplicationContext则有些不同，如果我们像如下代码那样指定conf/appContext.xml，它会尝试从文件系统中加载bean定义文件 不过，我们可以像如下代码所示，通过在资源路径之前增加classpath:前缀，明确指定FileSystemXmlApplicationContext从classpath中加载bean定义的配置文件","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"资源加载","slug":"资源加载","permalink":"http://example.com/tags/%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD/"},{"name":"容器","slug":"容器","permalink":"http://example.com/tags/%E5%AE%B9%E5%99%A8/"}],"author":"John Doe"},{"title":"Spring IoC容器 ApplicationContext","slug":"Spring-IoC容器-ApplicationContext","date":"2022-03-04T07:21:00.000Z","updated":"2022-03-04T07:23:24.352Z","comments":true,"path":"2022/03/04/Spring-IoC容器-ApplicationContext/","link":"","permalink":"http://example.com/2022/03/04/Spring-IoC%E5%AE%B9%E5%99%A8-ApplicationContext/","excerpt":"","text":"作为Spring提供的较之BeanFactory更为先进的IoC容器实现，ApplicationContext除了拥有BeanFactory支持的所有功能之外，还进一步扩展了基本容器的功能，包括BeanFactoryPostProces\u0002sor、BeanPostProcessor以及其他特殊类型bean的自动识别、容器启动后bean实例的自动初始化、国际化的信息支持、容器内事件发布等。 常见的ApplicationContext实现类有 org.springframework.context.support.FileSystemXmlApplicationContext。在默认情况下，从文件系统加载bean定义以及相关资源的ApplicationContext实现。 org.springframework.context.support.ClassPathXmlApplicationContext。在默认情况下，从Classpath加载bean定义以及相关资源的ApplicationContext实现。 org.springframework.web.context.support.XmlWebApplicationContext。Spring提供的用于Web应用程序的ApplicationContext实现","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://example.com/tags/%E5%AE%B9%E5%99%A8/"}],"author":"John Doe"},{"title":"了解Spring中bean的一生","slug":"了解Spring中bean的一生","date":"2022-03-04T06:10:00.000Z","updated":"2022-03-04T06:52:30.847Z","comments":true,"path":"2022/03/04/了解Spring中bean的一生/","link":"","permalink":"http://example.com/2022/03/04/%E4%BA%86%E8%A7%A3Spring%E4%B8%ADbean%E7%9A%84%E4%B8%80%E7%94%9F/","excerpt":"","text":"容器启动之后，并不会马上就实例化相应的bean定义。我们知道，容器现在仅仅拥有所有对象的BeanDefinition来保存实例化阶段将要用的必要信息。只有当请求方通过BeanFactory的getBean()方法来请求某个对象实例的时候，才有可能触发Bean实例化阶段的活动。BeanFactory的getBean（）法可以被客户端对象显式调用，也可以在容器内部隐式地被调用。隐式调用有如下两种情况。  对于BeanFactory来说，对象实例化默认采用延迟初始化。通常情况下，当对象A被请求而需要第一次实例化的时候，如果它所依赖的对象B之前同样没有被实例化，那么容器会先实例化对象A所依赖的对象。这时容器内部就会首先实例化对象B，以及对象 A依赖的其他还没有实例化的对象。这种情况是容器内部调用getBean()，对于本次请求的请求方是隐式的。  ApplicationContext启动之后会实例化所有的bean定义，但ApplicationContext在实现的过程中依然遵循Spring容器实现流程的两个阶段，只不过它会在启动阶段的活动完成之后，紧接着调用注册到该容器的所有bean定义的实例化方法getBean()。这就是为什么当你得到ApplicationContext类型的容器引用时，容器内所有对象已经被全部实例化完成。不信你查一下类org.AbstractApplicationContext的refresh()方法。 1、 Bean的实例化与 BeanWrapper：容器在内部实现的时候，采用“策略模式（Strategy Pattern）”来决定采用何种方式初始化bean实例。通常，可以通过反射或者CGLIB动态字节码生成来初始化相应的bean实例或者动态生成其子类。 org.springframework.beans.factory.support.InstantiationStrategy定义是实例化策略的抽象接口，其直接子类SimpleInstantiationStrategy实现了简单的对象实例化功能，可以通过反射来实例化对象实例，但不支持方法注入方式的对象实例化。CglibSubclassingInstantiation\u0002Strategy继承了SimpleInstantiationStrategy的以反射方式实例化对象的功能，并且通过CGLIB的动态字节码生成功能，该策略实现类可以动态生成某个类的子类，进而满足了方法注入所需的对象实例化需求。默认情况下，容器内部采用的是CglibSubclassingInstantiationStrategy。 容器只要根据相应bean定义的BeanDefintion取得实例化信息，结合CglibSubclassingIns\u0002tantiationStrategy以及不同的bean定义类型，就可以返回实例化完成的对象实例。但是，返回方式上有些“点缀”。不是直接返回构造完成的对象实例，而是以BeanWrapper对构造完成的对象实例进行包裹，返回相应的BeanWrapper实例。 BeanWrapper接口通常在Spring框架内部使用，它有一个实现类org.springframework.beans.BeanWrapperImpl。其作用是对某个bean进行“包裹”，然后对这个“包裹”的bean进行操作，比如设置或者获取bean的相应属性值。而在第一步结束后返回BeanWrapper实例而不是原先的对象实例，就是为了第二步“设置对象属性”。 BeanWrapper定义继承了org.springframework.beans.PropertyAccessor接口，可以以统一的方式对对象属性进行访问；BeanWrapper定义同时又直接或者间接继承了PropertyEditorRegistry和TypeConverter接口。不知你是否还记得CustomEditorConfigurer？当把各种PropertyEditor注册给容器时，知道后面谁用到这些PropertyEditor吗？对，就是BeanWrapper！在第一步构造完成对象之后，Spring会根据对象实例构造一个BeanWrapperImpl实例，然后将之前CustomEditor\u0002Configurer注册的PropertyEditor复制一份给BeanWrapperImpl实例（这就是BeanWrapper同时又是PropertyEditorRegistry的原因）。这样，当BeanWrapper转换类型、设置对象属性值时，就不会无从下手了。 2、 各色的Aware接口： 当对象实例化完成并且相关属性以及依赖设置完成之后，Spring容器会检查当前对象实例是否实现了一系列的以Aware命名结尾的接口定义。如果是，则将这些Aware接口定义中规定的依赖注入给当前对象实例。 3、 BeanPostProcessor BeanPostProcessor的概念容易与BeanFactoryPostProcessor的概念混淆。但只要记住Bean\u0002PostProcessor是存在于对象实例化阶段，而BeanFactoryPostProcessor则是存在于容器启动阶段，这两个概念就比较容易区分了。 与BeanFactoryPostProcessor通常会处理容器内所有符合条件的BeanDefinition类似，Bean\u0002PostProcessor会处理容器内所有符合条件的实例化后的对象实例。该接口声明了两个方法，分别在两个不同的时机执行。postProcessBeforeInitialization()方法是BeanPostProcessor前置处理这一步将会执行的方法，postProcessAfterInitialization()则是对应BeanPostProcessor后置处理那一步将会执行的方法。BeanPostProcessor的两个方法中都传入了原来的对象实例的引用，这为我们扩展容器的对象实例化过程中的行为提供了极大的便利，我们几乎可以对传入的对象实例执行任何的操作。 通常比较常见的使用BeanPostProcessor的场景，是处理标记接口实现类，或者为当前对象提供代理实现。除了检查标记接口以便应用自定义逻辑，还可以通过BeanPostProcessor对当前对象实例做更多的处理。比如替换当前对象实例或者字节码增强当前对象实例等。Spring的AOP则更多地使用BeanPostProcessor来为对象生成相应的代理对象，如org.springframework.aop.framework.autoproxy.BeanNameAutoProxyCreator。 4、 InitializingBean和init-method： org.springframework.beans.factory.InitializingBean是容器内部广泛使用的一个对象生命周期标识接口 该接口定义很简单，其作用在于，在对象实例化过程调用过“BeanPostProcessor的前置处理”之后，会接着检测当前对象是否实现了InitializingBean接口，如果是，则会调用其afterProper\u0002tiesSet()方法进一步调整对象实例的状态。比如，在有些情况下，某个业务对象实例化完成后，还不能处于可以使用状态。这个时候就可以让该业务对象实现该接口，并在方法afterPropertiesSet()中完成对该业务对象的后续处理。 虽然该接口在Spring容器内部广泛使用，但如果真的让我们的业务对象实现这个接口，则显得Spring容器比较具有侵入性。所以，Spring还提供了另一种方式来指定自定义的对象初始化操作，那就是在XML配置的时候，使用的init-method属性。 通过init-method，系统中业务对象的自定义初始化操作可以以任何方式命名，而不再受制于InitializingBean的afterPropertiesSet()。如果系统开发过程中规定：所有业务对象的自定义初始化操作都必须以init()命名，为了省去挨个的设置init-method这样的烦琐，我们还可以通过最顶层的的default-init-method统一指定这一init()方法名。 5、 DisposableBean与destroy-method： 当所有的一切，该设置的设置，该注入的注入，该调用的调用完成之后，容器将检查singleton类型的bean实例，看其是否实现了org.springframework.beans.factory.DisposableBean接口。或者其对应的bean定义是否通过的destroy-method属性指定了自定义的对象销毁方法。如果是，就会为该实例注册一个用于对象销毁的回调（Callback），以便在这些singleton类型的对象实例销毁之前，执行销毁逻辑。 与InitializingBean和init-method用于对象的自定义初始化相对应，DisposableBean和destroy-method为对象提供了执行自定义销毁逻辑的机会。 最常见到的该功能的使用场景就是在Spring容器中注册数据库连接池，在系统退出后，连接池应该关闭，以释放相应资源。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"bean","slug":"bean","permalink":"http://example.com/tags/bean/"}],"author":"John Doe"},{"title":"插手“容器的启动”","slug":"插手“容器的启动”","date":"2022-03-04T02:33:00.000Z","updated":"2022-03-04T06:09:45.853Z","comments":true,"path":"2022/03/04/插手“容器的启动”/","link":"","permalink":"http://example.com/2022/03/04/%E6%8F%92%E6%89%8B%E2%80%9C%E5%AE%B9%E5%99%A8%E7%9A%84%E5%90%AF%E5%8A%A8%E2%80%9D/","excerpt":"","text":"Spring提供了一种叫做BeanFactoryPostProcessor的容器扩展机制。该机制允许我们在容器实例化相应对象之前，对注册到容器的BeanDefinition所保存的信息做相应的修改。这就相当于在容器实现的第一阶段最后加入一道工序，让我们对最终的BeanDefinition做一些额外的操作，比如修改其中bean定义的某些属性，为bean定义增加其他信息等。 如果要自定义实现BeanFactoryPostProcessor，通常我们需要实org.springframework.beans.factory.config.BeanFactoryPostProcessor接口。同时，因为一个容器可能拥有多个Bean\u0002FactoryPostProcessor，这个时候可能需要实现类同时实现Spring的org.springframework.core.Ordered接口，以保证各个BeanFactoryPostProcessor可以按照预先设定的顺序执行（如果顺序紧要的话）。但是，因为Spring已经提供了几个现成的BeanFactoryPostProcessor实现类，所以，大多时候，我们很少自己去实现某个BeanFactoryPostProcessor。其中，org.springframework.beans.factory.config.PropertyPlaceholderConfigurer和org.springframework.beans.factory. config.Property OverrideConfigurer是两个比较常用的BeanFactoryPostProcessor。另外，为了处理配置文件中的数据类型与真正的业务对象所定义的数据类型转换，Spring还允许我们通过org.springframework.beans.factory.config.CustomEditorConfigurer来注册自定义的Pro\u0002pertyEditor以补助容器中默认的PropertyEditor。可以参考BeanFactoryPostProcessor的Javadoc来了解更多其实现子类的情况。 对于BeanFactory来说，我们需要用手动方式应用所有的BeanFactoryPostProcessor 对于ApplicationContext来说，情况看起来要好得多。因为ApplicationContext会自动识别配置文件中的BeanFactoryPostProcessor并应用它，所以，相对于BeanFactory，在ApplicationContext中加载并应用BeanFactoryPostProcessor，仅需要在XML配置文件中将这些BeanFactoryPost\u0002Processor简单配置一下即可。 1、PropertyPlaceholderConfigurer： 通常情况下，我们不想将类似于系统管理相关的信息同业务对象相关的配置信息混杂到XML配置文件中，以免部署或者维护期间因为改动繁杂的XML配置文件而出现问题。我们会将一些数据库连接信息、邮件服务器等相关信息单独配置到一个properties文件中，这样，如果因系统资源变动的话，只需要关注这些简单properties配置文件即可。PropertyPlaceholderConfigurer允许我们在XML配置文件中使用占位符（PlaceHolder），并将这些占位符所代表的资源单独配置到简单的properties文件中来加载。 基本机制就是之前所说的那样。当BeanFactory在第一阶段加载完成所有配置信息时，BeanFactory中保存的对象的属性信息还只是以占位符的形式存在，如${jdbc.url}、${jdbc.driver}。当PropertyPlaceholderConfigurer作为BeanFactoryPostProcessor被应用时，它会使用properties配置文件中的配置信息来替换相应BeanDefinition中占位符所表示的属性值。这样，当进入容器实现的第二阶段实例化bean时，bean定义中的属性值就是最终替换完成的了。PropertyPlaceholderConfigurer不单会从其配置的properties文件中加载配置项，同时还会检查Java的System类中的Properties，可以通过setSystemPropertiesMode()或者setSystemProper\u0002tiesModeName()来控制是否加载或者覆盖System相应Properties的行为。PropertyPlaceholder\u0002Configurer提供了SYSTEM_PROPERTIES_MODE_FALLBACK、SYSTEM_PROPERTIES_MODE_NEVER和SYSTEM_PROPERTIES_MODE_OVERRIDE三种模式。默认采用的是SYSTEM_PROPERTIES_ MODE_FALLBACK，即如果properties文件中找不到相应配置项，则到System的Properties中查找，我们还可以选择不检查System的Properties或者覆盖它。 2、 CustomEditorConfigurer：我们知道，不管对象是什么类型，也不管这些对象所声明的依赖对象是什么类型，通常都是通过XML（或者properties甚至其他媒介）文件格式来配置这些对象类型。但XML所记载的，都是String类型，即容器从XML格式的文件中读取的都是字符串形式，最终应用程序却是由各种类型的对象所构成。要想完成这种由字符串到具体对象的转换（不管这个转换工作最终由谁来做），都需要这种转换规则相关的信息，而CustomEditorConfigurer就是帮助我们传达类似信息的。 Spring内部通过JavaBean的PropertyEditor来帮助进行String类型到其他类型的转换工作。只要为每种对象类型提供一个 PropertyEditor ，就可以根据该对象类型取得与其相对应的PropertyEditor来做具体的类型转换。Spring容器内部在做具体的类型转换的时候，会采用JavaBean框架内默认的PropertyEditor搜寻逻辑，从而继承了对原生类型以及java.lang.String.java.awt.Color和java.awt.Font等类型的转换支持。同时，Spring框架还提供了自身实现的一些Property\u0002Editor，这些PropertyEditor大部分都位于org.springframework. beans.propertyeditors包下。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://example.com/tags/%E5%AE%B9%E5%99%A8/"}],"author":"John Doe"},{"title":"Spring容器背后的秘密","slug":"Spring容器背后的秘密","date":"2022-03-04T02:22:00.000Z","updated":"2022-03-04T02:34:21.122Z","comments":true,"path":"2022/03/04/Spring容器背后的秘密/","link":"","permalink":"http://example.com/2022/03/04/Spring%E5%AE%B9%E5%99%A8%E8%83%8C%E5%90%8E%E7%9A%84%E7%A7%98%E5%AF%86/","excerpt":"","text":"Spring的IOC容器它会以某种方式加载Configuration Metadata（通常也就是XML格式的配置信息），然后根据这些信息绑定整个系统的对象，最终组装成一个可用的基于轻量级容器的应用系统。 Spring的IOC容器在实现上述过程中可以分为两个阶段：容器启动阶段和Bean实例化阶段。 Spring的IoC容器在实现的时候，充分运用了这两个实现阶段的不同特点，在每个阶段都加入了相应的容器扩展点，以便我们可以根据具体场景的需要加入自定义的扩展逻辑。 1、容器启动阶段：容器启动伊始，首先会通过某种途径加载Configuration MetaData。除了代码方式比较直接，在大部分情况下，容器需要依赖某些工具类（BeanDefinitionReader）对加载的Configuration MetaData进行解析和分析，并将分析后的信息编组为相应的BeanDefinition，最后把这些保存了bean定义必要信息的BeanDefinition，注册到相应的BeanDefinitionRegistry，这样容器启动工作就完成了。 总地来说，该阶段所做的工作可以认为是准备性的，重点更加侧重于对象管理信息的收集。当然，一些验证性或者辅助性的工作也可以在这个阶段完成。 2、 Bean实例化阶段：经过第一阶段，现在所有的bean定义信息都通过BeanDefinition的方式注册到了BeanDefinitionRegistry中。当某个请求方通过容器的getBean方法明确地请求某个对象，或者因依赖关系容器需要隐式地调用getBean方法时，就会触发第二阶段的活动。该阶段，容器会首先检查所请求的对象之前是否已经初始化。如果没有，则会根据注册的BeanDefinition所提供的信息实例化被请求对象，并为其注入依赖。如果该对象实现了某些回调接口，也会根据回调接口的要求来装配它。当该对象装配完毕之后，容器会立即将其返回请求方使用。 如果说第一阶段只是根据图纸装配生产线的话，那么第二阶段就是使用装配好的生产线来生产具体的产品了。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"IOC","slug":"IOC","permalink":"http://example.com/tags/IOC/"}],"author":"John Doe"},{"title":"bean的scope的使用陷阱","slug":"bean的scope的使用陷阱","date":"2022-03-03T15:48:00.000Z","updated":"2022-03-03T16:01:27.658Z","comments":true,"path":"2022/03/03/bean的scope的使用陷阱/","link":"","permalink":"http://example.com/2022/03/03/bean%E7%9A%84scope%E7%9A%84%E4%BD%BF%E7%94%A8%E9%99%B7%E9%98%B1/","excerpt":"","text":"我们知道，拥有prototype类型scope的bean，在请求方每次向容器请求该类型对象的时候，容器都会返回一个全新的该对象实例。但是对于在类A中定义成员变量类B，并且通过setter注入类B，并getter返回类B时，会存在每次返回的对象都是同一个对象。 原因在于：虽然A拥有prototype类型的scope，但当容器将一个B的实例注入A之后，A就会一直持有这个FXNewsBean实例的引用。虽然每次输出都调用了getNewsBean()方法并返回了 FXNewsBean 的实例，但实际上每次返回的都是A持有的容器第一次注入的实例。这就是问题之所在。换句话说，第一个实例注入后，A再也没有重新向容器申请新的实例。所以，容器也不会重新为其注入新的B类型的实例。 解决的方案就在于保证get方法每次从容器中取得新的B实例，而不是每次都返回其持有的单一实例。 1、方法注入：Spring容器提出了一种叫做方法注入（Method Injection）的方式，可以帮助我们解决上述问题。我们所要做的很简单，只要让getNewsBean方法声明符合规定的格式，并在配置文件中通知容器，当该方法被调用的时候，每次返回指定类型的对象实例即可。也就是说，该方法必须能够被子类实现或者覆写，因为容器会为我们要进行方法注入的对象使用Cglib动态生成一个子类实现，从而替代当前对象。 2、使用BeanFactoryAware接口：我们知道，即使没有方法注入，只要在实现 get方法的时候，能够保证每次调用BeanFactory的getBean(“newsBean”)，就同样可以每次都取得新的FXNewsBean对象实例。Spring框架提供了一个BeanFactoryAware接口，容器在实例化实现了该接口的bean定义的过程中，会自动将容器本身注入该bean。这样，该bean就持有了它所处的BeanFactory的引用 3、 使用ObjectFactoryCreatingFactoryBean：ObjectFactoryCreatingFactoryBean是Spring提供的一个FactoryBean实现，它返回一个ObjectFactory实例。从ObjectFactoryCreatingFactoryBean返回的这个ObjectFactory实例可以为我们返回容器管理的相关对象。实际上， ObjectFactoryCreatingFactoryBean 实现了BeanFactoryAware接口，它返回的ObjectFactory实例只是特定于与Spring容器进行交互的一个实现而已。使用它的好处就是，隔离了客户端对象对BeanFactory的直接引用。 4、方法替换：与方法注入只是通过相应方法为主体对象注入依赖对象不同，方法替换更多体现在方法的实现层面上，它可以灵活替换或者说以新的方法实现覆盖掉原来某个方法的实现逻辑。基本上可以认为，方法替换可以帮助我们实现简单的方法拦截功能。 首先，我们需要给出org.springframework.beans.factory.support.MethodReplacer的实现类，在这个类中实现将要替换的方法逻辑。 有了要替换的逻辑之后，我们就可以把这个逻辑通过配置到FXNewsProv\u0002ider的bean定义中，使其生效。 最后需要强调的是，这种方式刚引入的时候执行效率不是很高。而且，当你充分了解并应用SpringAOP之后，我想你也不会再回头求助这个特色功能。不过，怎么说这也是一个选择，场景合适的话，为何不用呢？哦，如果要替换的方法存在参数，或者对象存在多个重载的方法，可以在内部通过明确指定将要替换的方法参数类型。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"scop","slug":"scop","permalink":"http://example.com/tags/scop/"}],"author":"John Doe"},{"title":"工厂方法与 FactoryBean","slug":"工厂方法与-FactoryBean","date":"2022-03-03T15:05:00.000Z","updated":"2022-03-03T15:31:28.499Z","comments":true,"path":"2022/03/03/工厂方法与-FactoryBean/","link":"","permalink":"http://example.com/2022/03/03/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E4%B8%8E-FactoryBean/","excerpt":"","text":"在强调“面向接口编程”的同时，有一点需要注意：虽然对象可以通过声明接口来避免对特定接口实现类的过度耦合，但总归需要一种方式将声明依赖接口的对象与接口实现类关联起来。否则，只依赖一个不做任何事情的接口是没有任何用处的。 如果该类是由我们设计并开发的，那么还好说，我们可以通过依赖注入，让容器帮助我们解除接口与实现类之间的耦合性。但是，有时，我们需要依赖第三方库，需要实例化并使用第三方库中的相关类，这时，接口与实现类的耦合性需要其他方式来避免。 通常的做法是通过使用工厂方法（Factory Method）模式，提供一个工厂类来实例化具体的接口实现类，这样，主体对象只需要依赖工厂类，具体使用的实现类有变更的话，只是变更工厂类，而主体对象不需要做任何变动。 针对使用工厂方法模式实例化对象的方式，Spring的IoC容器同样提供了对应的集成支持。我们所要做的，只是将工厂类所返回的具体的接口实现类注入给主体对象 1、 静态工厂方法（Static Factory Method） 2、非静态工厂方法（Instance Factory Method） 3、FactoryBean：FactoryBean是Spring容器提供的一种可以扩展容器对象实例化逻辑的接口，请不要将其与容器名称BeanFactory相混淆。FactoryBean，其主语是Bean，定语为Factory，也就是说，它本身与其他注册到容器的对象一样，只是一个Bean而已，只不过，这种类型的Bean本身就是生产对象的工厂（Factory）。 当某些对象的实例化过程过于烦琐，通过XML配置过于复杂，使我们宁愿使用Java代码来完成这个实例化过程的时候，或者，某些第三方库不能直接注册到Spring容器的时候，就可以实现org.spring.framework.beans.factory.FactoryBean接口，给出自己的对象实例化逻辑代码。当然，不使用Fac.toryBean，而像通常那样实现自定义的工厂方法类也是可以的。不过，FactoryBean可是Spring提供的对付这种情况的“制式装备”哦！ Spring容器内部许多地方了使用FactoryBean。下面是一些比较常见的FactoryBean实现，你可以参照FactoryBean的Javadoc以了解更多内容。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"FactoryBean","slug":"FactoryBean","permalink":"http://example.com/tags/FactoryBean/"}],"author":"John Doe"},{"title":"bean的scope","slug":"bean的scope","date":"2022-03-03T14:23:00.000Z","updated":"2022-03-03T15:05:21.116Z","comments":true,"path":"2022/03/03/bean的scope/","link":"","permalink":"http://example.com/2022/03/03/bean%E7%9A%84scope/","excerpt":"","text":"BeanFactory除了拥有作为IoC Service Provider的职责，作为一个轻量级容器，它还有着其他一些职责，其中就包括对象的生命周期管理。 Spring容器最初提供了两种bean的scope类型：singleton和prototype，但发布2.0之后，又引入了另外三种scope类型，即request、session和global session类型。不过这三种类型有所限制，只能在Web应用中使用。也就是说，只有在支持Web应用的ApplicationContext中使用这三个scope才是合理的。 1、singleton：标记为拥有singleton scope的对象定义，在Spring的IoC容器中只存在一个实例，所有对该对象的引用将共享这个实例。该实例从容器启动，并因为第一次被请求而初始化之后，将一直存活到容器退出，也就是说，它与IoC容器“几乎”拥有相同的“寿命”。 （注意：需要注意的一点是，不要因为名字的原因而与GoF所提出的Singleton模式相混淆，二者的语意是不同的：标记为singleton的bean是由容器来保证这种类型的bean在同一个容器中只存在一个共享实例；而Singleton模式则是保证在同一个Classloader中只存在一个这种类型的实例。） 2、 prototype：针对声明为拥有prototype scope的bean定义，容器在接到该类型对象的请求的时候，会每次都重新生成一个新的对象实例给请求方。虽然这种类型的对象的实例化以及属性设置等工作都是由容器负责的，但是只要准备完毕，并且对象实例返回给请求方之后，容器就不再拥有当前返回对象的引用，请求方需要自己负责当前返回对象的后继生命周期的管理工作，包括该对象的销毁。也就是说，容器每次返回给请求方一个新的对象实例之后，就任由这个对象实例“自生自灭”了。 3、 request：Spring容器，即XmlWebApplicationContext会为每个HTTP请求创建一个全新的Request\u0002Processor对象供当前请求使用，当请求结束后，该对象实例的生命周期即告结束。当同时有10个HTTP请求进来的时候，容器会分别针对这10个请求返回10个全新的RequestProcessor对象实例，且它们之间互不干扰。从不是很严格的意义上说，request可以看作prototype的一种特例，除了场景更加具体之外，语意上差不多。 4、session：对于Web应用来说，放到session中的最普遍的信息就是用户的登录信息，对于这种放到session中的信息，我们可使用如下形式指定其scope为session 5、global session：global session只有应用在基于portlet的Web应用程序中才有意义，它映射到portlet的global范围的 3session。如果在普通的基于servlet的Web应用中使用了这个类型的scope，容器会将其作为普通的session类型的scope对待。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"Spring ","slug":"Spring/Spring","permalink":"http://example.com/categories/Spring/Spring/"}],"tags":[{"name":"scope","slug":"scope","permalink":"http://example.com/tags/scope/"}],"author":"John Doe"},{"title":"Spring的IOC容器之BeanFactory","slug":"Spring的IOC容器之BeanFactory","date":"2022-03-03T13:21:00.000Z","updated":"2022-03-03T13:56:15.460Z","comments":true,"path":"2022/03/03/Spring的IOC容器之BeanFactory/","link":"","permalink":"http://example.com/2022/03/03/Spring%E7%9A%84IOC%E5%AE%B9%E5%99%A8%E4%B9%8BBeanFactory/","excerpt":"","text":"BeanFactory，顾名思义，就是生产Bean的工厂。当然，严格来说，这个“生产过程”可能不像说起来那么简单。既然Spring框架提倡使用POJO，那么把每个业务对象看作一个JavaBean对象，或许更容易理解为什么Spring的IoC基本容器会起这么一个名字。作为Spring提供的基本的IoC容器，BeanFactory可以完成作为IoC Service Provider的所有职责，包括业务对象的注册和对象间依赖关系的绑定。 BeanFactory就像一个汽车生产厂。你从其他汽车零件厂商或者自己的零件生产部门取得汽车零件送入这个汽车生产厂，最后，只需要从生产线的终点取得成品汽车就可以了。相似地，将应用所需的所有业务对象交给BeanFactory之后，剩下要做的，就是直接从BeanFactory取得最终组装完成并且可用的对象。至于这个最终业务对象如何组装，你不需要关心，BeanFactory会帮你搞定。 所以，对于客户端来说，与BeanFactory打交道其实很简单。最基本地，BeanFactory肯定会公开一个取得组装完成的对象的方法接口，就像代码清单4-1中真正的BeanFactory的定义所展示的那样。 BeanFactory就像一个汽车生产厂。你从其他汽车零件厂商或者自己的零件生产部门取得汽车零件送入这个汽车生产厂，最后，只需要从生产线的终点取得成品汽车就可以了。相似地，将应用所需的所有业务对象交给BeanFactory之后，剩下要做的，就是直接从BeanFactory取得最终组装完成并且可用的对象。至于这个最终业务对象如何组装，你不需要关心，BeanFactory会帮你搞定。 当BeanFactory说这些事情让它来做的时候，可能没有告诉你它会怎么来做这个事情。不过没关系，我们通常只需将“生产线图纸”交给BeanFactory就行了。通常情况下，它会通过常用的图纸（XML文件）来注册并管理各个业务对象之间的依赖关系。 当然BeanFactory只是一个接口，我们最终需要一个该接口的实现来进行实际的Bean的管理，DefaultListableBeanFactory就是这么一个比较通用的BeanFactory实现类。 DefaultListableBeanFactory除了间接地实现了BeanFactory接口，还实现了BeanDefinitionRegistry接口，该接口才是在BeanFactory的实现中担当Bean注册管理的角色。基本上，BeanFactory接口只定义如何访问容器内管理的Bean的方法，各个BeanFactory的具体实现类负责具体Bean的注册以及管理工作。BeanDefinitionRegistry接口定义抽象了Bean的注册逻辑。通常情况下，具体的BeanFactory实现类会实现这个接口来管理Bean的注册。 每一个受管的对象，在容器中都会有一个BeanDefinition的实例（instance）与之相对应，该BeanDefinition的实例负责保存对象的所有必要信息，包括其对应的对象的class类型、是否是抽象类、构造方法参数以及其他属性等。当客户端向BeanFactory请求相应对象的时候，BeanFactory会通过这些信息为客户端返回一个完备可用的对象实例。RootBeanDefinition和ChildBean\u0002Definition是BeanDefinition的两个主要实现类。 采用外部配置文件时，Spring的IoC容器有一个统一的处理方式。通常情况下，需要根据不同的外部配置文件格式，给出相应的BeanDefinitionReader实现类，由BeanDefinitionReader的相应实现类负责将相应的配置文件内容读取并映射到BeanDefinition，然后将映射后的BeanDefinition注册到一个BeanDefinitionRegistry，之后，BeanDefinitionRegistry即完成Bean的注册和加载。当然，大部分工作，包括解析文件格式、装配BeanDefinition之类的工作，都是由BeanDefinition\u0002Reader的相应实现类来做的，BeanDefinitionRegistry只不过负责保管而已。 与为 Properties配置文件格式提供PropertiesBeanDefinitionReader相对应，Spring同样为XML格式的配置文件提供了现成的BeanDefinitionReader实现，即XmlBeanDefinitionReader。XmlBeanDefinitionReader负责读取Spring指定格式的XML配置文件并解析，之后将解析后的文件内容映射到相应的BeanDefinition，并加载到相应的BeanDefinitionRegistry中（在这里是Default\u0002ListableBeanFactory）。这时，整个BeanFactory就可以放给客户端使用了。除了提供XmlBeanDefinitionReader用于XML格式配置文件的加载，Spring还在Default\u0002ListableBeanFactory的基础上构建了简化XML格式配置加载的XmlBeanFactory实现。 如果要通过注解标注的方式为类注入所需要的依赖，现在可以使用@Autowired以 及@Component等对相关类进行标记。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"BeanFactory","slug":"BeanFactory","permalink":"http://example.com/tags/BeanFactory/"}],"author":"John Doe"},{"title":"Spring的IOC容器","slug":"Spring的IOC容器","date":"2022-03-03T13:11:00.000Z","updated":"2022-03-03T13:20:31.109Z","comments":true,"path":"2022/03/03/Spring的IOC容器/","link":"","permalink":"http://example.com/2022/03/03/Spring%E7%9A%84IOC%E5%AE%B9%E5%99%A8/","excerpt":"","text":"Spring的IoC容器是一个IoC Service Provider，但是，这只是它被冠以IoC之名的部分原因，我们不能忽略的是“容器”。Spring的IoC容器是一个提供IoC支持的轻量级容器，除了基本的IoC支持，它作为轻量级容器还提供了IoC之外的支持。如在Spring的IoC容器之上，Spring还提供了相应的AOP框架支持、企业级服务集成等服务。Spring的IoC容器和IoCService Provider所提供的服务之间存在一定的交集。 Spring提供了两种容器类型：BeanFactoryApplicationContext  BeanFactory。基础类型IoC容器，提供完整的IoC服务支持。如果没有特殊指定，默认采用延迟初始化策略（lazy-load）。只有当客户端对象需要访问容器中的某个受管对象的时候，才对该受管对象进行初始化以及依赖注入操作。所以，相对来说，容器启动初期速度较快，所需要的资源有限。对于资源有限，并且功能要求不是很严格的场景，BeanFactory是比较合适的IoC容器选择。  ApplicationContext在BeanFactory的基础上构建，是相对比较高级的容器实现，除了拥有BeanFactory的所有支持，ApplicationContext还提供了其他高级特性，比如事件发布、国际化信息支持等。ApplicationContext所管理的对象，在该类型容器启动之后，默认全部初始化并绑定完成。所以，相对于BeanFactory来说，ApplicationContext要求更多的系统资源，同时，因为在启动时就完成所有初始化，容器启动时间较之BeanFactory也会长一些。在那些系统资源充足，并且要求更多功能的场景中，ApplicationContext类型的容器是比较合适的选择。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"IOC","slug":"IOC","permalink":"http://example.com/tags/IOC/"}],"author":"John Doe"},{"title":"—IoC Service Provider 如何管理对象间的 依赖关系","slug":"—IoC-Service-Provider-如何管理对象间的-依赖关系","date":"2022-03-03T10:30:00.000Z","updated":"2022-03-03T13:11:08.016Z","comments":true,"path":"2022/03/03/—IoC-Service-Provider-如何管理对象间的-依赖关系/","link":"","permalink":"http://example.com/2022/03/03/%E2%80%94IoC-Service-Provider-%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E5%AF%B9%E8%B1%A1%E9%97%B4%E7%9A%84-%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB/","excerpt":"","text":"IoC Service Provider不是人类，也就不能像酒吧服务生那样通过大脑来记忆和存储所有的相关信息。所以，它需要寻求其他方式来记录诸多对象之间的对应关系。比如：  它可以通过最基本的文本文件来记录被注入对象和其依赖对象之间的对应关系；  它也可以通过描述性较强的XML文件格式来记录对应信息；  它还可以通过编写代码的方式来注册这些对应信息；  甚至，如果愿意，它也可以通过语音方式来记录对象间的依赖注入关系（“嗨，它要一个这种类型的对象，拿这个给它”）。 那么，实际情况下，各种具体的IoC Service Provider实现又是通过哪些方式来记录“服务信息”的呢？我们可以归纳一下，当前流行的 IoC Service Provider产品使用的注册对象管理信息的方式主要有以下几种。 1、直接编码方式 2、配置文件方式 3、元数据方式","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"IOC","slug":"IOC","permalink":"http://example.com/tags/IOC/"}],"author":"John Doe"},{"title":"IoC Service Provider 的职责","slug":"IoC-Service-Provider-的职责","date":"2022-03-03T10:27:00.000Z","updated":"2022-03-03T10:28:50.333Z","comments":true,"path":"2022/03/03/IoC-Service-Provider-的职责/","link":"","permalink":"http://example.com/2022/03/03/IoC-Service-Provider-%E7%9A%84%E8%81%8C%E8%B4%A3/","excerpt":"","text":"IoC Service Provider的职责相对来说比较简单，主要有两个：业务对象的构建管理和业务对象间的依赖绑定。  业务对象的构建管理。在IoC场景中，业务对象无需关心所依赖的对象如何构建如何取得，但这部分工作始终需要有人来做。所以，IoC Service Provider需要将对象的构建逻辑从客户端对象那里剥离出来，以免这部分逻辑污染业务对象的实现。  业务对象间的依赖绑定。对于IoC Service Provider来说，这个职责是最艰巨也是最重要的，这是它的最终使命之所在。如果不能完成这个职责，那么，无论业务对象如何的“呼喊”，也不会得到依赖对象的任何响应（最常见的倒是会收到一个NullPointerException）。IoC Service Provider通过结合之前构建和管理的所有业务对象，以及各个业务对象间可以识别的依赖关系，将这些对象所依赖的对象注入绑定，从而保证每个业务对象在使用的时候，可以处于就绪状态。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"IoC Service Provider","slug":"IoC-Service-Provider","permalink":"http://example.com/tags/IoC-Service-Provider/"}],"author":"John Doe"},{"title":"IOC的基本理念：让别人为你服务","slug":"IOC的基本理念：让别人为你服务","date":"2022-03-03T09:01:00.000Z","updated":"2022-03-03T10:25:33.400Z","comments":true,"path":"2022/03/03/IOC的基本理念：让别人为你服务/","link":"","permalink":"http://example.com/2022/03/03/IOC%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%90%86%E5%BF%B5%EF%BC%9A%E8%AE%A9%E5%88%AB%E4%BA%BA%E4%B8%BA%E4%BD%A0%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"IOC即控制反转，它还有一个别名叫做依赖注入（DependencyInjection）。 在我日常开发中，经常需要一个对象依赖于另一个对象的服务。最简单而有效的方式就是直接在类的构造函数中新建相应的依赖类。这就好比要装修新房，需要用家具，这个时候，根据通常解决对象依赖关系的做法，我们就会直接打造出需要的家具来。不过，通常都是分工明确的，所以，大多数情况下，我们可以去家具广场将家具买回来，然后根据需要装修布置即可。不管是直接打造家具（通过new构造对象），还是去家具广场买家具（通过工厂设计模式），有一个共同点需要我们关注，那就是我们都是自己主动地去获取依赖的对象！可是回头想想，我们自己每次用到什么依赖对象都要主动地去获取，这是否真的必要？我们最终所要做的，其实就是直接调用依赖对象所提供的某项服务而已。只要用到这个依赖对象的时候，它能够准备就绪，我们完全可以不管这个对象是自己找来的还是别人送过来的。 实际上IOC就是为了帮助我们解决这种问题的，而提供了更加轻松简洁的方式。它的反转，就反转在让你从原来的事必躬亲，转变为现在的享受服务。 通常情况下，被注入对象会直接依赖于被依赖对象。但是，在IoC的场景中，二者之间通过IoC Service Provider来打交道，所有的被注入对象和依赖对象现在由IoC Service Provider统一管理。被注入对象需要什么，直接跟IoC Service Provider招呼一声，后者就会把相应的被依赖对象注入到被注入对象中，从而达到IoC Service Provider为被注入对象服务的目的。IoC Service Provider在这里就是通常的IoC容器所充当的角色。从被注入对象的角度看，与之前直接寻求依赖对象相比，依赖对象的取得方式发生了反转，控制也从被注入对象转到了IoC Service Provider那里。 （IoC Service Provider在这里是一个抽象出来的概念，它可以指代任何将IoC场景中的业务对象绑定到一起的实现方式。它可以是一段代码，也可以是一组相关的类，甚至可以是比较通用的IoC框架或者IoC容器实现。）","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"IOC的理解","slug":"IOC的理解","permalink":"http://example.com/tags/IOC%E7%9A%84%E7%90%86%E8%A7%A3/"}],"author":"John Doe"},{"title":"Spring三种注入方法比较","slug":"Spring三种注入方法比较","date":"2022-03-03T08:53:00.000Z","updated":"2022-03-03T08:54:49.415Z","comments":true,"path":"2022/03/03/Spring三种注入方法比较/","link":"","permalink":"http://example.com/2022/03/03/Spring%E4%B8%89%E7%A7%8D%E6%B3%A8%E5%85%A5%E6%96%B9%E6%B3%95%E6%AF%94%E8%BE%83/","excerpt":"","text":"接口注入。从注入方式的使用上来说，接口注入是现在不甚提倡的一种方式，基本处于“退役状态”。因为它强制被注入对象实现不必要的接口，带有侵入性。而构造方法注入和setter方法注入则不需要如此。 构造方法注入。这种注入方式的优点就是，对象在构造完成之后，即已进入就绪状态，可以 马上使用。缺点就是，当依赖对象比较多的时候，构造方法的参数列表会比较长。而通过反射构造对象的时候，对相同类型的参数的处理会比较困难，维护和使用上也比较麻烦。而且在Java中，构造方法无法被继承，无法设置默认值。对于非必须的依赖处理，可能需要引入多个构造方法，而参数数量的变动可能造成维护上的不便。 setter方法注入。因为方法可以命名，所以setter方法注入在描述性上要比构造方法注入好一些。 另外，setter方法可以被继承，允许设置默认值，而且有良好的IDE支持。缺点当然就是对象无法在构造完成后马上进入就绪状态。","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"}],"tags":[{"name":"注入方式","slug":"注入方式","permalink":"http://example.com/tags/%E6%B3%A8%E5%85%A5%E6%96%B9%E5%BC%8F/"}],"author":"John Doe"},{"title":"MySQL怎么查看索引是否是高选择性？","slug":"MySQL怎么查看索引是否是高选择性？","date":"2022-03-02T11:33:00.000Z","updated":"2022-03-02T11:40:36.822Z","comments":true,"path":"2022/03/02/MySQL怎么查看索引是否是高选择性？/","link":"","permalink":"http://example.com/2022/03/02/MySQL%E6%80%8E%E4%B9%88%E6%9F%A5%E7%9C%8B%E7%B4%A2%E5%BC%95%E6%98%AF%E5%90%A6%E6%98%AF%E9%AB%98%E9%80%89%E6%8B%A9%E6%80%A7%EF%BC%9F/","excerpt":"","text":"通过show index查看结果列中的cardinality值（表示索引中不重复记录数量的预估值），在实际应用中cardinality/table.size应该尽可能接近1。 cardinality是在存储引擎层进行统计的。具体方式是通过采样的方法来完成。具体发生在insert和update操作中，策略为①表中1/16数据发生过变化②stat_modified_counter&gt;2 000 000 000（表中数据实际未增加，实际发生变化的还是这一行数据①就无法适用，则通过②的计数器stat_modirfied_counter表示发生变化次数）。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"索引","slug":"索引","permalink":"http://example.com/tags/%E7%B4%A2%E5%BC%95/"}],"author":"John Doe"},{"title":"InnoDB行溢出（Redundant）","slug":"InnoDB行溢出","date":"2022-03-02T10:45:00.000Z","updated":"2022-03-02T10:53:16.247Z","comments":true,"path":"2022/03/02/InnoDB行溢出/","link":"","permalink":"http://example.com/2022/03/02/InnoDB%E8%A1%8C%E6%BA%A2%E5%87%BA/","excerpt":"","text":"3个列长度总和是66000，innoDB存储引擎的页为16kb，16384字节，会产生行溢出，因此对于这种情况，数据不会存放于b+tree的叶子节点中，而是存入页类型为uncompress blob页中。 每页中至少存放两条行记录（否则失去了B+tree的意义，变为了链表），因此如果一页中只能放一条记录，则会将数据放到溢出页。而对于Text或BLOB的数据类型亦然。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"行结构","slug":"行结构","permalink":"http://example.com/tags/%E8%A1%8C%E7%BB%93%E6%9E%84/"}],"author":"John Doe"},{"title":"MySQL中varchar中的N","slug":"MySQL中varchar中的N","date":"2022-03-02T10:42:00.000Z","updated":"2022-03-02T10:44:12.635Z","comments":true,"path":"2022/03/02/MySQL中varchar中的N/","link":"","permalink":"http://example.com/2022/03/02/MySQL%E4%B8%ADvarchar%E4%B8%AD%E7%9A%84N/","excerpt":"","text":"varchar(N)指的是字符长度，而官方文档中指的是最大支持65535是字节","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"行","slug":"行","permalink":"http://example.com/tags/%E8%A1%8C/"}],"author":"John Doe"},{"title":"如何在 Linux 系统中查看 TCP 状态？","slug":"如何在-Linux-系统中查看-TCP-状态？","date":"2022-02-25T01:56:00.000Z","updated":"2022-02-25T01:58:06.991Z","comments":true,"path":"2022/02/25/如何在-Linux-系统中查看-TCP-状态？/","link":"","permalink":"http://example.com/2022/02/25/%E5%A6%82%E4%BD%95%E5%9C%A8-Linux-%E7%B3%BB%E7%BB%9F%E4%B8%AD%E6%9F%A5%E7%9C%8B-TCP-%E7%8A%B6%E6%80%81%EF%BC%9F/","excerpt":"","text":"netstat-napt","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://example.com/tags/TCP/"}],"author":"John Doe"},{"title":"最左匹配原则","slug":"最左匹配原则","date":"2022-02-24T08:02:00.000Z","updated":"2022-02-24T08:04:16.906Z","comments":true,"path":"2022/02/24/最左匹配原则/","link":"","permalink":"http://example.com/2022/02/24/%E6%9C%80%E5%B7%A6%E5%8C%B9%E9%85%8D%E5%8E%9F%E5%88%99/","excerpt":"","text":"MySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引。如User表的name和city加联合索引就是(name,city)，而最左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到。如下： select * from user where name=xx and city=xx ; ／／可以命中索引 select * from user where name=xx ; // 可以命中索引 select * from user where city=xx; // 无法命中索引 需要注意：查询的时候如果两个条件都用上了，但是顺序不同，如 city= xx and name ＝xx，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的.由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDERBY子句也遵循此规则。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"最左匹配原则","slug":"最左匹配原则","permalink":"http://example.com/tags/%E6%9C%80%E5%B7%A6%E5%8C%B9%E9%85%8D%E5%8E%9F%E5%88%99/"}],"author":"John Doe"},{"title":"一条SQL语句执行得很慢的原因有哪些？","slug":"一条SQL语句执行得很慢的原因有哪些？","date":"2022-02-24T07:50:00.000Z","updated":"2022-02-24T07:59:49.798Z","comments":true,"path":"2022/02/24/一条SQL语句执行得很慢的原因有哪些？/","link":"","permalink":"http://example.com/2022/02/24/%E4%B8%80%E6%9D%A1SQL%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E5%BE%97%E5%BE%88%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F/","excerpt":"","text":"一个 SQL 执行的很慢，我们要分两种情况讨论： 1、大多数情况下很正常，偶尔很慢，则有如下原因 (1)、数据库在刷新脏页，例如 redo log 页写满了需要同步到磁盘。 (2)、执行的时候，遇到锁，如表锁、行锁。 2、这条 SQL 语句一直执行的很慢，则有如下原因。 (1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。 (2)、数据库选错了索引。 转载：https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485185&amp;idx=1&amp;sn=66ef08b4ab6af5757792223a83fc0d45&amp;chksm=cea248caf9d5c1dc72ec8a281ec16aa3ec3e8066dbb252e27362438a26c33fbe842b0e0adf47&amp;token=79317275&amp;lang=zh_CN%23rd","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"性能","slug":"性能","permalink":"http://example.com/tags/%E6%80%A7%E8%83%BD/"}],"author":"John Doe"},{"title":"分库分表之后的主键处理方式","slug":"分库分表之后的主键处理方式","date":"2022-02-24T04:56:00.000Z","updated":"2022-02-24T05:00:22.852Z","comments":true,"path":"2022/02/24/分库分表之后的主键处理方式/","link":"","permalink":"http://example.com/2022/02/24/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E4%B9%8B%E5%90%8E%E7%9A%84%E4%B8%BB%E9%94%AE%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F/","excerpt":"","text":"1、UUID：不适合作为主键，其太长了而且无序，插入效率低 2、数据库自增id：两台数据库分别设置不同步⻓，⽣成不重复ID的策略来实现⾼可⽤。这种⽅式⽣成的 id 有序，但是需要独⽴部署数据库实例，成本⾼，还会有性能瓶颈。 3、利⽤ redis ⽣成 id : 性能⽐᫾好，灵活⽅便，不依赖于数据库。但是，引⼊了新的组件造成系统更加复杂，可⽤性降低，编码更加复杂，增加了系统成本。 4、Twitter的snowflake算法： 1.第一位 占用1bit，其值始终是0，没有实际作用。 2.时间戳 占用41bit，精确到毫秒，总共可以容纳约140年的时间。 3.工作机器id 占用10bit，其中高位5bit是数据中心ID（datacenterId），低位5bit是工作节点ID（workerId），做多可以容纳1024个节点。 4.序列号 占用12bit，这个值在同一毫秒同一节点上从0开始不断累加，最多可以累加到4095。 SnowFlake算法在同一毫秒内最多可以生成多少个全局唯一ID呢？只需要做一个简单的乘法： 1024x4096 SnowFlake算法的优点： 1.生成ID时不依赖于DB，完全在内存生成，高性能高可用。 2.ID呈趋势递增，后续插入索引树的时候性能较好。 SnowFlake算法的缺点： 依赖于系统时钟的一致性。如果某台机器的系统时钟回拨，有可能造成ID冲突，或者ID乱序。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"主键","slug":"主键","permalink":"http://example.com/tags/%E4%B8%BB%E9%94%AE/"}],"author":"John Doe"},{"title":"http常见状态码","slug":"http常见状态码","date":"2022-02-23T07:48:00.000Z","updated":"2022-02-23T07:56:43.034Z","comments":true,"path":"2022/02/23/http常见状态码/","link":"","permalink":"http://example.com/2022/02/23/http%E5%B8%B8%E8%A7%81%E7%8A%B6%E6%80%81%E7%A0%81/","excerpt":"","text":"1xx：表示一种提示信息，一般是服务器的中间状态，不常用 2xx：表示服务器已经成功处理了请求 200：成功204：成功（响应头没有body数据）206：用于http分块下载或者断点续传，表示响应的body里面的数据并不完整，只是一部分 3xx：客户端请求的资源发生了变动需要重定向 301：表示永久重定向，即访问的资源永久不存在 302：临时重定向，即访问的资源还在，需要换一个url访问 301和302会在响应头使用location字段表明重定向的url进行重定向 304：不具有跳转含义，表明请求的资源未修改，重定向缓存文件。 4xx：请求的报文有误，服务器无法处理 400：请求错误，具体不清楚 403：服务器禁止访问资源 404：访问的资源在服务器找不到 5xx 类状态码表示客户端请求报⽂正确，但是服务器处理时内部发⽣了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通⽤的错误码，服务器发⽣了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不⽀持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器发⽣了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时⽆法响应服务器，类似“⽹络服务正忙，请稍后᯿试”的意思。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"http","slug":"http","permalink":"http://example.com/tags/http/"}],"author":"John Doe"},{"title":"http","slug":"http","date":"2022-02-23T07:37:47.000Z","updated":"2022-02-23T07:38:21.504Z","comments":true,"path":"2022/02/23/http/","link":"","permalink":"http://example.com/2022/02/23/http/","excerpt":"","text":"http是计算机世界里面两点之间进行文字、图片、视频等超文本数据传输的协议","categories":[],"tags":[],"author":"John Doe"},{"title":"get和post的区别","slug":"get和post的区别","date":"2022-02-18T14:38:00.000Z","updated":"2022-02-18T14:39:22.715Z","comments":true,"path":"2022/02/18/get和post的区别/","link":"","permalink":"http://example.com/2022/02/18/get%E5%92%8Cpost%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"POST和GET都是向服务器提交数据，并且都会从服务器获取数据。 区别： 1、传送方式：get通过地址栏传输，post通过报文传输。 2、传送长度：get参数有长度限制（受限于url长度），而post无限制 3、GET和POST还有一个重大区别，简单的说： GET产生一个TCP数据包；POST产生两个TCP数据包 长的说： 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）； 而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。 因为POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效。因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？ GET与POST都有自己的语义，不能随便混用。 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。 建议： 1、get方式的安全性较Post方式要差些，包含机密信息的话，建议用Post数据提交方式； 2、在做数据查询时，建议用Get方式；而在做数据添加、修改或删除时，建议用Post方式； 案例：一般情况下，登录的时候都是用的POST传输，涉及到密码传输，而页面查询的时候，如文章id查询文章，用get 地址栏的链接为：article.php?id=11，用post查询地址栏链接为：article.php， 不会将传输的数据展现出来。 拓展资料： GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"get","slug":"get","permalink":"http://example.com/tags/get/"},{"name":"post","slug":"post","permalink":"http://example.com/tags/post/"}],"author":"John Doe"},{"title":"代理模式","slug":"代理模式","date":"2022-02-11T13:22:00.000Z","updated":"2022-02-11T13:38:00.109Z","comments":true,"path":"2022/02/11/代理模式/","link":"","permalink":"http://example.com/2022/02/11/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"代理模式是指，为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户类和目标对象之间起到中介的作用。说直白一点就是在不修改目标对象的基础上，使用代理对象来增强目标对象的业务逻辑方法。 代理模式分为：静态代理和动态代理（jdk动态代理和cglib动态代理） 静态代理就是：代理类在程序运行前就确定好了和目标类的关系，在编译期就实现了。其中静态代理的缺点在于： 1、代码复杂，不便于管理：试想对于代理类，需要和目标类实现相同接口即每个代理类都要实现目标类的的方法，会出现代码重复，且考虑到如果接口增加一个方法，其所有实现类都要重写，维护也麻烦。 2、代理类依赖于目标类：当代理类考虑代理多个服务的时候，不便于实现 动态代理是在程序运行期间根据jvm反射机制动态生成的。 jdk动态代理：基于java反射机制实现的。具体通过使用java.lang.reflect 包提供三个类支持代理模式 Proxy, Method和 InovcationHandler。（要求：求目标对象必须实现接口） public interface UsbSell &#123; Object sell(float amount); &#125; public class UsbFactory implements UsbSell &#123; public Object sell(float amount) &#123; float price = 0; if (amount &gt; 100)&#123; price = (float) (amount * (1 + 0.2)); &#125;else &#123; price = (float) (amount * (1 + 0.5)); &#125; return price; &#125; &#125; public class ProxySeller &#123; private Object target; public ProxySeller() &#123; &#125; public ProxySeller(Object target) &#123; this.target = target; &#125; public Object getProxy()&#123; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; float res = (Float) method.invoke(target,args); System.out.println(&quot;==&quot;+res); return proxy; &#125; &#125;); &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; UsbFactory factory = new UsbFactory(); ProxySeller seller = new ProxySeller(factory); UsbSell proxy = (UsbSell)seller.getProxy(); UsbSell s = (UsbSell)proxy.sell(50); s.sell(50); &#125; &#125; cglib动态代理：一个开源项目。对于无接口的类，要为其创建动态代理，就要使用 CGLIB 来实现。CGLIB 代理的生成原理是生成目标类的子类，而子类是增强过的，这个子类对象就是代理对象。所以，使用CGLIB 生成动态代理，要求目标类必须能够被继承，即不能是 final 的类。 public class Saller &#123; public float sell(int amount)&#123; float price = 100; if (amount &gt; 100)&#123; price = (float) (price * (1 + 0.2)); &#125;else &#123; price = (float) (price * (1 + 0.5)); &#125; return price; &#125; &#125; public class ProxySaller implements MethodInterceptor &#123; private Object target; public ProxySaller() &#123; &#125; public ProxySaller(Object target) &#123; this.target = target; &#125; public Object getProxySaller()&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(target.getClass()); enhancer.setCallback(this); Saller saller = (Saller) enhancer.create(); return saller; &#125; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; Float price = (Float) methodProxy.invoke(target,objects); System.out.println(&quot;===&quot;+price); return price; &#125; &#125; public class Main &#123; public static void main(String[] args) &#123; Saller saller = new Saller(); ProxySaller proxySaller = new ProxySaller(saller); Saller proxy = (Saller) proxySaller.getProxySaller(); proxy.sell(100); &#125; &#125;","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"代理模式","slug":"代理模式","permalink":"http://example.com/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"innoDB中的锁","slug":"innoDB中的锁","date":"2022-02-10T05:38:00.000Z","updated":"2022-02-10T11:19:02.156Z","comments":true,"path":"2022/02/10/innoDB中的锁/","link":"","permalink":"http://example.com/2022/02/10/innoDB%E4%B8%AD%E7%9A%84%E9%94%81/","excerpt":"","text":"innoDB实现了共享锁（读锁）和排他锁（写锁）两种行级锁。意向共享锁和意向排他锁两种表级别的锁。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://example.com/tags/%E9%94%81/"}],"author":"John Doe"},{"title":"lock与latch","slug":"lock与latch","date":"2022-02-10T05:36:00.000Z","updated":"2022-02-10T05:38:14.315Z","comments":true,"path":"2022/02/10/lock与latch/","link":"","permalink":"http://example.com/2022/02/10/lock%E4%B8%8Elatch/","excerpt":"","text":"","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://example.com/tags/%E9%94%81/"}],"author":"John Doe"},{"title":"MySQL分区","slug":"MySQL分区","date":"2022-02-09T12:14:49.000Z","updated":"2022-02-09T12:14:49.287Z","comments":true,"path":"2022/02/09/MySQL分区/","link":"","permalink":"http://example.com/2022/02/09/MySQL%E5%88%86%E5%8C%BA/","excerpt":"","text":"","categories":[],"tags":[],"author":"John Doe"},{"title":"MySQL表","slug":"MySQL表","date":"2022-02-09T10:47:00.000Z","updated":"2022-02-09T12:07:08.587Z","comments":true,"path":"2022/02/09/MySQL表/","link":"","permalink":"http://example.com/2022/02/09/MySQL%E8%A1%A8/","excerpt":"","text":"innoDB中，表根据主键顺序存放。每张表都有一个主键，在建表时没有显示定义主键，则innoDB会先判断表中是否有非空的唯一索引，如果有，则该索引即为主键（对于多个非空唯一索引，根据定义的顺序选择，而不是建表列的顺序选择），如果没有，则会自动创建一个6字节的指针。 innoDB中，数据被逻辑的放在一个表空间。表空间由段组成，段又由区组成，区又有页组成，页时最基本的单位。如下： innoDB默认情况下有一个共享表空间，如果用户开启参数innodb_file_per_table则每张表的数据单独放到一个表空间。（需要注意的是：单独的表空间只是存放数据、索引和插入缓冲bitmap页，对于其他数据，如回滚信息、插入缓冲索引页等仍是存放在共享表空间） 对于段由innoDB管理，数据段即为B+tree的叶子节点，索引段即为B+tree的非叶子节点，回滚段较为特殊。 区则是连续页（默认16kb/页）组成的空间（大小1mb）。一个区默认有64个连续的页。为了保证区中页的连续性，innoDB会一次从磁盘申请4-5个区。值得注意的是： innoDB常见页： 页又由行组成最多允许7992（16kb/2-200）行记录。innoDB提供了Compact和Redundant格式的行数据格式。需要注意：除了下图的信息外，还存在事务ID列（6字节）和回滚指针列（7字节），如果innoDB没有定义主键还会有一个6字节的rowid列 Compact行记录： Redundant行记录格式： 当然一般情况下innoDB的数据都是放在页类型为B+tree-node中，但是当发生行溢出，数据存放在Uncompress BLOB页中。 innoDB数据页结构：","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"表","slug":"表","permalink":"http://example.com/tags/%E8%A1%A8/"}],"author":"John Doe"},{"title":"MySQL文件","slug":"MySQL文件","date":"2022-02-09T08:05:00.000Z","updated":"2022-02-09T08:39:14.232Z","comments":true,"path":"2022/02/09/MySQL文件/","link":"","permalink":"http://example.com/2022/02/09/MySQL%E6%96%87%E4%BB%B6/","excerpt":"","text":"1、参数文件：MySQL实例启动时会读取参数文件来初始化。 2、日志文件： 错误日志（记录了MySQL执行期间的错误信息） 二进制日志（记录了对MySQL执行的写操作，默认未开启。 作用：1、恢复，可以通过binlog进行数据的恢复2、复制：通过复制和执行binlog对远程的MySQL进行实时数据同步（主从复制）3、审计：对binlog数据进行审计，看是否有对数据库进行注入的攻击 ） 慢查询日志（可以从中得到一些SQL优化信息，默认未开启） 查询日志（记录了所有对MySQL的请求信息） 3、套接字文件 4、pid文件 5、表结构定义文件（以frm为后缀名）：记录了该表的表结构定义。除此之外还用于存放视图的定义。 6、innoDB存储引擎文件： a）表空间文件（默认10mb，名为ibdata1）：可以设置基于innoDB存储的单独的。idb独立表空间文件（仅存储数据、索引等信息，其他信息还是存放于表空间文件）。 b）、redolog文件（默认会有两个名为ib_logfile0和ib_logfile1的文件）：每个innoDB至少有一个redolog组（每组至少有两个redolog文件），redolog冲缓冲区写入磁盘是按512字节，即一个扇区大小，可以保障写入必定成功（所有不需要doublewrite）","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"文件","slug":"文件","permalink":"http://example.com/tags/%E6%96%87%E4%BB%B6/"}],"author":"John Doe"},{"title":"innoDB存储引擎","slug":"innoDB存储引擎","date":"2022-02-09T03:04:00.000Z","updated":"2022-02-09T07:37:44.969Z","comments":true,"path":"2022/02/09/innoDB存储引擎/","link":"","permalink":"http://example.com/2022/02/09/innoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/","excerpt":"","text":"innoDB存储引擎是开源的第一个完整支持ACID事务的MySQL存储引擎（第一个支持事务的是BDB存储引擎），其特点是行锁设计、支持MVCC、支持外键、一致性非锁定读等。被广泛的应用。 innoDB存储引擎有多个内存块，组成了一个大的内存池，每个内存块有指定的后台线程来维护其运行。 1、main线程主要负责将缓冲区的数据异步刷新到磁盘，保证数据的一致性（包括脏页的刷新、合并插入缓冲、undo页的回收等） 2、IO线程主要是负责IO请求的回调，包括read、write、insert buffer、log等，其使用了AIO机制，保证了IO性能。 3、Purge线程主要用于回收提交事务之后，undo页可能不再需要，需要对其进行回收。（1.2版本支持多个Purge线程，目的是进一步加快undo页的回收，提升性能） 4、Page cleaner线程主要用于脏页的刷新操作，减轻main线程的压力。 innoDB是基于磁盘存储的，为了权衡磁盘速度和CPU速度的差异，提供了一块缓冲池技术来提升性能。（因此可以将缓冲池区域设置大一点来进行优化操作）innoDB1.0允许多个缓冲池实例，磁盘读取的页根据哈希值均匀分配到不同缓冲池中（目的：减少数据库资源竞争，增加数据库并发处理能力） 在数据的读取中，会先去缓冲池中查看是否存在于缓冲池，如果存在直接读取，不存在则去磁盘读取，在同步到缓冲池中。而对于写操作则是先写到缓冲池，然后根据Checkpoint机制将脏数据刷新到磁盘，保证磁盘和内存数据的一致性。 缓冲池具体的数据页有： 为了管理这些数据页，innoDB使用了一个freeLIst链表来管理空闲的页内存，LRUList来管理已经分配的页内存，flushList来管理脏页。（脏页及存在于LRUList，又存在于flushList，是两者共享的） 对于LRUList管理的页，采用了LRU（最近最少使用）算法来管理（缓冲池页大小默认16kb），在LRU列表中加入了一个midpoint位置（默认是5/8位置处），midpoint位置前面的是热点数据区域，后面的是冷数据区域（设置冷、热数据区域主要是为了保证一些经常被访问的数据存在于内存中，提示效率的一种考虑）。当一个新的页被分配到LRULIst上，会先加入到midpoint位置后面（这样做是为了防止当进行全表查询的时候，多个页会覆盖调热数据区域的页，而这些查的数据页又只使用一次，后续不再使用，当后面访问热区域的页时有会从磁盘中查找，浪费性能），同时也指定了一个从冷数据区域晋升到热数据区域的参数，当到了晋升时间后，冷数据区域的页就会晋升到热数据区域。 值得注意的是：空闲页的内存freeList+以分配的页内存LRUList并不等于缓冲池的内存，因为缓冲池中包含得其他部分页（自适应哈希索引、lock信息等）不需要LRU维护，不存在于LRUList中。 另外，页是支持压缩的，16kb的页可以压缩成1kb、2kb、4kb、8kb。页的大小发生变化，所有对于压缩的页，会使用zipLRUList进行管理。（注意：LRUList包含zipLRUList中的页） 对于zipLIRList的页的分配采用伙伴算法 例如压缩后的页为4kb 1、先检查4kb的zipLRUList是否有空闲页，存在即分配 2、否则，检查8kb的zipLRUList看是否存在空闲页，存在则将8kb分为两个4kb，将4kb的页放入4kbzipLRUList，然后为其分配 3、在否则，检查16kb的freeList看是否存在空闲页，存在则将16kb分为两个4kb，一个8kb，分别放入对应zipLRUList，然后为其分配 由上图可知，innoDB除了缓冲池，还存在redolog日志缓冲和额外内存池。 其中redolog日志缓冲（默认8mb大小）是redolog文件的缓冲区（redolog文件记录了写请求的指令，对页的写指令都会记录到这个文件中，后续数据库恢复会使用到这个文件）当满足以下条件就会将缓冲区的数据刷新到文件中。 1、每个事物提交会进行刷新 2、当缓冲区小于一半，会进行刷新 3、main线程每秒会进行一次刷新 而额外的内存池则是在对于一些数据结构本身进行进行内存分配时会从额外内存储进行申请。 前面提到进行写操作入时，一般会先写到缓冲区，然后在根据checkpoint机制将脏页刷新到内存，保持内存和磁盘数据的一致性。但考虑到如果频繁发生写操作，而对脏数据刷新到磁盘不加以控制，每来一个写操作，都会进行一次刷新，那就会产生大量的io，导致整体性能下降；除此之外，在刷新的时候如果出现了宕机，数据也会丢失。因此采用提交事物前，先写redolog日志，然后在修改内存中的页，即使将脏页刷新到磁盘时出现宕机，也能够根据redolog日志进行恢复。而chenckpoint技术就是为了解决 1、缩短数据库的恢复时间（因为chenckpoint前的脏页都已经刷新到磁盘了，只需对chenckpoint之后的进行恢复）2、缓冲池不够时将脏页刷新到磁盘。（当缓冲池不够用时，会根据LRU算法将最近最少用的页淘汰，而淘汰时会检测是否为脏页，如果是则执行checkpoint，将脏页刷新到磁盘）3、redolog日志不够用时，刷新脏页（即redolog的大小是有限制的，chenckpont前的是可重用的，而chenckpoint之后的是需要的，如果redolog文件里面全部都是需要使用的，则必须进行checkpoint） 在innoDB中，使用LSN（八字节）标记版本，每个页都有自己的LSN，redolog日志中和checkpoint中也有。 在innoDB中存在两种checkpoint，即sharp checkpoint（默认）和fuzzy checkpoint。 sharp checkpoint发生在数据库关闭时，此时会将所有脏页刷新到磁盘（会发生迟钝） fuzzy checkpoint则是每次只刷新部分脏页到磁盘。以下是几种发生fuzzy checkpoint的情况： 1、main线程会每秒或10秒的速度从fulshList中刷新页到磁盘。 2、当缓冲池没有多余空闲空间，会根据LRU算法冲LRUList淘汰页，对于淘汰的页会检测是否是脏页，是则会刷新到磁盘。 3、当redolog不可用时会强制flushList中的脏页进行刷新 4、当脏页太多，也会强制进行checkpoint刷新脏页到磁盘。 innoDB主要工作都是在main线程中完成的，其内部由多个循环组成（主循环、后台循环、刷新循环、暂停循环），在多个循环中切换进行工作。 innoDB1.0 主循环： 后台循环： innoDB1.2基于上述IO限制，加入了innoDB_io_capacitiy用于表示IO（默认200），对于刷新的页用百分比来控制 另外一个参数是innoDB_max_dirty_pct（默认75），当脏页小于innoDB_max_dirty_pct也会刷新一定量的脏页（之前是不会刷新的）。 接下来说一说innoDB的插入缓冲。insert buffer和数据页一样，是物理页的一部分。 在innoDB中，主键是唯一标识，插入记录一般按主键递增顺序插入。因此，聚集索引一般是顺序的（比如自增id这种），对于顺序的一般插入操作速度很快，但对于主键是uuid之类则和辅助索引一样，是随机的。因此对于这种情况，按顺序插入则相对要慢得多。因此insert buffer的作用就是对于非聚集索引的插入或者更新操作先判断是否存在缓冲池，若存在则直接插入，不存在则放到insert buffer中，在以一定频率进行inser buffer和辅助索引子节点的合并，提高对于非聚集索引的插入性能。当然使用insert buffer需要满足 insert buffer数据实现是一颗b+树， change buffer：在1.0.x版本引入了channge buffer，可以对增删改都进行缓冲 两次写：当innoDB刷新某个页到磁盘中，但只刷新了部分，数据库就宕机了（部分写失效）。double write就是为了解决这种情况产生的。 double write由两部分组成。一部分时内存double write buffer（大小2mb），一部分是磁盘上的共享表空间中连续的128页（即两个区，大小为2mb）。在对脏页进行刷新时，并不直接写磁盘，而是通过memcpy函数将脏页先复杂到 doublewrite buffer，然后doubllewrite buffer再分两次顺序的写到共享表空间的物理磁盘上（每次写1mb）。完成之后，在将doublewrite buffer中的页写入各个表文件空间中。如果在写入表中磁盘时发生了宕机什么的。在恢复时，可以从共享表空间中找到一个备份页，将其复制到表空间。 自适应哈希：innoDB会对表上各索引页的查询监控。如果建立哈希索引会提升性能，则建立哈希索引。而条件就是：对这个页的连续访问模式要一样。 异步IO：innoDB采用AIO的方式处理磁盘操作，可以在发起一个IO请求后，立马发起另一个IO请求，当全部发送完后，等所有请求操作完。除此之外，还可以进行IO的合并操作。 刷新邻接页：即刷新一个脏页时，会检测该页周围的页是否是脏页，是则一并刷新。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"innoDB","slug":"innoDB","permalink":"http://example.com/tags/innoDB/"}],"author":"John Doe"},{"title":"jedis和redission","slug":"jedis和redission","date":"2022-02-08T12:45:00.000Z","updated":"2022-02-08T12:46:11.557Z","comments":true,"path":"2022/02/08/jedis和redission/","link":"","permalink":"http://example.com/2022/02/08/jedis%E5%92%8Credission/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"框架实现","slug":"框架实现","permalink":"http://example.com/tags/%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0/"}],"author":"John Doe"},{"title":"一致性hash算法","slug":"一致性hash算法","date":"2022-02-08T12:33:00.000Z","updated":"2022-02-08T12:34:21.071Z","comments":true,"path":"2022/02/08/一致性hash算法/","link":"","permalink":"http://example.com/2022/02/08/%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95/","excerpt":"","text":"","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"Redis","slug":"算法/Redis","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/Redis/"}],"tags":[{"name":"一致性哈希算法","slug":"一致性哈希算法","permalink":"http://example.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/"}],"author":"John Doe"},{"title":"Redis集群的主从复制模型","slug":"Redis集群的主从复制模型","date":"2022-02-08T12:27:00.000Z","updated":"2022-02-08T12:27:38.911Z","comments":true,"path":"2022/02/08/Redis集群的主从复制模型/","link":"","permalink":"http://example.com/2022/02/08/Redis%E9%9B%86%E7%BE%A4%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"主从复制模型","slug":"主从复制模型","permalink":"http://example.com/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%9E%8B/"}],"author":"John Doe"},{"title":"Redis内存优化","slug":"Redis内存优化","date":"2022-02-08T12:09:00.000Z","updated":"2022-02-08T12:10:03.147Z","comments":true,"path":"2022/02/08/Redis内存优化/","link":"","permalink":"http://example.com/2022/02/08/Redis%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"内存优化","slug":"内存优化","permalink":"http://example.com/tags/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/"}],"author":"John Doe"},{"title":"Redis的回收进程如何工作","slug":"Redis的回收进程如何工作","date":"2022-02-08T09:37:00.000Z","updated":"2022-02-08T11:59:38.055Z","comments":true,"path":"2022/02/08/Redis的回收进程如何工作/","link":"","permalink":"http://example.com/2022/02/08/Redis%E7%9A%84%E5%9B%9E%E6%94%B6%E8%BF%9B%E7%A8%8B%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"回收进程","slug":"回收进程","permalink":"http://example.com/tags/%E5%9B%9E%E6%94%B6%E8%BF%9B%E7%A8%8B/"}],"author":"John Doe"},{"title":"一个Redis实例能存放多少key？","slug":"一个Redis实例能存放多少key？","date":"2022-02-08T09:27:00.000Z","updated":"2022-02-08T09:28:21.147Z","comments":true,"path":"2022/02/08/一个Redis实例能存放多少key？/","link":"","permalink":"http://example.com/2022/02/08/%E4%B8%80%E4%B8%AARedis%E5%AE%9E%E4%BE%8B%E8%83%BD%E5%AD%98%E6%94%BE%E5%A4%9A%E5%B0%91key%EF%BC%9F/","excerpt":"","text":"理论上 Redis 可以处理多达 2^32 的 keys，并且在实际中进行了测试，每个实例至少存放了 2 亿 5 千万的 keys。我们正在测试一些较大的值。任何 list、set、和 sorted set 都可以放 2^32 个元素。换句话说，Redis 的存储极限是系统中的可用内存值。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[],"author":"John Doe"},{"title":"Redis异步队列","slug":"Redis异步队列","date":"2022-02-08T08:50:00.000Z","updated":"2022-02-08T09:02:41.782Z","comments":true,"path":"2022/02/08/Redis异步队列/","link":"","permalink":"http://example.com/2022/02/08/Redis%E5%BC%82%E6%AD%A5%E9%98%9F%E5%88%97/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"异步队列","slug":"异步队列","permalink":"http://example.com/tags/%E5%BC%82%E6%AD%A5%E9%98%9F%E5%88%97/"}],"author":"John Doe"},{"title":"Redis分布式锁","slug":"Redis分布式锁","date":"2022-02-08T08:29:00.000Z","updated":"2022-02-08T08:30:14.720Z","comments":true,"path":"2022/02/08/Redis分布式锁/","link":"","permalink":"http://example.com/2022/02/08/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"转载自：https://www.cnblogs.com/wangyingshuo/p/14510524.html","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"分布式锁","slug":"分布式锁","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}],"author":"John Doe"},{"title":"如何保证Redis数据都是热点数据？","slug":"如何保证Redis数据都是热点数据？","date":"2022-02-07T10:06:00.000Z","updated":"2022-02-07T10:11:22.310Z","comments":true,"path":"2022/02/07/如何保证Redis数据都是热点数据？/","link":"","permalink":"http://example.com/2022/02/07/%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81Redis%E6%95%B0%E6%8D%AE%E9%83%BD%E6%98%AF%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%EF%BC%9F/","excerpt":"","text":"1.限定 Redis 占用的内存，Redis 会根据自身数据淘汰策略，加载热数据到内存。所以，计算一下 20W 数据大约占用的内存，然后设置一下 Redis 内存限制即可。 2.问题是什么数据？ 比如用户数据。数据库有2000w条。活跃用户：redis sortSet里 放两天内(为方便取一天内活跃用户)登录过的用户，登录一次ZADD一次，如set已存在则覆盖其分数（登录时间）。键：login:users，值：分数 时间戳、value userid。设置一个周期任务，比如每天03:00:00点删除sort set中前一天3点前的数据（保证set不无序增长、留近一天内活跃用户）。 取时，拿到当前时间戳（int 10位），再减1天就可按分数范围取过去24h活跃用户。 3.看你的提问,应该只是把Redis当缓存来用.提供一种简单实现缓存失效的思路: LRU(最近少用的淘汰)即redis的缓存每命中一次,就给命中的缓存增加一定ttl(过期时间)(根据具体情况来设定, 比如10分钟).一段时间后, 热数据的ttl都会较大, 不会自动失效, 而冷数据基本上过了设定的ttl就马上失效了.","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"热点数据","slug":"热点数据","permalink":"http://example.com/tags/%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE/"}],"author":"John Doe"},{"title":"Redis共享整数字符串","slug":"Redis共享整数字符串","date":"2022-02-07T01:55:00.000Z","updated":"2022-02-07T01:55:23.165Z","comments":true,"path":"2022/02/07/Redis共享整数字符串/","link":"","permalink":"http://example.com/2022/02/07/Redis%E5%85%B1%E4%BA%AB%E6%95%B4%E6%95%B0%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"共享","slug":"共享","permalink":"http://example.com/tags/%E5%85%B1%E4%BA%AB/"}],"author":"John Doe"},{"title":"Redis对象内存回收","slug":"Redis对象内存回收","date":"2022-02-07T01:53:00.000Z","updated":"2022-02-07T01:53:31.910Z","comments":true,"path":"2022/02/07/Redis对象内存回收/","link":"","permalink":"http://example.com/2022/02/07/Redis%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6/","excerpt":"","text":"","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"内存回收","slug":"内存回收","permalink":"http://example.com/tags/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6/"}],"author":"John Doe"},{"title":"Redis底层数据结构之对象","slug":"Redis底层数据结构之对象","date":"2022-02-07T00:49:00.000Z","updated":"2022-02-07T01:52:21.525Z","comments":true,"path":"2022/02/07/Redis底层数据结构之对象/","link":"","permalink":"http://example.com/2022/02/07/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"Redis对外提供了五种数据类型，分别是String、List、HashMap、HashSet以及ZSeT，其中String作为key-value键值映射的key，以及五种value之一，而其他四种则只能作为value。并且这五种数据类型在底层实现上都至少有两种数据结构实现。 在底层上，由一个type类型表明当前数据对象属于哪个类型，由encodeing表明底层具体的数据结构实现，然后由一个指针指向底层的数据结构实现。这样的好处的话主要就是在不同的应用场景选择不同的底层数据结构实现，会大大提高redis的存储性能。 1、具体的话，String类型底层实现有：int、raw、embstr三种数据结构的实现。其中int类型的底层数据结构实现主要是用于存放整数值，当我们的value是一个整数值，就可以选择用int类型的底层实现。而raw类型的底层实现则是一个动态字符串数据结构，一般当字符串大于32字节就会使用到。embstr则是当字符串小于32字节会使用到。两者的不同在于，embstr只会进行一次内存分配和释放，而raw则会进行两次内存分配和释放；而且embstr的内存时连续的，而raw不是。 需要注意的是：double这种浮点型的数据作为value存储的时候，底层使用的是str类型的数据结构实现。另外上述三种底层数据结构实现是可以相互转换的。 2、list类型底层编码可以使ziplist和linkedlist两种类型，当list满足每个节点小于64字节并且节点数小于512个就可以采用ziplist作为底层实现，否则采用linkedlist 3、hash对象底层编码可以使ziplist和hashtable两种类型 4、set集合的编码实现可以使整数集合和hashtable 5、有序集合zset的编码实现：ziplist和skiplist。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"对象","slug":"对象","permalink":"http://example.com/tags/%E5%AF%B9%E8%B1%A1/"}],"author":"John Doe"},{"title":"Redis底层数据结构之整数集合","slug":"Redis底层数据结构之整数集合","date":"2022-02-06T13:40:00.000Z","updated":"2022-02-06T13:49:01.981Z","comments":true,"path":"2022/02/06/Redis底层数据结构之整数集合/","link":"","permalink":"http://example.com/2022/02/06/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/","excerpt":"","text":"整数集合是Redis用于保存整数值得集合数据结构，可以保存int16、int32、int64de整数值，并且有序不会重复，具体由encoding决定保存是int16、32还是64. 当将一个新元素加入整数集合时，而且这个元素类型长于当前集合类型，就会先对集合升级，然后在加入新元素。 升级： 1、根据新元素类型，开辟新的数组 2、将原数组的元素转移到新数组的正确位置上，且转化为与新数组相同的类型 3、将新元素加到新数组指定的位置 好处： 1、提升灵活性，C语言是静态类型语言，为了避免错误，不会将两种类型放在一个数据结构里面，通过底层数组升级操作，不必担心不同类型的整数出现类型错误 2、节约内存，整数集合的升级操作，确保了只在需要的时候进行，尽量节约内存。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"整数集合","slug":"整数集合","permalink":"http://example.com/tags/%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/"}],"author":"John Doe"},{"title":"Redis底层数据结构之跳表","slug":"Redis底层数据结构实现之跳表","date":"2022-02-06T13:13:00.000Z","updated":"2022-02-06T13:24:50.758Z","comments":true,"path":"2022/02/06/Redis底层数据结构实现之跳表/","link":"","permalink":"http://example.com/2022/02/06/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%9E%E7%8E%B0%E4%B9%8B%E8%B7%B3%E8%A1%A8/","excerpt":"","text":"跳表支持平均o（logN）、最坏O（n）复杂度的节点查找，还可以通过顺序性操作来批量处理节点。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"跳表","slug":"跳表","permalink":"http://example.com/tags/%E8%B7%B3%E8%A1%A8/"}],"author":"John Doe"},{"title":"Redis底层数据结构之字典","slug":"Redis底层实现之字典","date":"2022-02-06T12:37:00.000Z","updated":"2022-02-06T13:24:45.912Z","comments":true,"path":"2022/02/06/Redis底层实现之字典/","link":"","permalink":"http://example.com/2022/02/06/Redis%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E4%B9%8B%E5%AD%97%E5%85%B8/","excerpt":"","text":"字典即符号表，Redis的数据库就是通过字典作为底层实现的。而字典的底层实现主要是使用hash表。 1、hash表底层实现是通过数组加链表实现的，对于一个key值，通过计算其hashcode，然后与上hash表的掩码（数组-1），得到在数组中的下标，然后同该下标上的链表进行比较（没有链表则直接加上去），看是否是同一个值，如果是，则覆盖，不是则加到链表尾。 2、字典则是一个包含两个hash表的结构体，一般情况只使用下标为0的hash表，当对0下标的hash表进行扩容时，会使用到1下标处的hash表。即当0下标处的hash表 a）满足服务器没有执bgsave或者bgrewriteaof命令，并且hash表负载因子大于等于1 b）或者满足服务器执bgsave或者bgrewriteaof命令，并且hash表负载因子大于等于5 （因为在执bgsave或者bgrewriteaof命令时，服务器在执行备份操作，为了尽可能提高其效率，避免在此期间进行hash表扩容操作） c）负载因子小于0.1会收缩 就会发生扩容，此时会渐进的将0下标的hash表的数据转移到扩容后的1下标处。（这里之所以采取渐进式的转移，主要是考虑到当hash表里面存的数据量很大时，一次性转移会很消耗时间）","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"}],"author":"John Doe"},{"title":"Redis底层数据结构之链表","slug":"Redis底层数据结构之链表","date":"2022-02-06T12:28:00.000Z","updated":"2022-02-06T12:35:31.761Z","comments":true,"path":"2022/02/06/Redis底层数据结构之链表/","link":"","permalink":"http://example.com/2022/02/06/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%93%BE%E8%A1%A8/","excerpt":"","text":"链表作为一种常用数据结构，Redis也对其进行了实现。链表键、发布与订阅、慢查询、监视器等方面都用到了链表。其底层由node节点和list结构构成，node节点包含前驱和后继指针以及value值，而list结构则包含了指向投节点、尾结点的指针以及链表节点数、节点复制函数、释放函数等。即最终是一个双端无环链表。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"}],"author":"John Doe"},{"title":"Redis底层数据结构之SDS","slug":"Redis底层数据结构之SDS","date":"2022-02-06T12:13:00.000Z","updated":"2022-02-06T12:36:06.134Z","comments":true,"path":"2022/02/06/Redis底层数据结构之SDS/","link":"","permalink":"http://example.com/2022/02/06/Redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8BSDS/","excerpt":"","text":"Redis是用C语言写的，底层实现了众多数据结构，其中字符串是最常用的一种，其底层实现并不是用的C语言的char[]数组，而是进行了简单的封装sds结构体，定义了一个int的len、free和char[]来实现字符串。其相较于原生的C语言字符串有如下优点： 1、可以通过len-free以常数阶获取字符串长度 2、可以通过free字段避免缓冲区出现溢出的情况 3、同时也减少字符串修改时，内存重新分配的次数，其具体实现是通过预先分配内存（即当追加字符串之后，字符串小于1MB，会多分配一倍的空间）和懒惰回收（即当字符串变短之后，不会立即回收那一部分空间，而是作为临时空间供后续字符串扩增做优化） 4、可以保存二进制安全的数据","categories":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"}],"tags":[{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}],"author":"John Doe"},{"title":"枚举单例模式如何防止反射和反序列化","slug":"枚举单例模式如何防止反射和反序列化","date":"2022-01-27T11:08:00.000Z","updated":"2022-03-05T01:43:58.546Z","comments":true,"path":"2022/01/27/枚举单例模式如何防止反射和反序列化/","link":"","permalink":"http://example.com/2022/01/27/%E6%9E%9A%E4%B8%BE%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E5%8F%8D%E5%B0%84%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/","excerpt":"","text":"1、枚举单例在创建时不存在并发问题： 枚举类里的各个枚举项是是通过static代码块来定义和初始化的，它们会在类被加载时完成初始化，而java类的加载由JVM保证线程安全，所以，创建一个Enum类型的枚举是线程安全的 2、反序列化： Java对枚举的序列化作了规定，在序列化时，仅将枚举对象的name属性输出到结果中，在反序列化时，就是通过java.lang.Enum的valueOf来根据名字查找对象，而不是新建一个新的对象。枚举在序列化和反序列化时，并不会调用构造方法，这就防止了反序列化导致的单例破坏的问题。 3、反射： 反射在通过newInstance创建对象时，会检查这个类是否是枚举类，如果是，会抛出异常java.lang.IllegalArgumentException: Cannot reflectively create enum objects，表示反射创建对象失败。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://example.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"单利模式防止反射创建新的实例","slug":"单利模式防止反射创建新的实例","date":"2022-01-27T09:47:00.000Z","updated":"2022-01-27T09:49:12.324Z","comments":true,"path":"2022/01/27/单利模式防止反射创建新的实例/","link":"","permalink":"http://example.com/2022/01/27/%E5%8D%95%E5%88%A9%E6%A8%A1%E5%BC%8F%E9%98%B2%E6%AD%A2%E5%8F%8D%E5%B0%84%E5%88%9B%E5%BB%BA%E6%96%B0%E7%9A%84%E5%AE%9E%E4%BE%8B/","excerpt":"","text":"方法一（饿汉式）：在私有的构造器里面增加判断，如果不为空，抛出异常之类 方法二（懒汉式）：可以增加一个静态变量，然后在类初始化的时候将静态变量修改值，然后在构造器内判断静态变量的值来做相应的操作","categories":[],"tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://example.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"如果实现了序列化接口, 还要做什么来防止反序列化破坏单例","slug":"：如果实现了序列化接口-还要做什么来防止反序列化破坏单例","date":"2022-01-27T09:40:00.000Z","updated":"2022-01-27T09:47:09.071Z","comments":true,"path":"2022/01/27/：如果实现了序列化接口-还要做什么来防止反序列化破坏单例/","link":"","permalink":"http://example.com/2022/01/27/%EF%BC%9A%E5%A6%82%E6%9E%9C%E5%AE%9E%E7%8E%B0%E4%BA%86%E5%BA%8F%E5%88%97%E5%8C%96%E6%8E%A5%E5%8F%A3-%E8%BF%98%E8%A6%81%E5%81%9A%E4%BB%80%E4%B9%88%E6%9D%A5%E9%98%B2%E6%AD%A2%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E7%A0%B4%E5%9D%8F%E5%8D%95%E4%BE%8B/","excerpt":"","text":"在类中添加如下方法","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[],"author":"John Doe"},{"title":"Redis开发运维实践指南笔记","slug":"Redis开发运维实践指南笔记","date":"2022-01-26T14:10:01.000Z","updated":"2022-01-26T14:25:32.547Z","comments":true,"path":"2022/01/26/Redis开发运维实践指南笔记/","link":"","permalink":"http://example.com/2022/01/26/Redis%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1、Redis为一个运行在内存中的数据结构服务器（data structures server）。Redis使用的是单进程（除持久化时），所以在配置时，一个实例只会用到一个CPU。 2、 3、列出key： 渐进的遍历整个数据库：keys命令会一次性遍历整个数据库获取与之匹配的键，当数据库包含得键值越来越多，这个命令会愈来愈慢，因此，可以用scan命令渐进的，分多次遍历整个数据库 4、 5、","categories":[],"tags":[],"author":"John Doe"},{"title":"交替打印输出","slug":"交替打印输出","date":"2022-01-26T12:59:00.000Z","updated":"2022-01-26T13:00:45.447Z","comments":true,"path":"2022/01/26/交替打印输出/","link":"","permalink":"http://example.com/2022/01/26/%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E8%BE%93%E5%87%BA/","excerpt":"","text":"三个线程交替打印输出 public class AlternateOutput &#123; public static void main(String[] args) &#123; // Test1 test1 = new Test1(); // new Thread(()-&gt;&#123; // try &#123; // test1.print(1); // &#125; catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; // &#125;).start(); // new Thread(()-&gt;&#123; // try &#123; // test1.print(2); // &#125; catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; // &#125;).start(); // new Thread(()-&gt;&#123; // try &#123; // test1.print(3); // &#125; catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; // &#125;).start(); // Test2 test2 = new Test2(); // Thread t1 = new Thread(()-&gt;&#123; // try &#123; // test2.print(&quot;a&quot;); // &#125; catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; // &#125;); // Thread t2 = new Thread(()-&gt;&#123; // try &#123; // test2.print(&quot;b&quot;); // &#125; catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; // &#125;); // Thread t3 = new Thread(()-&gt;&#123; // try &#123; // test2.print(&quot;c&quot;); // &#125; catch (InterruptedException e) &#123; // e.printStackTrace(); // &#125; // &#125;); // test2.setThreads(t1,t2,t3); // test2.start(); Test3 test3 = new Test3(); Condition condition1 = test3.newCondition(); Condition condition2 = test3.newCondition(); Condition condition3 = test3.newCondition(); new Thread(()-&gt;&#123; test3.print(&quot;a&quot;,condition1,condition2); &#125;).start(); new Thread(()-&gt;&#123; test3.print(&quot;b&quot;,condition2,condition3); &#125;).start(); new Thread(()-&gt;&#123; test3.print(&quot;c&quot;,condition3,condition1); &#125;).start(); test3.start(condition1); &#125; &#125; class Test1&#123; private Integer flag = 1; private Integer num = 10; public void print(int curFlag) throws InterruptedException &#123; for (int i=0; i&lt;num; ++i)&#123; synchronized (this)&#123; while (this.flag != curFlag)&#123; this.wait(); &#125; System.out.println(curFlag); this.flag = curFlag % 3 + 1; this.notifyAll(); &#125; &#125; &#125; &#125; class Test2&#123; private Thread[] threads; private Integer num = 10; public Test2(Thread... threads) &#123; this.threads = threads; &#125; public void setThreads(Thread... threads) &#123; this.threads = threads; &#125; public void print(String s) throws InterruptedException &#123; for (int i=0;i&lt;num;++i)&#123; LockSupport.park(); System.out.println(s); LockSupport.unpark(getNextThread()); &#125; &#125; public Thread getNextThread()&#123; int size = threads.length; Thread cur = Thread.currentThread(); for (int i=0;i&lt;size;++i)&#123; if (cur == threads[i])&#123; return threads[(i + 1) % size]; &#125; &#125; return null; &#125; public void start() &#123; for (Thread thread: threads)&#123; thread.start(); &#125; LockSupport.unpark(threads[0]); &#125; &#125; class Test3 extends ReentrantLock&#123; private int num = 10; public void start(Condition condition)&#123; this.lock(); try &#123; condition.signal(); &#125;finally &#123; this.unlock(); &#125; &#125; public void print(String s, Condition cur,Condition next)&#123; for (int i=0;i&lt;num;++i)&#123; this.lock(); try&#123; cur.await(); System.out.println(s); next.signal(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; this.unlock(); &#125; &#125; &#125; &#125;","categories":[],"tags":[],"author":"John Doe"},{"title":"synchronized锁静态变量Integer","slug":"synchronized锁静态变量Integer","date":"2022-01-25T02:18:00.000Z","updated":"2022-01-25T02:22:28.673Z","comments":true,"path":"2022/01/25/synchronized锁静态变量Integer/","link":"","permalink":"http://example.com/2022/01/25/synchronized%E9%94%81%E9%9D%99%E6%80%81%E5%8F%98%E9%87%8FInteger/","excerpt":"","text":"当我尝试用synchronized去锁一个Integer的静态变量时，在多线程下发生了线程不安全问题，原因是synchronized锁住的Integer静态变量在不断发生变化，即i++会不断创建新的Integer，然后致使多线程下锁的不是一个对象，锁无效（以下代码在-128~127之间是有效的，因为存在Integer缓存问题）。 public class Main &#123; private static Integer i = 0; public static void main(String[] args) throws InterruptedException &#123; List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; 2; j++) &#123; Thread thread = new Thread(() -&gt; &#123; for (int k = 0; k &lt; 127; k++) &#123; synchronized (i) &#123; i++; &#125; &#125; &#125;, &quot;&quot; + j); list.add(thread); &#125; list.stream().forEach(t -&gt; t.start()); list.stream().forEach(t -&gt; &#123; try &#123; t.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println(i); &#125; &#125;","categories":[{"name":"juc","slug":"juc","permalink":"http://example.com/categories/juc/"}],"tags":[{"name":"synchronized","slug":"synchronized","permalink":"http://example.com/tags/synchronized/"}],"author":"John Doe"},{"title":"终止模式之两阶段终止模式（Interrupt）","slug":"终止模式之两阶段终止模式","date":"2022-01-24T11:10:00.000Z","updated":"2022-01-24T11:20:45.418Z","comments":true,"path":"2022/01/24/终止模式之两阶段终止模式/","link":"","permalink":"http://example.com/2022/01/24/%E7%BB%88%E6%AD%A2%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%B8%A4%E9%98%B6%E6%AE%B5%E7%BB%88%E6%AD%A2%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"Thread类中的stop（）方法可以用于终止一个线程，但这个方法要求立即终止，被终止的线程没有机会料理后事。因此，这里采用终止模式中的两阶段终止模式来优雅的结束一个线程，给被终止的线程一个料理后事的机会。（如果被打断线程正在 sleep，wait，join 会导致被打断的线程抛InterruptedException，并清除 打断标记如果打断的正在运行的线程，则会设置打断标记 ；park的线程被打断，也会设置 打断标记） public class TPTInterrupt &#123; public static void main(String[] args) throws InterruptedException &#123; TPTInterrupt tptInterrupt = new TPTInterrupt(); tptInterrupt.start(); Thread.sleep(2000); tptInterrupt.stop(); &#125; private Thread thread; public void start()&#123; thread = new Thread(()-&gt;&#123; while (true)&#123; Thread thread = Thread.currentThread(); if (thread.isInterrupted())&#123; System.out.println(&quot;料理后事...&quot;); break; &#125; try &#123; Thread.sleep(1000); System.out.println(&quot;运行中...&quot;); &#125; catch (InterruptedException e) &#123; // 标记打断 e.printStackTrace(); thread.interrupt(); &#125; &#125; &#125;); thread.start(); &#125; public void stop()&#123; thread.interrupt(); &#125; &#125;","categories":[{"name":"juc","slug":"juc","permalink":"http://example.com/categories/juc/"},{"name":"设计模式","slug":"juc/设计模式","permalink":"http://example.com/categories/juc/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"终止模式","slug":"终止模式","permalink":"http://example.com/tags/%E7%BB%88%E6%AD%A2%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"创建线程的方式","slug":"创建线程的方式","date":"2022-01-24T11:02:00.000Z","updated":"2022-03-08T14:03:10.109Z","comments":true,"path":"2022/01/24/创建线程的方式/","link":"","permalink":"http://example.com/2022/01/24/%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%96%B9%E5%BC%8F/","excerpt":"","text":"1、创建Thread对象 2、使用Runnable配合Thread使用 3、FutureTask配合Callable和Thread使用 4、通过线程池创建","categories":[],"tags":[{"name":"创建线程","slug":"创建线程","permalink":"http://example.com/tags/%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B/"}],"author":"John Doe"},{"title":"为什么要自定义类型加载器？","slug":"为什么要自定义类型加载器？","date":"2022-01-23T11:19:00.000Z","updated":"2022-01-23T11:20:52.309Z","comments":true,"path":"2022/01/23/为什么要自定义类型加载器？/","link":"","permalink":"http://example.com/2022/01/23/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%9E%8B%E5%8A%A0%E8%BD%BD%E5%99%A8%EF%BC%9F/","excerpt":"","text":"1、隔离加载类：在某些框架内进行中间件与应用的模块隔离，把类加载到不同的环境。比如：阿里内某容器框架通过自定义类加载器确保应用中依赖的 jar 包不会影响到中间件运行时使用的 jar 包。再比如：Tomcat 这类 Web 应用服务器，内部自定义了好几种类加载器，用于隔离同一个 Web 应用服务器上的不同应用程序。(类的仲裁 –&gt; 类冲突) 2、修改类加载的方式：类的加载模型并非强制，除 Bootstrap 外，其他的加载并非一定要引入，或者根据实际情况在某个时间点按需进行动态加载 3、扩展加载源：比如从数据库、网络、甚至是电视机机顶盒进行加载 4、防止源码泄露：Java 代码容易被编译和篡改，可以进行编译加密。那么类加载也需要自定义，还原加密的字节码","categories":[{"name":"jv'm","slug":"jv-m","permalink":"http://example.com/categories/jv-m/"}],"tags":[],"author":"John Doe"},{"title":"沙箱安全机制","slug":"沙箱安全机制","date":"2022-01-23T11:16:00.000Z","updated":"2022-01-23T11:19:08.964Z","comments":true,"path":"2022/01/23/沙箱安全机制/","link":"","permalink":"http://example.com/2022/01/23/%E6%B2%99%E7%AE%B1%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/","excerpt":"","text":"沙箱安全机制就是将java代码限定在jvm特定的运行范围，并且严格限制代码对本地资源的访问，本地系统造成破坏。","categories":[{"name":"jv'm","slug":"jv-m","permalink":"http://example.com/categories/jv-m/"}],"tags":[],"author":"John Doe"},{"title":"判定一个类型是否属于\"不再被使用的类\"的条件","slug":"判定一个类型是否属于-不再被使用的类-的条件","date":"2022-01-23T09:49:00.000Z","updated":"2022-01-23T09:50:58.551Z","comments":true,"path":"2022/01/23/判定一个类型是否属于-不再被使用的类-的条件/","link":"","permalink":"http://example.com/2022/01/23/%E5%88%A4%E5%AE%9A%E4%B8%80%E4%B8%AA%E7%B1%BB%E5%9E%8B%E6%98%AF%E5%90%A6%E5%B1%9E%E4%BA%8E-%E4%B8%8D%E5%86%8D%E8%A2%AB%E4%BD%BF%E7%94%A8%E7%9A%84%E7%B1%BB-%E7%9A%84%E6%9D%A1%E4%BB%B6/","excerpt":"","text":"1、该类所有的实例都被回收，即java堆中不存在该类的实例或其子类实例对象 2、加载该类的类加载器被回收 3、该类对应的java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法","categories":[{"name":"jv'm","slug":"jv-m","permalink":"http://example.com/categories/jv-m/"},{"name":"jvm","slug":"jv-m/jvm","permalink":"http://example.com/categories/jv-m/jvm/"}],"tags":[],"author":"John Doe"},{"title":"类的初始化情况：主动使用vs被动使用","slug":"类的初始化情况：主动使用vs被动使用","date":"2022-01-23T09:31:00.000Z","updated":"2022-01-23T09:43:56.451Z","comments":true,"path":"2022/01/23/类的初始化情况：主动使用vs被动使用/","link":"","permalink":"http://example.com/2022/01/23/%E7%B1%BB%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%83%85%E5%86%B5%EF%BC%9A%E4%B8%BB%E5%8A%A8%E4%BD%BF%E7%94%A8vs%E8%A2%AB%E5%8A%A8%E4%BD%BF%E7%94%A8/","excerpt":"","text":"主动使用：类只有在首次主动使用时才会被加载，而在首次使用被加载时，必须进行初始化。 以下使用被认为是主动使用：1、当创建一个类的实例时，比如使用 new 关键字，或者通过反射、克隆、反序列化 2、当调用类的静态方法时，即当使用了字节码 invokestatic 指令 3、当使用类、接口的静态字段时(final 修饰特殊考虑)，比如，使用 getstatic 或者 putsttic 指令。(对应访问变量、赋值变量操作) 4、当使用 java.lang.reflect 包中的方法反射类的方法时。比如：Class.forname(“com.atguigu.java.Test”) 5、当初始化子类时，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化 6、如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，该接口要在其之前被初始化 7、当虚拟机启动时，用户需要指定一个要执行的主类(包含 main() 方法的那个类)，虚拟机会先初始化这个主类 8、当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。(涉及解析 REF_getStatic、REF_putStatic、REF_invokeStatic 方法句柄对应的类) 注意：1、当Java 虚拟机初始化一个类时，要求它的所有父类都已经被初始化，但是这条规则并不适用于接口在初始化一个类时，并不会先初始化它所实现的接口在初始化一个接口时，并不会先初始化它的父接口。因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化，只有当程序首次使用特定接口的静态字段时，才会导致该接口的初始化2、JVM 启动的时候通过引导类加载器加载一个初始类。这个类在调用 public static void main(String[]) 方法之前被链接和初始化。这个方法的执行将依次导致所需的类的加载、链接和初始化 被动使用：除了以上的情况属于主动使用，其他的情况均属于被动使用。被动使用不会引起类的初始化。也就是说：并不是在代码中出现的类，就一定会被加载或者初始化。如果不符合主动使用的条件，类就不会初始化。 1、当访问一个静态字段时，只有真正声明这个字段的类才会被初始化 2、当通过子类引用父类的静态变量，不会导致子类初始化 3、通过数组定义类引用，不会触发此类的初始化 4、引用变量不会触发此类或接口的初始化。因为常量在链接阶段就已经被显式赋值了 5、调用 ClassLoader 类的 loadClass() 方法加载一个类，并不是对类的主动使用，不会导致类的初始化","categories":[{"name":"jv'm","slug":"jv-m","permalink":"http://example.com/categories/jv-m/"}],"tags":[{"name":"类初始化：主动使用与被动使用","slug":"类初始化：主动使用与被动使用","permalink":"http://example.com/tags/%E7%B1%BB%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%9A%E4%B8%BB%E5%8A%A8%E4%BD%BF%E7%94%A8%E4%B8%8E%E8%A2%AB%E5%8A%A8%E4%BD%BF%E7%94%A8/"}],"author":"John Doe"},{"title":"类的加载过程","slug":"类的加载过程","date":"2022-01-23T07:55:00.000Z","updated":"2022-01-23T08:54:30.085Z","comments":true,"path":"2022/01/23/类的加载过程/","link":"","permalink":"http://example.com/2022/01/23/%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/","excerpt":"","text":"类的加载，我的理解就是将类的二进制字节码文件加载到内存中，并通过解析字节码中的常量池、类字段、类方法等信息，在jvm方法区中构建出该类的模板，并在堆区创建一个对象实例作为方法区这个类的各种数据访问入口，在jvm运行期间能够通过这个类的模板信息来调用类的静态变量、方法等。其加载过程的话，主要分为加载、链接（验证、准备、解析）、初始化三个步骤。 1、首先加载，就是查找类的全限定类名，将类的二进制字节码文件加载到jvm的内存中，将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构，并为之在堆区创建一个实例对象，作为方法区这个类的数据访问入口。当然，在加载前还需要进行验证操作，即检查字节码文件格式，看是否遵循jvm的规范。比如是否以魔数开头等。验证通过后，该类的二进制信息便会被加载到内存。 2、加载到方法区后需要验证，即检查类的语义、字节码验证、符号引用验证，看是否符合规范。 3、当验证完毕之后，就开始准备阶段，这一步主要是对类的静态变量分配内存并附上默认值。（注意：final修饰的静态变量在编译阶段就会分配，准备阶段是显示赋值，并且此阶段也不会为实例变量分配初始化） 4、然后便是解析阶段，即将符号引用转变为直接引用，得到类、字段、方法等在内存中的指针或者偏移量。 5、最后便是初始化，这个阶段主要是为类的静态变量进行显示赋值。即执行类构造器cinit方法。即执行类变量的赋值动作和静态语句块(static{}块)，虚期机会保证在子类的()方法执行之前, 父类的()方法已经执行完毕。如果一个类中没有静态语句块,也没有对变量的赋值操作, 那么编译器可以不为这个类生成()方法。 需要注意的是：接口与类不同的是, 执行接口的()方法不需要先执行父接口的()方法。只有当父接口中定义的变量被使用时, 父接口才会被初始化。 另外, 接口的实现类在初始化时也一样不会执行接口的()方法。另外，虚拟机会保证一个类的()方法在多线程环境中被正确地加锁和同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的()法,其他线程部需要阻塞等待，直到活动线程执行()方法完毕。如果在一个类的()方法中有耗时很长的操作, 那就可能造成多个进程阻塞, 在实际应用中这种阻塞往往是隐蔽的。","categories":[{"name":"jv'm","slug":"jv-m","permalink":"http://example.com/categories/jv-m/"}],"tags":[{"name":"类的加载过程","slug":"类的加载过程","permalink":"http://example.com/tags/%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/"}],"author":"John Doe"},{"title":"关于集合类中的modCount++","slug":"关于集合类中的modCount","date":"2022-01-21T06:45:00.000Z","updated":"2022-01-21T07:17:15.741Z","comments":true,"path":"2022/01/21/关于集合类中的modCount/","link":"","permalink":"http://example.com/2022/01/21/%E5%85%B3%E4%BA%8E%E9%9B%86%E5%90%88%E7%B1%BB%E4%B8%AD%E7%9A%84modCount/","excerpt":"","text":"话不多说，直接看源码注释讲解 由上图可知，该字段目的在于记录集合结构被修改的次数（增、删、改），该字段被迭代器所使用，当对集合进行迭代遍历时，防止数据发生改变引起错误。因此，当我们使用迭代器时，如果该值被改了，就会触发fast-fail机制，抛出异常ConcurrentModificationExceptions。","categories":[{"name":"集合","slug":"集合","permalink":"http://example.com/categories/%E9%9B%86%E5%90%88/"},{"name":"java","slug":"集合/java","permalink":"http://example.com/categories/%E9%9B%86%E5%90%88/java/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://example.com/tags/ArrayList/"}],"author":"John Doe"},{"title":"HashMap1.7","slug":"HashMap","date":"2022-01-18T11:27:00.000Z","updated":"2022-01-18T11:53:34.793Z","comments":true,"path":"2022/01/18/HashMap/","link":"","permalink":"http://example.com/2022/01/18/HashMap/","excerpt":"","text":"HashMap1.7底层由数组+链表实现，提供的无参构造方法默认数组容量是16，加载因子是0.75，临界值为16 * 0.75 = 12，当到了临界值则进行扩容。 你也可以通过有参构造方法指定容量和加载因子。 注意，不管有参无参此时都还未初始化数组，只是定义了数组容量。当我们第一次put往hashmap的放数据的时候才会初始化 而此时初始化会根据我们最初的容量大小进行初始化，大小为大于等于当前容量的2的幂。 然后便是计算hash值，根据hash值得到数组下标，根据下标到指定位置，如果发送hash冲突则通过拉链法，将冲突元素头插进链表","categories":[{"name":"java基础","slug":"java基础","permalink":"http://example.com/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"集合","slug":"集合","permalink":"http://example.com/tags/%E9%9B%86%E5%90%88/"},{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"}],"author":"John Doe"},{"title":"ArrayList","slug":"ArrayList","date":"2022-01-17T12:13:00.000Z","updated":"2022-01-17T12:20:04.535Z","comments":true,"path":"2022/01/17/ArrayList/","link":"","permalink":"http://example.com/2022/01/17/ArrayList/","excerpt":"","text":"ArrayList 1、ArrayList底层默认是用object数组实现的，因此在增删元素上需要移动元素，效率较低，但支持随机访问元素 2、ArrayList是线层不安全的，并发环境下，多个线程同时操作 ArrayList，会引发不可预知的异常或错误。 3、ArrayList的默认的大小是10。一开始是空数组，当第一次add的时候才会扩容到10，后续容器满了之后会按1.5倍进行扩容。如果一开始指定容器大小，后续则直接按1.5倍进行扩容。最大扩容不超过Integer.MAX_VALUE","categories":[{"name":"java基础","slug":"java基础","permalink":"http://example.com/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"集合","slug":"集合","permalink":"http://example.com/tags/%E9%9B%86%E5%90%88/"},{"name":"List","slug":"List","permalink":"http://example.com/tags/List/"}],"author":"John Doe"},{"title":"成员变量与局部变量","slug":"成员变量与局部变量","date":"2022-01-16T11:20:00.000Z","updated":"2022-01-16T11:22:59.161Z","comments":true,"path":"2022/01/16/成员变量与局部变量/","link":"","permalink":"http://example.com/2022/01/16/%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F%E4%B8%8E%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F/","excerpt":"","text":"从语法形式上看:成员变量是属于类的，⽽局部变量是在⽅法中定义的变量或是⽅法的参数；成员变量可以被 public , private , static 等修饰符所修饰，⽽局部变量不能被访问控制修饰符及 static 所修饰；但是，成员变量和局部变量都能被 final 所修饰。2. 从变量在内存中的存储⽅式来看:如果成员变量是使⽤ static 修饰的，那么这个成员变量是属于类的，如果没有使⽤ static 修饰，这个成员变量是属于实例的。对象存于堆内存，如果局部变量类型为基本数据类型，那么存储在栈内存，如果为引⽤数据类型，那存放的是指向堆内存对象的引⽤或者是指向常量池中的地址。3. 从变量在内存中的⽣存时间上看:成员变量是对象的⼀部分，它随着对象的创建⽽存在，⽽局部变量随着⽅法的调⽤⽽⾃动消失。4. 成员变量如果没有被赋初值:则会⾃动以类型的默认值⽽赋值（⼀种情况例外:被 final 修饰的成员变量也必须显式地赋值），⽽局部变量则不会⾃动赋值。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[],"author":"John Doe"},{"title":"接口和抽象类的区别","slug":"接口和抽象类的区别","date":"2022-01-16T10:39:00.000Z","updated":"2022-01-16T11:17:43.700Z","comments":true,"path":"2022/01/16/接口和抽象类的区别/","link":"","permalink":"http://example.com/2022/01/16/%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%8A%BD%E8%B1%A1%E7%B1%BB%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"接⼝的⽅法默认是 public ，所有⽅法在接⼝中不能有实现(Java 8 开始接⼝⽅法可以有默认实现），⽽抽象类可以有⾮抽象的⽅法。 接⼝中除了 static 、 final 变量，不能有其他变量，⽽抽象类中则不⼀定。 ⼀个类可以实现多个接⼝，但只能实现⼀个抽象类。接⼝⾃⼰本身可以通过 extends 关键字扩展多个接⼝。 接⼝⽅法默认修饰符是 public ，抽象⽅法可以有 public 、 protected 和 default 这些修饰符（抽象⽅法就是为了被重写所以不能使⽤ private 关键字修饰！）。 从设计层⾯来说，抽象是对类的抽象，是⼀种模板设计，⽽接⼝是对⾏为的抽象，是⼀种⾏为的规范。备注： 在 JDK8 中，接⼝也可以定义静态⽅法，可以直接⽤接⼝名调⽤。实现类和实现是不可以调⽤的。如果同时实现两个接⼝，接⼝中定义了⼀样的默认⽅法，则必须重写，不然会报错。 jdk9 的接⼝被允许定义私有⽅法 。总结⼀下 jdk7~jdk9 Java 中接⼝概念的变化： 在 jdk 7 或更早版本中，接⼝⾥⾯只能有常量变量和抽象⽅法。这些接⼝⽅法必须由选择实现接⼝的类实现。 jdk 8 的时候接⼝可以有默认⽅法和静态⽅法功能。 Jdk 9 在接⼝中引⼊了私有⽅法和私有静态⽅法。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"接口","slug":"接口","permalink":"http://example.com/tags/%E6%8E%A5%E5%8F%A3/"}],"author":"John Doe"},{"title":"在 Java 中定义⼀个不做事且没有参数的构造⽅法的作⽤","slug":"在-Java-中定义⼀个不做事且没有参数的构造⽅法的作⽤","date":"2022-01-16T10:34:00.000Z","updated":"2022-01-16T10:34:43.521Z","comments":true,"path":"2022/01/16/在-Java-中定义⼀个不做事且没有参数的构造⽅法的作⽤/","link":"","permalink":"http://example.com/2022/01/16/%E5%9C%A8-Java-%E4%B8%AD%E5%AE%9A%E4%B9%89%E2%BC%80%E4%B8%AA%E4%B8%8D%E5%81%9A%E4%BA%8B%E4%B8%94%E6%B2%A1%E6%9C%89%E5%8F%82%E6%95%B0%E7%9A%84%E6%9E%84%E9%80%A0%E2%BD%85%E6%B3%95%E7%9A%84%E4%BD%9C%E2%BD%A4/","excerpt":"","text":"Java 程序在执⾏⼦类的构造⽅法之前，如果没有⽤ super() 来调⽤⽗类特定的构造⽅法，则会调⽤⽗类中“没有参数的构造⽅法”。因此，如果⽗类中只定义了有参数的构造⽅法，⽽在⼦类的构造⽅法中⼜没有⽤ super() 来调⽤⽗类中特定的构造⽅法，则编译时将发⽣错误，因为 Java 程序在⽗类中找不到没有参数的构造⽅法可供执⾏。解决办法是在⽗类⾥加上⼀个不做事且没有参数的构造⽅法。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[],"author":"John Doe"},{"title":"重载和重写的区别","slug":"重载和重写的区别","date":"2022-01-16T10:05:00.000Z","updated":"2022-01-16T10:25:19.715Z","comments":true,"path":"2022/01/16/重载和重写的区别/","link":"","permalink":"http://example.com/2022/01/16/%E9%87%8D%E8%BD%BD%E5%92%8C%E9%87%8D%E5%86%99%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"重载：在一个java类中，有多个方法同名，签名不同（即不同的参数数量、顺序以及类型）的函数，就发生了重载。 重写：子类继承了父类然后重写了父类中的方法（保持和父类方法的返回值类型、函数名、签名等都不变，只是在函数体中的代码实现逻辑改变了） 注意：重写时，子类抛出的异常范围应小于等于父类，访问修饰变量范围应大于等于父类。如果父类方法被final、static、private修饰则子类不能重写父类方法，但被static修饰的方法可以再次声明。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"重写","slug":"重写","permalink":"http://example.com/tags/%E9%87%8D%E5%86%99/"},{"name":"重载","slug":"重载","permalink":"http://example.com/tags/%E9%87%8D%E8%BD%BD/"}],"author":"ATAO"},{"title":"Java中的基本数据类型","slug":"Java中的基本数据类型","date":"2022-01-15T10:31:00.000Z","updated":"2022-01-15T10:35:39.104Z","comments":true,"path":"2022/01/15/Java中的基本数据类型/","link":"","permalink":"http://example.com/2022/01/15/Java%E4%B8%AD%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"java中的基本数据类型有byte（1字节）、short（2字节）、int（四字节）、long（8字节）、float（4字节）、double（8字节）、boolean（1位）、char（2字节）","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}],"author":"ATAO"},{"title":"final、finalize()、finally","slug":"final、finalize-、finally","date":"2022-01-11T01:48:00.000Z","updated":"2022-01-11T02:27:34.968Z","comments":true,"path":"2022/01/11/final、finalize-、finally/","link":"","permalink":"http://example.com/2022/01/11/final%E3%80%81finalize-%E3%80%81finally/","excerpt":"","text":"1、final：在java中，final主要用于修饰类、方法和变量。 1.1 修饰类：用final修饰类时，表明这个类不能被其他类所继承。 注意：当用final对类进行修饰的时候，类中所有成员方法默认是final方法。 1.2 修饰方法：用fianl修饰方法时，表明这个方法不能被其子类重写。 1.3 修饰变量：用final修饰变量的话表明这个变量是一个常量，只能被赋值一次，赋值后其值不能够修改。 当final修饰一个基本数据类型时，表示该基本数据类型的值一旦在初始化后便不能发生变化（）；如果final修饰一个引用类型时，则在对其初始化之后便不能再让其指向其他对象了，但该引用所指向的对象的内容是可以发生变化的。本质上是一回事，因为引用的值是一个地址，final要求值，即地址的值不发生变化。 final修饰一个成员变量（属性），必须要显示初始化。这里有两种初始化方式，一种是在变量声明的时候初始化；第二种方法是在声明变量的时候不赋初值，但是要在这个变量所在的类的所有的构造函数中对这个变量赋初值。 扩展：在java中，String被设计成final类，那为什么平时使用时，String的值可以被改变呢？ 字符串常量池是java堆内存中一个特殊的存储区域，当我们建立一个String对象时，假设常量池不存在该字符串，则创建一个，若存在则直接引用已经存在的字符串。当我们对String对象值改变的时候，例如 String a=&quot;A&quot;; a=&quot;B&quot; 。a是String对象的一个引用（我们这里所说的String对象其实是指字符串常量），当a=“B”执行时，并不是原本String对象(&quot;A&quot;)发生改变，而是创建一个新的对象(&quot;B&quot;)，令a引用它。 2、finally：finally作为异常处理的一部分，它用在try/catch语句中，经常被用在需要释放资源的情况下。 注意： 1、只有与finally对应的try语句块得到执行的情况下，finally语句块才会执行。 2、在 try 语句块中执行了 System.exit (0) 语句，终止了 Java 虚拟机的运行或者在执行 try 语句块或者 catch 语句块时被打断（interrupted）或者被终止（killed）等情况finally也可能不会执行。 易错点： 答案：4 4 4 原因：finally语句在return之前执行。 3、finalize：finalize()是在java.lang.Object里定义的，每一个对象都有这么个方法。这个方法在gc启动，该对象被回收的时候被调用。 注意：一个对象的finalize()方法只会被调用一次，而且finalize()被调用不意味着gc会立即回收该对象，所以有可能调用finalize()后，该对象又不需要被回收了，然后到了真正要被回收的时候，因为前面调用过一次，所以不会调用finalize()，产生问题。 所以，推荐不要使用finalize()方法，它跟析构函数不一样。","categories":[{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"final、finally、fi'nalize","slug":"final、finally、fi-nalize","permalink":"http://example.com/tags/final%E3%80%81finally%E3%80%81fi-nalize/"}],"author":"ATAo"},{"title":"为什么Integer 100==100 为true，而Integer 1000==1000为false？","slug":"为什么Integer-100-100-为true，而Integer-1000-1000为false？","date":"2022-01-08T13:39:00.000Z","updated":"2022-01-08T14:19:54.922Z","comments":true,"path":"2022/01/08/为什么Integer-100-100-为true，而Integer-1000-1000为false？/","link":"","permalink":"http://example.com/2022/01/08/%E4%B8%BA%E4%BB%80%E4%B9%88Integer-100-100-%E4%B8%BAtrue%EF%BC%8C%E8%80%8CInteger-1000-1000%E4%B8%BAfalse%EF%BC%9F/","excerpt":"","text":"在java的Integer包装类中为什么Integer a = 100, b = 100,c = 1000,d =1000，令a==b为true，而c==d为false呢？ 首先在上面的代码中，Integer a = 100会调用Integer的Integer.valueOf(int i)这个方法，而这个方法的源代码如下： 我们会发现在将int类型装箱时做了一个判断语句 if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) 这句话是什么意思呢？通过注释可以知道，在将一个int类型装箱为Integer类型时，总会优先调用此方法。其存在一个-128到127范围的缓存，如果int类型时该范围内，则直接返回缓存中的值，不需要额外创建Integer类型，这样可以产生显著更好的空间和时间性能。而且其范围也是可以设置。 所有我们可以知道，在执行Integer a = 100，b = 100时，走了缓存，因此b的地址同a应该一样，而c = 1000, d = 1000并为走缓存，而是走的new Interger(i)，因此创建了两个对象。 而我们知道，==比较走的是比较对象的地址。因此才会有为什么Integer 100==100 为true，而Integer 1000==1000为false。 debug如下：","categories":[{"name":"java基础","slug":"java基础","permalink":"http://example.com/categories/java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Integer","slug":"Integer","permalink":"http://example.com/tags/Integer/"}],"author":"ATAO"},{"title":"快速选择","slug":"快速选择","date":"2022-01-08T06:04:00.000Z","updated":"2022-01-08T06:08:50.171Z","comments":true,"path":"2022/01/08/快速选择/","link":"","permalink":"http://example.com/2022/01/08/%E5%BF%AB%E9%80%9F%E9%80%89%E6%8B%A9/","excerpt":"","text":"快速选择，适用于寻找无序数组中第k大（小）或者前k大（小）这种情况，即TopK问题，是快速排序的一种变化。 class Solution &#123; public static int[] getLeastNumbers(int[] arr, int k) &#123; return quickSelect(arr,k,0,arr.length-1); &#125; private static int[] quickSelect(int[] arr,int k,int l, int r)&#123; if (arr.length &lt;= k)&#123; return arr; &#125; int index = quickSort(arr,l,r); if (index == k)&#123; return Arrays.copyOf(arr,index); &#125;else if (index &lt; k)&#123; return quickSelect(arr,k,index+1,r); &#125;else &#123; return quickSelect(arr,k,l,index-1); &#125; &#125; private static int quickSort(int[] arr, int l, int r) &#123; int mid = l ,i = l, j = r; while (i &lt; j)&#123; while (i&lt;j &amp;&amp; arr[j] &gt;= arr[mid])&#123; --j; &#125; if(i&lt;j &amp;&amp; arr[j] &lt; arr[mid])&#123; swap(arr,j,mid); mid = j; &#125; // p(arr); while (i&lt;j &amp;&amp; arr[i] &lt;= arr[mid])&#123; ++i; &#125; if(i&lt;j &amp;&amp; arr[i] &gt; arr[mid])&#123; swap(arr,i,mid); mid = i; &#125; // p(arr); &#125; swap(arr,i,mid); return mid; &#125; private static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125; public static void p(int[] arr)&#123; for (int n:arr)&#123; System.out.print(n+&quot; &quot;); &#125; System.out.println(); &#125; &#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"快速选择","slug":"快速选择","permalink":"http://example.com/tags/%E5%BF%AB%E9%80%9F%E9%80%89%E6%8B%A9/"},{"name":"Top","slug":"Top","permalink":"http://example.com/tags/Top/"}],"author":"ATAO"},{"title":"快速排序","slug":"快速排序","date":"2022-01-08T05:41:00.000Z","updated":"2022-01-08T05:48:02.025Z","comments":true,"path":"2022/01/08/快速排序/","link":"","permalink":"http://example.com/2022/01/08/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","excerpt":"","text":"原理： 设要排序的数组是A[0]……A[N-1]，首先任意选取一个数据（通常选用数组的第一个数）作为关键数据，然后将所有比它小的数都放到它左边，所有比它大的数都放到它右边，这个过程称为一趟快速排序。值得注意的是，快速排序不是一种稳定的排序算法，也就是说，多个相同的值的相对位置也许会在算法结束时产生变动。 一趟快速排序的算法是： 1）设置两个变量i、j，排序开始的时候：i=0，j=N-1； 2）以第一个数组元素作为关键数据，赋值给key，即key=A[0]； 3）从j开始向前搜索，即由后开始向前搜索(j--)，找到第一个小于key的值A[j]，将A[j]和A[i]的值交换； 4）从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于key的A[i]，将A[i]和A[j]的值交换； 5）重复第3、4步，直到i==j； (3,4步中，没找到符合条件的值，即3中A[j]不小于key,4中A[i]不大于key的时候改变j、i的值，使得j=j-1，i=i+1，直至找到为止。找到符合条件的值，进行交换的时候i， j指针位置不变。另外，i==j这一过程一定正好是i+或j-完成的时候，此时令循环结束）。 代码： public class QuickSort &#123; public static void main(String[] args) &#123; int k = 3; int[] arr = &#123;5,3,7,6,4,1,0,2,9,10,8&#125;; quickSort(arr,0,arr.length-1); p(arr); &#125; private static int[] quickSort(int[] arr,int l, int r) &#123; if (l&gt;r) return null; int mid = l ,i = l, j = r; while (i &lt; j)&#123; while (i&lt;j &amp;&amp; arr[j] &gt;= arr[mid])&#123; --j; &#125; if(i&lt;j &amp;&amp; arr[j] &lt; arr[mid])&#123; swap(arr,j,mid); mid = j; &#125; p(arr); while (i&lt;j &amp;&amp; arr[i] &lt;= arr[mid])&#123; ++i; &#125; if(i&lt;j &amp;&amp; arr[i] &gt; arr[mid])&#123; swap(arr,i,mid); mid = i; &#125; p(arr); &#125; System.out.println(&quot;=========&quot;+i); swap(arr,i,mid); mid = i; quickSort(arr,mid+1,r); quickSort(arr,l,mid-1); return arr; &#125; private static void swap(int[] arr, int i, int j) &#123; int tmp = arr[i]; arr[i] = arr[j]; arr[j] = tmp; &#125; public static void p(int[] arr)&#123; for (int n:arr)&#123; System.out.print(n+&quot; &quot;); &#125; System.out.println(); &#125; }","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"快速排序","slug":"快速排序","permalink":"http://example.com/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"}],"author":"John Doe"},{"title":"进程通信的方式","slug":"有了for循环，为什么还需要forEach？","date":"2022-01-07T12:48:00.000Z","updated":"2022-01-07T12:59:11.982Z","comments":true,"path":"2022/01/07/有了for循环，为什么还需要forEach？/","link":"","permalink":"http://example.com/2022/01/07/%E6%9C%89%E4%BA%86for%E5%BE%AA%E7%8E%AF%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E9%9C%80%E8%A6%81forEach%EF%BC%9F/","excerpt":"","text":"在操作系统中，进程是资源分配的基本单位，进程间如果要实现通信，有共享存储、消息传递、管道以及socket这几种方式。 共享存储： 1、基于数据结构的共享：比如共享空间里只能放 一个长度为10的数组。这种共享方式速度慢、 限制多，是一种低级通信方式。 2、基于存储区的共享：在内存中画出一块共享存 储区，数据的形式、存放位置都由进程控制， 而不是操作系统。相比之下，这种共享方式速 度更快，是一种高级通信方式。 管道通信： 1. 管道只能采用半双工通信，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置 两个管道。 2. 各进程要互斥地访问管道。 3. 数据以字符流的形式写入管道，当管道写满时，写进程的write()系统调用将被阻塞，等待读进程将数据 取走。当读进程将数据全部取走后，管道变空，此时读进程的read()系统调用将被阻塞。 4. 如果没写满，就不允许读。如果没读空，就不允许写。 5. 数据一旦被读出，就从管道中被抛弃，这就意味着读进程最多只能有一个，否则可能会有读错数据的情 况。 消息传递： 1、直接传递：发送到接收方的接受缓冲队列上 2、间接传递：设置一个接受中转信箱，发送方发送的消息发送到信箱，接收方接受消息从信箱中取 socket：借助于网络通信，从一个主机的进程发送消息到另一个主机上的进程。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"author":"ATAO"},{"title":"单例模式","slug":"单例模式","date":"2022-01-05T08:04:00.000Z","updated":"2022-03-05T01:43:05.127Z","comments":true,"path":"2022/01/05/单例模式/","link":"","permalink":"http://example.com/2022/01/05/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"单例模式，即java类不对外提供构造方法，在类加载的时候创建一个实例化的对象，或者提供一个方法，在方法中作出限制，保证例化对象的创建全局只有唯一一个。其好处在于可以节约系统资源，在资源共享的情况下，避免由于资源操作时导致的性能或损耗等。如日志文件，应用配置。在控制资源的情况下，方便资源之间的互相通信。如线程池等。一般可以用于网站的计数器、web应用的日志、配置对象的读取、打印机、任务管理器、数据库连接池。其具体代码实现可以分为饿汉式和懒汉式。 /** 饿汉式 /public class Singleton01 { public static final Singleton01 instance = new Singleton01(); private Singleton01(){ }}/** 饿汉式 /public class Singleton02 { public static final Singleton02 instance; static { instance = new Singleton02(); } private Singleton02(){ } }/** 饿汉式 /public enum Singleton03 { INSTANCE}/** 懒汉式: 存在线程安全问题 /public class Singleton04 { private static Singleton04 instance; private Singleton04(){ } public static Singleton04 getInstance(){ if (instance == null)&#123; instance = new Singleton04(); &#125; return instance; }}/** 懒汉式: 解决线程安全问题 /public class Singleton05 { private volatile static Singleton05 instance; private Singleton05(){ } public static Singleton05 getInstance(){ if (instance == null)&#123; synchronized (Singleton05.class)&#123; instance = new Singleton05(); &#125; &#125; return instance; }}/** 懒汉式: 内部类 /public class Singleton06 { private Singleton06(){ } private static class Inner{ private static final Singleton06 instance = new Singleton06(); } public static Singleton06 getInstance(){ return Inner.instance; }} 总结： 添加 volatile 关键字之后的双重检查锁模式是一种比较好的单例实现模式，能够保证在多线程的情况下线程安全也不会有性能问题。 静态内部类单例模式中实例由内部类创建，由于 JVM 在加载外部类的过程中, 是不会加载静态内部类的, 只有内部类的属性/方法被调用时才会被加载, 并初始化其静态属性。静态属性由于被static 修饰，保证只被实例化一次，并且严格保证实例化顺序。 静态内部类单例模式是一种优秀的单例模式，是开源项目中比较常用的一种单例模式。在没有加任何锁的情况下，保证了多线程下的安全，并且没有任何性能影响和空间的浪费。 枚举类实现单例模式是极力推荐的单例实现模式，因为枚举类型是线程安全的，并且只会装载一次，设计者充分的利用了枚举的这个特性来实现单例模式，枚举的写法非常简单，而且枚举类型是所用单例实现中唯一一种不会被破坏的单例实现模式。","categories":[{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"},{"name":"设计模式","slug":"java/设计模式","permalink":"http://example.com/categories/java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"author":"John Doe"},{"title":"Hello World","slug":"hello-world","date":"2022-01-05T06:09:04.194Z","updated":"2022-01-05T06:09:04.194Z","comments":true,"path":"2022/01/05/hello-world/","link":"","permalink":"http://example.com/2022/01/05/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/categories/Elasticsearch/"},{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"Kafka","slug":"算法/Kafka","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/Kafka/"},{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"I/O多路复用","slug":"I-O多路复用","permalink":"http://example.com/categories/I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/categories/Kafka/"},{"name":"Zookeeper","slug":"Kafka/Zookeeper","permalink":"http://example.com/categories/Kafka/Zookeeper/"},{"name":"消息队列","slug":"Kafka/消息队列","permalink":"http://example.com/categories/Kafka/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"http://example.com/categories/Spring-Security/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"编译原理","slug":"编译原理","permalink":"http://example.com/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"集合","slug":"集合","permalink":"http://example.com/categories/%E9%9B%86%E5%90%88/"},{"name":"ArrayList","slug":"集合/ArrayList","permalink":"http://example.com/categories/%E9%9B%86%E5%90%88/ArrayList/"},{"name":"Spring ","slug":"Spring/Spring","permalink":"http://example.com/categories/Spring/Spring/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/categories/Redis/"},{"name":"Redis","slug":"算法/Redis","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/Redis/"},{"name":"juc","slug":"juc","permalink":"http://example.com/categories/juc/"},{"name":"设计模式","slug":"juc/设计模式","permalink":"http://example.com/categories/juc/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"jv'm","slug":"jv-m","permalink":"http://example.com/categories/jv-m/"},{"name":"jvm","slug":"jv-m/jvm","permalink":"http://example.com/categories/jv-m/jvm/"},{"name":"java","slug":"集合/java","permalink":"http://example.com/categories/%E9%9B%86%E5%90%88/java/"},{"name":"java基础","slug":"java基础","permalink":"http://example.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/categories/Java%E5%9F%BA%E7%A1%80/"},{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机基础/计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"设计模式","slug":"java/设计模式","permalink":"http://example.com/categories/java/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"分片","slug":"分片","permalink":"http://example.com/tags/%E5%88%86%E7%89%87/"},{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://example.com/tags/Elasticsearch/"},{"name":"routing","slug":"routing","permalink":"http://example.com/tags/routing/"},{"name":"基础概念","slug":"基础概念","permalink":"http://example.com/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"name":"算法","slug":"算法","permalink":"http://example.com/tags/%E7%AE%97%E6%B3%95/"},{"name":"时间轮","slug":"时间轮","permalink":"http://example.com/tags/%E6%97%B6%E9%97%B4%E8%BD%AE/"},{"name":"DelayQueue","slug":"DelayQueue","permalink":"http://example.com/tags/DelayQueue/"},{"name":"队列","slug":"队列","permalink":"http://example.com/tags/%E9%98%9F%E5%88%97/"},{"name":"ScheduledThreadPoolExecutor","slug":"ScheduledThreadPoolExecutor","permalink":"http://example.com/tags/ScheduledThreadPoolExecutor/"},{"name":"Timer","slug":"Timer","permalink":"http://example.com/tags/Timer/"},{"name":"JDK","slug":"JDK","permalink":"http://example.com/tags/JDK/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"IO","slug":"IO","permalink":"http://example.com/tags/IO/"},{"name":"I/O多路复用","slug":"I-O多路复用","permalink":"http://example.com/tags/I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"},{"name":"select/epoll/poll","slug":"select-epoll-poll","permalink":"http://example.com/tags/select-epoll-poll/"},{"name":"Kraft模式","slug":"Kraft模式","permalink":"http://example.com/tags/Kraft%E6%A8%A1%E5%BC%8F/"},{"name":"数据积压","slug":"数据积压","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B/"},{"name":"消费者","slug":"消费者","permalink":"http://example.com/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"},{"name":"漏消费","slug":"漏消费","permalink":"http://example.com/tags/%E6%BC%8F%E6%B6%88%E8%B4%B9/"},{"name":"重复消费","slug":"重复消费","permalink":"http://example.com/tags/%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9/"},{"name":"offset","slug":"offset","permalink":"http://example.com/tags/offset/"},{"name":"分区分配策略","slug":"分区分配策略","permalink":"http://example.com/tags/%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5/"},{"name":"高效读写","slug":"高效读写","permalink":"http://example.com/tags/%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99/"},{"name":"清楚策略","slug":"清楚策略","permalink":"http://example.com/tags/%E6%B8%85%E6%A5%9A%E7%AD%96%E7%95%A5/"},{"name":"文件存储","slug":"文件存储","permalink":"http://example.com/tags/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8/"},{"name":"Leader","slug":"Leader","permalink":"http://example.com/tags/Leader/"},{"name":"Partition","slug":"Partition","permalink":"http://example.com/tags/Partition/"},{"name":"Kafka","slug":"Kafka","permalink":"http://example.com/tags/Kafka/"},{"name":"Leader和Follower故障","slug":"Leader和Follower故障","permalink":"http://example.com/tags/Leader%E5%92%8CFollower%E6%95%85%E9%9A%9C/"},{"name":"工作流程","slug":"工作流程","permalink":"http://example.com/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://example.com/tags/Zookeeper/"},{"name":"数据有序","slug":"数据有序","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F/"},{"name":"事务","slug":"事务","permalink":"http://example.com/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"数据","slug":"数据","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE/"},{"name":"认证","slug":"认证","permalink":"http://example.com/tags/%E8%AE%A4%E8%AF%81/"},{"name":"AOP","slug":"AOP","permalink":"http://example.com/tags/AOP/"},{"name":"面试题","slug":"面试题","permalink":"http://example.com/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"循环依赖","slug":"循环依赖","permalink":"http://example.com/tags/%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/"},{"name":"应用","slug":"应用","permalink":"http://example.com/tags/%E5%BA%94%E7%94%A8/"},{"name":"创建者模式","slug":"创建者模式","permalink":"http://example.com/tags/%E5%88%9B%E5%BB%BA%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"name":"建造者模式","slug":"建造者模式","permalink":"http://example.com/tags/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/"},{"name":"原型模式","slug":"原型模式","permalink":"http://example.com/tags/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"name":"工厂模式","slug":"工厂模式","permalink":"http://example.com/tags/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"},{"name":"transient","slug":"transient","permalink":"http://example.com/tags/transient/"},{"name":"单例模式","slug":"单例模式","permalink":"http://example.com/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"破坏","slug":"破坏","permalink":"http://example.com/tags/%E7%A0%B4%E5%9D%8F/"},{"name":"设计原则","slug":"设计原则","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"},{"name":"UML","slug":"UML","permalink":"http://example.com/tags/UML/"},{"name":"分类","slug":"分类","permalink":"http://example.com/tags/%E5%88%86%E7%B1%BB/"},{"name":"注解","slug":"注解","permalink":"http://example.com/tags/%E6%B3%A8%E8%A7%A3/"},{"name":"IOC","slug":"IOC","permalink":"http://example.com/tags/IOC/"},{"name":"容器","slug":"容器","permalink":"http://example.com/tags/%E5%AE%B9%E5%99%A8/"},{"name":"资源加载","slug":"资源加载","permalink":"http://example.com/tags/%E8%B5%84%E6%BA%90%E5%8A%A0%E8%BD%BD/"},{"name":"bean","slug":"bean","permalink":"http://example.com/tags/bean/"},{"name":"scop","slug":"scop","permalink":"http://example.com/tags/scop/"},{"name":"FactoryBean","slug":"FactoryBean","permalink":"http://example.com/tags/FactoryBean/"},{"name":"scope","slug":"scope","permalink":"http://example.com/tags/scope/"},{"name":"BeanFactory","slug":"BeanFactory","permalink":"http://example.com/tags/BeanFactory/"},{"name":"IoC Service Provider","slug":"IoC-Service-Provider","permalink":"http://example.com/tags/IoC-Service-Provider/"},{"name":"IOC的理解","slug":"IOC的理解","permalink":"http://example.com/tags/IOC%E7%9A%84%E7%90%86%E8%A7%A3/"},{"name":"注入方式","slug":"注入方式","permalink":"http://example.com/tags/%E6%B3%A8%E5%85%A5%E6%96%B9%E5%BC%8F/"},{"name":"索引","slug":"索引","permalink":"http://example.com/tags/%E7%B4%A2%E5%BC%95/"},{"name":"行结构","slug":"行结构","permalink":"http://example.com/tags/%E8%A1%8C%E7%BB%93%E6%9E%84/"},{"name":"行","slug":"行","permalink":"http://example.com/tags/%E8%A1%8C/"},{"name":"TCP","slug":"TCP","permalink":"http://example.com/tags/TCP/"},{"name":"最左匹配原则","slug":"最左匹配原则","permalink":"http://example.com/tags/%E6%9C%80%E5%B7%A6%E5%8C%B9%E9%85%8D%E5%8E%9F%E5%88%99/"},{"name":"性能","slug":"性能","permalink":"http://example.com/tags/%E6%80%A7%E8%83%BD/"},{"name":"主键","slug":"主键","permalink":"http://example.com/tags/%E4%B8%BB%E9%94%AE/"},{"name":"http","slug":"http","permalink":"http://example.com/tags/http/"},{"name":"get","slug":"get","permalink":"http://example.com/tags/get/"},{"name":"post","slug":"post","permalink":"http://example.com/tags/post/"},{"name":"代理模式","slug":"代理模式","permalink":"http://example.com/tags/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"},{"name":"锁","slug":"锁","permalink":"http://example.com/tags/%E9%94%81/"},{"name":"表","slug":"表","permalink":"http://example.com/tags/%E8%A1%A8/"},{"name":"文件","slug":"文件","permalink":"http://example.com/tags/%E6%96%87%E4%BB%B6/"},{"name":"innoDB","slug":"innoDB","permalink":"http://example.com/tags/innoDB/"},{"name":"框架实现","slug":"框架实现","permalink":"http://example.com/tags/%E6%A1%86%E6%9E%B6%E5%AE%9E%E7%8E%B0/"},{"name":"一致性哈希算法","slug":"一致性哈希算法","permalink":"http://example.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/"},{"name":"主从复制模型","slug":"主从复制模型","permalink":"http://example.com/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%9E%8B/"},{"name":"内存优化","slug":"内存优化","permalink":"http://example.com/tags/%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/"},{"name":"回收进程","slug":"回收进程","permalink":"http://example.com/tags/%E5%9B%9E%E6%94%B6%E8%BF%9B%E7%A8%8B/"},{"name":"异步队列","slug":"异步队列","permalink":"http://example.com/tags/%E5%BC%82%E6%AD%A5%E9%98%9F%E5%88%97/"},{"name":"分布式锁","slug":"分布式锁","permalink":"http://example.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"热点数据","slug":"热点数据","permalink":"http://example.com/tags/%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE/"},{"name":"共享","slug":"共享","permalink":"http://example.com/tags/%E5%85%B1%E4%BA%AB/"},{"name":"内存回收","slug":"内存回收","permalink":"http://example.com/tags/%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6/"},{"name":"对象","slug":"对象","permalink":"http://example.com/tags/%E5%AF%B9%E8%B1%A1/"},{"name":"整数集合","slug":"整数集合","permalink":"http://example.com/tags/%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/"},{"name":"跳表","slug":"跳表","permalink":"http://example.com/tags/%E8%B7%B3%E8%A1%A8/"},{"name":"哈希表","slug":"哈希表","permalink":"http://example.com/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"},{"name":"链表","slug":"链表","permalink":"http://example.com/tags/%E9%93%BE%E8%A1%A8/"},{"name":"字符串","slug":"字符串","permalink":"http://example.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"synchronized","slug":"synchronized","permalink":"http://example.com/tags/synchronized/"},{"name":"终止模式","slug":"终止模式","permalink":"http://example.com/tags/%E7%BB%88%E6%AD%A2%E6%A8%A1%E5%BC%8F/"},{"name":"创建线程","slug":"创建线程","permalink":"http://example.com/tags/%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B/"},{"name":"类初始化：主动使用与被动使用","slug":"类初始化：主动使用与被动使用","permalink":"http://example.com/tags/%E7%B1%BB%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%9A%E4%B8%BB%E5%8A%A8%E4%BD%BF%E7%94%A8%E4%B8%8E%E8%A2%AB%E5%8A%A8%E4%BD%BF%E7%94%A8/"},{"name":"类的加载过程","slug":"类的加载过程","permalink":"http://example.com/tags/%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/"},{"name":"ArrayList","slug":"ArrayList","permalink":"http://example.com/tags/ArrayList/"},{"name":"集合","slug":"集合","permalink":"http://example.com/tags/%E9%9B%86%E5%90%88/"},{"name":"HashMap","slug":"HashMap","permalink":"http://example.com/tags/HashMap/"},{"name":"List","slug":"List","permalink":"http://example.com/tags/List/"},{"name":"接口","slug":"接口","permalink":"http://example.com/tags/%E6%8E%A5%E5%8F%A3/"},{"name":"重写","slug":"重写","permalink":"http://example.com/tags/%E9%87%8D%E5%86%99/"},{"name":"重载","slug":"重载","permalink":"http://example.com/tags/%E9%87%8D%E8%BD%BD/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"java","slug":"java","permalink":"http://example.com/tags/java/"},{"name":"final、finally、fi'nalize","slug":"final、finally、fi-nalize","permalink":"http://example.com/tags/final%E3%80%81finally%E3%80%81fi-nalize/"},{"name":"Integer","slug":"Integer","permalink":"http://example.com/tags/Integer/"},{"name":"快速选择","slug":"快速选择","permalink":"http://example.com/tags/%E5%BF%AB%E9%80%9F%E9%80%89%E6%8B%A9/"},{"name":"Top","slug":"Top","permalink":"http://example.com/tags/Top/"},{"name":"快速排序","slug":"快速排序","permalink":"http://example.com/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}